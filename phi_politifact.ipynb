{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# PHI-3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/jacobshort/anaconda3/envs/llama/lib/python3.9/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "# IMPORTS\n",
    "import torch\n",
    "from transformers import AutoModelForCausalLM, AutoTokenizer\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import classification_report\n",
    "import numpy as np\n",
    "import os"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Initialise Model & Tokeniser"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`flash-attention` package not found, consider installing for better performance: No module named 'flash_attn'.\n",
      "Current `flash-attention` does not support `window_size`. Either upgrade or use `attn_implementation='eager'`.\n",
      "Loading checkpoint shards: 100%|██████████| 2/2 [00:00<00:00, 11.68it/s]\n"
     ]
    }
   ],
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained(\"microsoft/Phi-3-mini-4k-instruct\")\n",
    "\n",
    "model = AutoModelForCausalLM.from_pretrained(\n",
    "    \"microsoft/Phi-3-mini-4k-instruct\",  \n",
    "    torch_dtype=\"auto\",  \n",
    "    trust_remote_code=True\n",
    ")\n",
    "\n",
    "device = torch.device(\"mps\")\n",
    "model = model.to(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get Predictions & Metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predictions(model, tokenizer, df):\n",
    "    model.eval()\n",
    "    all_preds = []\n",
    "    prompts = df['text'].tolist()\n",
    "    total = len(prompts)\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for i, prompt in enumerate(prompts):\n",
    "            # Create the system and user prompts\n",
    "            system_prompt = \"You are a helpful assistant.\"\n",
    "            user_prompt = f\"Tell me if this text is real or fake news. Only answer with the word 'real' or 'fake'.\\n{prompt}\"\n",
    "            full_prompt = f\"<|system|>{system_prompt}<|user|>{user_prompt}<|assistant|>\"\n",
    "            \n",
    "            # Tokenize the combined prompt\n",
    "            inputs = tokenizer(full_prompt, return_tensors=\"pt\", truncation=True).to(device)\n",
    "\n",
    "            # Obtain model output\n",
    "            output = model.generate(**inputs, max_new_tokens=5, eos_token_id=tokenizer.eos_token_id)\n",
    "            \n",
    "            # Decode the generated output to text\n",
    "            generated_text = tokenizer.decode(output[0], skip_special_tokens=True).strip()\n",
    "\n",
    "            # Extract the answer by taking the last word, with normalization\n",
    "            predicted_text = generated_text.strip().split()[-1].lower()\n",
    "            \n",
    "            # Check if the predicted text is \"real\" or \"fake\" and map it to 1 or 0\n",
    "            if predicted_text == 'real':\n",
    "                prediction = 1\n",
    "            elif predicted_text == 'fake':\n",
    "                prediction = 0\n",
    "            else:\n",
    "                prediction = None \n",
    "\n",
    "            all_preds.append(prediction)\n",
    "            \n",
    "            processed_items = i + 1\n",
    "            remaining_items = total - processed_items\n",
    "            print(f\"Processed {processed_items} items, {remaining_items} items remaining\")\n",
    "\n",
    "    # Create a DataFrame with original data and predictions\n",
    "    results_df = df.copy()\n",
    "    results_df['prediction'] = all_preds\n",
    "\n",
    "    return results_df\n",
    "\n",
    "\n",
    "\n",
    "# Function to truncate text to a certain number of tokens\n",
    "# Ignore warning about tokenised sequence length\n",
    "def truncate_text(text, tokenizer, max_tokens):\n",
    "    tokens = tokenizer.encode(text)\n",
    "    if len(tokens) > max_tokens:\n",
    "        tokens = tokens[:max_tokens]\n",
    "    return tokenizer.decode(tokens, skip_special_tokens=True)\n",
    "\n",
    "\n",
    "\n",
    "# Function to get the results table\n",
    "def get_results_table(results_path, df):\n",
    "\n",
    "    if os.path.exists(results_path):\n",
    "        print(f\"Results file already exists at {results_path}. Loading existing results.\")\n",
    "        results_df = pd.read_csv(results_path)\n",
    "    else:\n",
    "        print(\"Results file does not exist. Running predictions.\")\n",
    "        df['text'] = df['text'].apply(lambda x: truncate_text(x, tokenizer, max_tokens=256))\n",
    "        results_df = predictions(model, tokenizer, df)\n",
    "        results_df.to_csv(results_path, index=False)\n",
    "        print(f\"Results saved to {results_path}.\")\n",
    "    return results_df\n",
    "\n",
    "\n",
    "\n",
    "def get_metrics(results_df):\n",
    "  \n",
    "    original_misinformations = results_df[results_df['is_true'] == 0]\n",
    "    correct_predictions = original_misinformations[original_misinformations['prediction'] == 0].shape[0]\n",
    "    success_rate = 100*(correct_predictions / original_misinformations.shape[0]) if original_misinformations.shape[0] > 0 else 0\n",
    "\n",
    "    metrics = classification_report(results_df['is_true'], results_df['prediction'])\n",
    "    \n",
    "    return success_rate, metrics\n",
    "\n",
    "\n",
    "\n",
    "def get_metrics_classwise(results_df):\n",
    "    original_misinformations = results_df[results_df['is_true'] == 0]\n",
    "    correct_predictions = original_misinformations[original_misinformations['prediction'] == 0].shape[0]\n",
    "    success_rate = 100*(correct_predictions / original_misinformations.shape[0]) if original_misinformations.shape[0] > 0 else 0\n",
    "\n",
    "    classwise_success_rates = {}\n",
    "    for category in results_df['label'].unique():\n",
    "        category_df = results_df[results_df['label'] == category]\n",
    "        original_misinformations = category_df[category_df['is_true'] == 0]\n",
    "        correct_predictions = original_misinformations[original_misinformations['prediction'] == 0].shape[0]\n",
    "        classwise_success_rate = 100 * (correct_predictions / original_misinformations.shape[0]) if original_misinformations.shape[0] > 0 else 0\n",
    "        classwise_success_rates[category] = classwise_success_rate\n",
    "\n",
    "    metrics = classification_report(results_df['is_true'], results_df['prediction'])\n",
    "\n",
    "    return success_rate, classwise_success_rates, metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results file already exists at /Applications/AI/msc_project/predictions/my_politifact_test_predictions_phi3.csv. Loading existing results.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>is_true</th>\n",
       "      <th>prediction</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Senate Passes Obama-Hagel Provision Aimed at P...</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>The .gov means it's official. Federal governme...</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Muslim convert and would-be domestic terrorist...</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>We'll stop supporting this browser soon. For t...</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Pledge of Allegiance E-mail  The following is ...</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>171</th>\n",
       "      <td>Fox News host Sandra Smith on Wednesday linked...</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>172</th>\n",
       "      <td>Listen to this page  Listen to this page  List...</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>173</th>\n",
       "      <td>NRA President Jim Porter Falsely Accused of Sa...</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>174</th>\n",
       "      <td>President Trump invited Elizabeth Alvarado, Ro...</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>175</th>\n",
       "      <td>Snopes Paid to Push ‘Propaganda’ by Facebook, ...</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>138 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                  text  is_true  prediction\n",
       "0    Senate Passes Obama-Hagel Provision Aimed at P...        1         1.0\n",
       "1    The .gov means it's official. Federal governme...        1         1.0\n",
       "2    Muslim convert and would-be domestic terrorist...        0         0.0\n",
       "4    We'll stop supporting this browser soon. For t...        1         0.0\n",
       "5    Pledge of Allegiance E-mail  The following is ...        1         1.0\n",
       "..                                                 ...      ...         ...\n",
       "171  Fox News host Sandra Smith on Wednesday linked...        0         1.0\n",
       "172  Listen to this page  Listen to this page  List...        1         1.0\n",
       "173  NRA President Jim Porter Falsely Accused of Sa...        0         0.0\n",
       "174  President Trump invited Elizabeth Alvarado, Ro...        0         0.0\n",
       "175  Snopes Paid to Push ‘Propaganda’ by Facebook, ...        0         0.0\n",
       "\n",
       "[138 rows x 3 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.71      0.76      0.74        59\n",
      "           1       0.81      0.77      0.79        79\n",
      "\n",
      "    accuracy                           0.77       138\n",
      "   macro avg       0.76      0.77      0.76       138\n",
      "weighted avg       0.77      0.77      0.77       138\n",
      "\n",
      "Success rate: 76.27%\n"
     ]
    }
   ],
   "source": [
    "# HUMAN TEST SET\n",
    "df = pd.read_csv(\"/Applications/AI/msc_project/data/my_politifact_test.csv\")\n",
    "results_path='/Applications/AI/msc_project/predictions/my_politifact_test_predictions_phi3.csv'\n",
    "results_df = get_results_table(results_path=results_path, df=df)\n",
    "results_df = results_df.dropna()\n",
    "display(results_df)\n",
    "\n",
    "success_rate, metrics = get_metrics(results_df)\n",
    "print(metrics)\n",
    "print(f\"Success rate: {success_rate:.2f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results file already exists at /Applications/AI/msc_project/predictions/my_llm_fake_politifact_test_predictions_phi3.csv. Loading existing results.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>text</th>\n",
       "      <th>news_id</th>\n",
       "      <th>seed_text</th>\n",
       "      <th>is_true</th>\n",
       "      <th>prediction</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>llm_totally_arbitrary_generation</td>\n",
       "      <td>Contrary to popular belief, saltwater pools ar...</td>\n",
       "      <td>na</td>\n",
       "      <td>na</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>llm_incomplete</td>\n",
       "      <td>Tonight on CROSSFIRE, the discussion revolves ...</td>\n",
       "      <td>politifact8259</td>\n",
       "      <td>Return to Transcripts main pageCROSSFIREShould...</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>llm_incomplete</td>\n",
       "      <td>Clinton said, \"Trump Management was charged wi...</td>\n",
       "      <td>politifact13138</td>\n",
       "      <td>Clinton said, \"Trump Management was charged wi...</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>llm_incomplete</td>\n",
       "      <td>One of the key findings from the leaked docume...</td>\n",
       "      <td>politifact7888</td>\n",
       "      <td>A rush transcript of \"This Week with George St...</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>llm_unsubstantiated_content</td>\n",
       "      <td>The reason why the interactive transcript coul...</td>\n",
       "      <td>politifact341</td>\n",
       "      <td>The interactive transcript could not be loaded...</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>407</th>\n",
       "      <td>llm_open_generation</td>\n",
       "      <td>In a disturbing display of bigotry and intoler...</td>\n",
       "      <td>politifact13766</td>\n",
       "      <td>How intolerant can a group of people get, folk...</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>408</th>\n",
       "      <td>llm_health_generation</td>\n",
       "      <td>Title: \"BREAKING: Landmark Study Reveals Choco...</td>\n",
       "      <td>na</td>\n",
       "      <td>na</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>410</th>\n",
       "      <td>llm_politics_generation</td>\n",
       "      <td>Title: Shocking Revelation: Recent Political S...</td>\n",
       "      <td>na</td>\n",
       "      <td>na</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>413</th>\n",
       "      <td>llm_incomplete</td>\n",
       "      <td>Services for KentuckyIt is an absolute honor t...</td>\n",
       "      <td>politifact7506</td>\n",
       "      <td>Services for KentuckyIt is an absolute honor t...</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>414</th>\n",
       "      <td>llm_hallucination</td>\n",
       "      <td>Title: \"Local Community Enjoys Successful Fund...</td>\n",
       "      <td>na</td>\n",
       "      <td>na</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>278 rows × 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                label  \\\n",
       "0    llm_totally_arbitrary_generation   \n",
       "1                      llm_incomplete   \n",
       "3                      llm_incomplete   \n",
       "5                      llm_incomplete   \n",
       "8         llm_unsubstantiated_content   \n",
       "..                                ...   \n",
       "407               llm_open_generation   \n",
       "408             llm_health_generation   \n",
       "410           llm_politics_generation   \n",
       "413                    llm_incomplete   \n",
       "414                 llm_hallucination   \n",
       "\n",
       "                                                  text          news_id  \\\n",
       "0    Contrary to popular belief, saltwater pools ar...               na   \n",
       "1    Tonight on CROSSFIRE, the discussion revolves ...   politifact8259   \n",
       "3    Clinton said, \"Trump Management was charged wi...  politifact13138   \n",
       "5    One of the key findings from the leaked docume...   politifact7888   \n",
       "8    The reason why the interactive transcript coul...    politifact341   \n",
       "..                                                 ...              ...   \n",
       "407  In a disturbing display of bigotry and intoler...  politifact13766   \n",
       "408  Title: \"BREAKING: Landmark Study Reveals Choco...               na   \n",
       "410  Title: Shocking Revelation: Recent Political S...               na   \n",
       "413  Services for KentuckyIt is an absolute honor t...   politifact7506   \n",
       "414  Title: \"Local Community Enjoys Successful Fund...               na   \n",
       "\n",
       "                                             seed_text  is_true  prediction  \n",
       "0                                                   na        0         1.0  \n",
       "1    Return to Transcripts main pageCROSSFIREShould...        0         1.0  \n",
       "3    Clinton said, \"Trump Management was charged wi...        0         0.0  \n",
       "5    A rush transcript of \"This Week with George St...        0         0.0  \n",
       "8    The interactive transcript could not be loaded...        0         0.0  \n",
       "..                                                 ...      ...         ...  \n",
       "407  How intolerant can a group of people get, folk...        0         0.0  \n",
       "408                                                 na        0         0.0  \n",
       "410                                                 na        0         0.0  \n",
       "413  Services for KentuckyIt is an absolute honor t...        0         1.0  \n",
       "414                                                 na        0         1.0  \n",
       "\n",
       "[278 rows x 6 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       1.00      0.67      0.80       278\n",
      "         1.0       0.00      0.00      0.00         0\n",
      "\n",
      "    accuracy                           0.67       278\n",
      "   macro avg       0.50      0.33      0.40       278\n",
      "weighted avg       1.00      0.67      0.80       278\n",
      "\n",
      "Success rate: 66.91%\n",
      "{'llm_totally_arbitrary_generation': 75.0, 'llm_incomplete': 47.61904761904761, 'llm_unsubstantiated_content': 75.0, 'llm_total_fabrication': 72.22222222222221, 'llm_rewritten': 69.04761904761905, 'llm_false_context': 61.904761904761905, 'llm_paraphrase': 70.27027027027027, 'llm_health_generation': 100.0, 'llm_outdated': 86.36363636363636, 'llm_ambiguity': 59.09090909090909, 'llm_politics_generation': 100.0, 'llm_hallucination': 25.0, 'llm_open_generation': 43.75}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/jacobshort/anaconda3/envs/llama/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/Users/jacobshort/anaconda3/envs/llama/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/Users/jacobshort/anaconda3/envs/llama/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    }
   ],
   "source": [
    "# LLM TEST SET\n",
    "df = pd.read_csv(\"/Applications/AI/msc_project/data/my_llm_fake_politifact_test.csv\")\n",
    "results_path='/Applications/AI/msc_project/predictions/my_llm_fake_politifact_test_predictions_phi3.csv'\n",
    "results_df = get_results_table(results_path=results_path, df=df)\n",
    "results_df = results_df.dropna()\n",
    "display(results_df)\n",
    "\n",
    "success_rate, classwise_success_rates, metrics = get_metrics_classwise(results_df)\n",
    "print(metrics)\n",
    "print(f\"Success rate: {success_rate:.2f}%\")\n",
    "print(classwise_success_rates)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.19 ('msc')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "ef2bd7e3e00f4b6fcee4892790b46d95cb807c19c0ee9ef583cd076259e322f8"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
