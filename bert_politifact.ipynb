{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Imports & GPU Selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/jacobshort/anaconda3/envs/uni_39/lib/python3.9/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "# IMPORTS\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from sklearn.metrics import classification_report\n",
    "from transformers import AutoModel, BertTokenizerFast\n",
    "import matplotlib.pyplot as plt\n",
    "from torch.utils.data import TensorDataset, DataLoader, RandomSampler, SequentialSampler\n",
    "import torch.optim as optim\n",
    "from sklearn.utils.class_weight import compute_class_weight\n",
    "import os\n",
    "import gc\n",
    "import re\n",
    "from scipy.stats import wilcoxon\n",
    "\n",
    "# SPECIFY GPU\n",
    "device = torch.device(\"mps\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# BERT Fine-Tuning On PolitiFact (Human)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Loading & Pre-Processing\n",
    "- Tokenisation\n",
    "- Analyse tokenised sequence length\n",
    "- Data formatting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to create tokenised text attention masks & labels in tensor format\n",
    "def pre_process_data(data, tokenizer, max_len):\n",
    "    text = data['text']\n",
    "    labels = data['is_true']\n",
    "\n",
    "    untruncated_tokenised_sequences = [(tokenizer.encode(text, truncation=False, add_special_tokens=True)) for text in text]\n",
    "\n",
    "    tokenised_sequences = tokenizer.batch_encode_plus(\n",
    "    text.tolist(),\n",
    "    max_length = max_len,\n",
    "    pad_to_max_length=True,\n",
    "    truncation=True)\n",
    "\n",
    "    tokenised_sequence_tensor = torch.tensor(tokenised_sequences['input_ids'])\n",
    "    mask_tensor = torch.tensor(tokenised_sequences['attention_mask'])\n",
    "    labels_tensor = torch.tensor(labels.tolist())\n",
    "\n",
    "    return untruncated_tokenised_sequences, tokenised_sequence_tensor, mask_tensor, labels_tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/jacobshort/anaconda3/envs/uni_39/lib/python3.9/site-packages/transformers/tokenization_utils_base.py:1601: FutureWarning: `clean_up_tokenization_spaces` was not set. It will be set to `True` by default. This behavior will be depracted in transformers v4.45, and will be then set to `False` by default. For more details check this issue: https://github.com/huggingface/transformers/issues/31884\n",
      "  warnings.warn(\n",
      "Token indices sequence length is longer than the specified maximum sequence length for this model (5466 > 512). Running this sequence through the model will result in indexing errors\n",
      "/Users/jacobshort/anaconda3/envs/uni_39/lib/python3.9/site-packages/transformers/tokenization_utils_base.py:2870: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "# Define tokeniser & truncation max length\n",
    "tokenizer = BertTokenizerFast.from_pretrained('bert-base-uncased')\n",
    "max_len = 256\n",
    "\n",
    "# Load data\n",
    "train_df = pd.read_csv(\"/Applications/AI/msc_project/data/my_politifact_train.csv\")\n",
    "val_df = pd.read_csv(\"/Applications/AI/msc_project/data/my_politifact_validation.csv\")\n",
    "test_df = pd.read_csv(\"/Applications/AI/msc_project/data/my_politifact_test.csv\")\n",
    "\n",
    "# Obtain tokenised text, attention masks & labels in tensor format\n",
    "train_untruncated_seq, train_seq, train_mask, train_y = pre_process_data(train_df, tokenizer, max_len)\n",
    "val_untruncated_seq, val_seq, val_mask, val_y = pre_process_data(val_df, tokenizer, max_len)\n",
    "test_untruncated_seq, test_seq, test_mask, test_y = pre_process_data(test_df, tokenizer, max_len)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "max:22952\n",
      "min:8\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1000x600 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Plot the histogram of untruncated token counts\n",
    "all_tokenised_seq = train_untruncated_seq + val_untruncated_seq + test_untruncated_seq\n",
    "token_counts = [len(seq) for seq in all_tokenised_seq]\n",
    "print('max:' + str(max(token_counts)))\n",
    "print('min:' + str(min(token_counts)))\n",
    "plt.figure(figsize=(10, 6))\n",
    "pd.Series(token_counts).hist(bins=200, range=(0, 25000))\n",
    "plt.xlabel('Token Count')\n",
    "plt.ylabel('Frequency')\n",
    "plt.title('Histogram of Token Counts in Tokenised PolitiFact Human Data')\n",
    "plt.xlim(0, 5000)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define Model Architecture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define frozen BERT model\n",
    "def initialise_bert_model():\n",
    "    # Load original BERT and freeze its parameters\n",
    "    bert = AutoModel.from_pretrained('bert-base-uncased')\n",
    "    for param in bert.parameters():\n",
    "        param.requires_grad = False\n",
    "\n",
    "    # Define the model architecture with classification head\n",
    "    # Classification head: ReLu -> FC -> ReLu -> FC -> Softmax\n",
    "    class BERT_Arch(nn.Module):\n",
    "\n",
    "        # Define layers within the model (we use these layers in the forward pass)\n",
    "        def __init__(self, bert):\n",
    "            super(BERT_Arch, self).__init__()\n",
    "            self.bert = bert\n",
    "            self.dropout = nn.Dropout(0.1)\n",
    "            self.relu = nn.ReLU()\n",
    "            self.fc1 = nn.Linear(768, 512)\n",
    "            self.fc2 = nn.Linear(512, 2)\n",
    "            self.softmax = nn.LogSoftmax(dim=1)\n",
    "\n",
    "        # Define forward pass (flow of data) through network\n",
    "        def forward(self, sent_id, mask):\n",
    "            # Pass the CLS token (BERT's output) to the model\n",
    "            _, cls_hs = self.bert(sent_id, attention_mask=mask, return_dict=False)\n",
    "            x = self.fc1(cls_hs)\n",
    "            x = self.relu(x)\n",
    "            x = self.dropout(x)\n",
    "            x = self.fc2(x)\n",
    "            x = self.softmax(x)\n",
    "            return x\n",
    "\n",
    "    # Create an instance of BERT and place on GPU\n",
    "    model = BERT_Arch(bert)\n",
    "    model = model.to(device)\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define unfrozen BERT model\n",
    "def initialise_bert_model_unfrozen():\n",
    "    # Load original BERT and freeze its parameters\n",
    "    bert = AutoModel.from_pretrained('bert-base-uncased')\n",
    "    for param in bert.parameters():\n",
    "        param.requires_grad = True\n",
    "\n",
    "    # Define the model architecture with classification head\n",
    "    # Classification head: ReLu -> FC -> ReLu -> FC -> Softmax\n",
    "    class BERT_Arch(nn.Module):\n",
    "\n",
    "        # Define layers within the model (we use these layers in the forward pass)\n",
    "        def __init__(self, bert):\n",
    "            super(BERT_Arch, self).__init__()\n",
    "            self.bert = bert\n",
    "            self.dropout = nn.Dropout(0.1)\n",
    "            self.relu = nn.ReLU()\n",
    "            self.fc1 = nn.Linear(768, 512)\n",
    "            self.fc2 = nn.Linear(512, 2)\n",
    "            self.softmax = nn.LogSoftmax(dim=1)\n",
    "\n",
    "        # Define forward pass (flow of data) through network\n",
    "        def forward(self, sent_id, mask):\n",
    "            # Pass the CLS token (BERT's output) to the model\n",
    "            _, cls_hs = self.bert(sent_id, attention_mask=mask, return_dict=False)\n",
    "            x = self.fc1(cls_hs)\n",
    "            x = self.relu(x)\n",
    "            x = self.dropout(x)\n",
    "            x = self.fc2(x)\n",
    "            x = self.softmax(x)\n",
    "            return x\n",
    "\n",
    "    # Create an instance of BERT and place on GPU\n",
    "    model = BERT_Arch(bert)\n",
    "    model = model.to(device)\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define Training & Evaluation Processes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define training function for BERT model\n",
    "def train(loss_function, optimizer, train_dataloader,model):\n",
    "    model.train()\n",
    "    total_loss = 0\n",
    "    total_preds = []\n",
    "    for step, batch in enumerate(train_dataloader):\n",
    "        if step % 50 == 0 and not step == 0:\n",
    "            print('  Batch {:>5,}  of  {:>5,}.'.format(step, len(train_dataloader)))\n",
    "        batch = [r.to(device) for r in batch]\n",
    "        sent_id, mask, labels = batch\n",
    "        model.zero_grad()\n",
    "        preds = model(sent_id, mask)\n",
    "        batch_loss = loss_function(preds, labels)\n",
    "        total_loss += batch_loss.item()\n",
    "        batch_loss.backward()\n",
    "        torch.nn.utils.clip_grad_norm_(model.parameters(), 1.0)\n",
    "        optimizer.step()\n",
    "        preds = preds.detach().cpu().numpy()\n",
    "        total_preds.append(preds)\n",
    "    avg_loss = total_loss / len(train_dataloader)\n",
    "    total_preds = np.concatenate(total_preds, axis=0)\n",
    "    return avg_loss, total_preds\n",
    "\n",
    "# Define evaluation function for BERT model\n",
    "def evaluate(loss_function, val_dataloader,model):\n",
    "    print(\"\\nEvaluating...\")\n",
    "    model.eval()\n",
    "    total_loss = 0\n",
    "    total_preds = []\n",
    "    for step, batch in enumerate(val_dataloader):\n",
    "        if step % 50 == 0 and not step == 0:\n",
    "            print('  Batch {:>5,}  of  {:>5,}.'.format(step, len(val_dataloader)))\n",
    "        batch = [t.to(device) for t in batch]\n",
    "        sent_id, mask, labels = batch\n",
    "        with torch.no_grad():\n",
    "            preds = model(sent_id, mask)\n",
    "            batch_loss = loss_function(preds, labels)\n",
    "            total_loss += batch_loss.item()\n",
    "            preds = preds.detach().cpu().numpy()\n",
    "            total_preds.append(preds)\n",
    "    avg_loss = total_loss / len(val_dataloader)\n",
    "    total_preds = np.concatenate(total_preds, axis=0)\n",
    "    return avg_loss, total_preds"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Hyperparameter Selection Using Validation Set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nos.remove(model_path)\\n'"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Define path to save / load model weights\n",
    "model_path = \"/Applications/AI/msc_project/model_weights/bert_weights_politifact_human_validation.pt\"\n",
    "\n",
    "# RUN THIS CODE TO RERUN HYPERPARAMETER TUNING\n",
    "'''\n",
    "os.remove(model_path)\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to perform Hyperparameter selection using grid search\n",
    "def hyper_param_selection(learning_rates, batch_sizes, epochs_options, model_inits, train_seq, train_mask, train_y, val_seq, val_mask, val_y):\n",
    "\n",
    "    # Calculate class weights\n",
    "    train_y_numpy = train_y.numpy()\n",
    "    train_y_pd = pd.DataFrame(train_y_numpy)\n",
    "    class_weights = compute_class_weight(\n",
    "        class_weight='balanced',\n",
    "        classes=np.unique(train_y_pd),\n",
    "        y=train_y_pd)\n",
    "    class_weights_tensor= torch.tensor(class_weights, dtype=torch.float).to(device)\n",
    "\n",
    "    # Initialize variables to store the best model's performance and hyperparameters\n",
    "    best_valid_loss = float('inf')\n",
    "    best_hyperparams = {'lr': None, 'batch_size': None, 'epochs': None, 'model_init': None}\n",
    "\n",
    "    # Check if model weights file already exists\n",
    "    if os.path.exists(model_path):\n",
    "        print(f\"Model weights already saved at {model_path}. Skipping hyperparameter selection.\")\n",
    "    else:\n",
    "        for model_init in model_inits:\n",
    "            for lr in learning_rates:\n",
    "                for batch_size in batch_sizes:\n",
    "                    for epochs in epochs_options:\n",
    "                        \n",
    "                        if model_init==\"unfrozen\":\n",
    "                            model = initialise_bert_model_unfrozen()\n",
    "                        else:\n",
    "                            model = initialise_bert_model()\n",
    "                        optimizer = optim.AdamW(model.parameters(), lr=lr)\n",
    "                        weighted_cross_entropy = nn.NLLLoss(weight=class_weights_tensor)\n",
    "                        \n",
    "                        print(f\"\\nTraining with model={model_init}, lr={lr}, batch_size={batch_size}, epochs={epochs}\")\n",
    "                        train_dataloader = DataLoader(TensorDataset(train_seq, train_mask, train_y), \n",
    "                                                    sampler=RandomSampler(TensorDataset(train_seq, train_mask, train_y)), \n",
    "                                                    batch_size=batch_size)\n",
    "                        val_dataloader = DataLoader(TensorDataset(val_seq, val_mask, val_y), \n",
    "                                                    sampler=SequentialSampler(TensorDataset(val_seq, val_mask, val_y)), \n",
    "                                                    batch_size=batch_size)\n",
    "\n",
    "                        for epoch in range(epochs):\n",
    "                            print('\\n Epoch {:} / {:}'.format(epoch + 1, epochs))\n",
    "                            train_loss, _ = train(loss_function=weighted_cross_entropy, optimizer=optimizer, train_dataloader=train_dataloader, model=model)\n",
    "                            valid_loss, _ = evaluate(loss_function=weighted_cross_entropy, val_dataloader=val_dataloader, model=model)\n",
    "                            if valid_loss < best_valid_loss:\n",
    "                                best_valid_loss = valid_loss\n",
    "                                best_hyperparams = {'lr': lr, 'batch_size': batch_size, 'epochs': epochs, 'model_init': model_init}\n",
    "                                torch.save(model.state_dict(), model_path)\n",
    "                                print(f\"Saved new best weights to {model_path}\")\n",
    "                            print(f'\\nTraining Loss: {train_loss:.3f}')\n",
    "                            print(f'Validation Loss: {valid_loss:.3f}')\n",
    "\n",
    "        print(f\"\\nBest Hyperparameters: Model = {best_hyperparams['model_init']}, Learning Rate = {best_hyperparams['lr']}, Batch Size = {best_hyperparams['batch_size']}, Epochs = {best_hyperparams['epochs']}\")\n",
    "        print(f\"Best model saved to: {model_path}\")\n",
    "\n",
    "    return best_hyperparams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model weights already saved at /Applications/AI/msc_project/model_weights/bert_weights_politifact_human_validation.pt. Skipping hyperparameter selection.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/jacobshort/anaconda3/envs/uni_39/lib/python3.9/site-packages/sklearn/preprocessing/_label.py:114: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'lr': None, 'batch_size': None, 'epochs': None, 'model_init': None}"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Define hyperparameter search grid\n",
    "learning_rates = [1e-5, 5e-5]\n",
    "batch_sizes = [16]\n",
    "epochs_options = [2, 4]\n",
    "model_inits = [\"unfrozen\", \"frozen\"]\n",
    "\n",
    "# Run hyperparameter selection (this code will not run if model weights already exist as we have already performed this step)\n",
    "hyper_param_selection(learning_rates=learning_rates, batch_sizes=batch_sizes, epochs_options=epochs_options, model_inits=model_inits, train_seq=train_seq, train_mask=train_mask, train_y=train_y, val_seq=val_seq, val_mask=val_mask, val_y=val_y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fine Tune Using Chosen Hyperparameters On Train Union Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nos.remove(model_path)\\n'"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Define path to save / load model weights\n",
    "model_path = \"/Applications/AI/msc_project/model_weights/bert_weights_politifact_human_finetuned.pt\"\n",
    "\n",
    "# RUN THIS CODE TO RERUN FINE-TUNING\n",
    "'''\n",
    "os.remove(model_path)\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to fine-tune the model on chosen hyperparameters\n",
    "def fine_tune(training_sequence, training_mask, training_y, epochs, batch_size, lr, model_init, model_path):\n",
    "    training_y_numpy = training_y.numpy()\n",
    "    training_y_pd = pd.DataFrame(training_y_numpy)\n",
    "    \n",
    "    class_weights = compute_class_weight(\n",
    "        class_weight='balanced',\n",
    "        classes=np.unique(training_y_pd),\n",
    "        y=training_y_pd)\n",
    "    weights = torch.tensor(class_weights, dtype=torch.float).to(device)\n",
    "\n",
    "    if os.path.exists(model_path):\n",
    "        print(f\"Model weights already saved at {model_path}. Skipping training.\")\n",
    "    else:\n",
    "        # DataLoader for the combined dataset\n",
    "        training_dataloader = DataLoader(TensorDataset(training_sequence, training_mask, training_y), \n",
    "                                        sampler=RandomSampler(TensorDataset(training_sequence, training_mask, training_y)), \n",
    "                                        batch_size=batch_size)\n",
    "\n",
    "        if model_init==\"unfrozen\":\n",
    "            model = initialise_bert_model_unfrozen()\n",
    "        else:\n",
    "            model = initialise_bert_model()\n",
    "        optimizer = optim.AdamW(model.parameters(), lr=lr)\n",
    "        cross_entropy = nn.NLLLoss(weight=weights)\n",
    "\n",
    "        # Model training loop\n",
    "        for epoch in range(epochs):\n",
    "            print(f'\\n Epoch {epoch + 1} / {epochs}')\n",
    "            train_loss = 0\n",
    "            model.train()\n",
    "            for step, batch in enumerate(training_dataloader):\n",
    "                batch = [item.to(device) for item in batch]\n",
    "                seq, mask, labels = batch\n",
    "                model.zero_grad()\n",
    "                outputs = model(seq, mask)\n",
    "                loss = cross_entropy(outputs, labels)\n",
    "                loss.backward()\n",
    "                optimizer.step()\n",
    "                train_loss += loss.item()\n",
    "            \n",
    "            # Log the average loss of the epoch\n",
    "            avg_train_loss = train_loss / len(training_dataloader)\n",
    "            print(f'\\nAverage Training Loss: {avg_train_loss:.3f}')\n",
    "\n",
    "        # Save the trained model weights\n",
    "        torch.save(model.state_dict(), model_path)\n",
    "        print(f\"Model weights saved to {model_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model weights already saved at /Applications/AI/msc_project/model_weights/bert_weights_politifact_human_finetuned.pt. Skipping training.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/jacobshort/anaconda3/envs/uni_39/lib/python3.9/site-packages/sklearn/preprocessing/_label.py:114: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    }
   ],
   "source": [
    "# Define best hyperparameters as chosen by previous hyperparameter selection grid search\n",
    "best_lr = 5e-5\n",
    "best_batch_size = 16\n",
    "best_epochs = 2\n",
    "best_model_init = \"unfrozen\"\n",
    "\n",
    "# Combine training and validation data for fine-tuning\n",
    "combined_training_sequence = torch.cat((train_seq, val_seq), 0)\n",
    "combined_training_mask = torch.cat((train_mask, val_mask), 0)\n",
    "combined_training_y = torch.cat((train_y, val_y), 0)\n",
    "\n",
    "# Fine-tune the model\n",
    "fine_tune(training_sequence=combined_training_sequence, training_mask=combined_training_mask, training_y=combined_training_y, epochs=best_epochs, batch_size=best_batch_size, lr=best_lr, model_init=best_model_init, model_path=model_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Predict Labels On Test Set & LLM Set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "A parameter name that contains `beta` will be renamed internally to `bias`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `gamma` will be renamed internally to `weight`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `beta` will be renamed internally to `bias`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `gamma` will be renamed internally to `weight`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `beta` will be renamed internally to `bias`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `gamma` will be renamed internally to `weight`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `beta` will be renamed internally to `bias`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `gamma` will be renamed internally to `weight`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `beta` will be renamed internally to `bias`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `gamma` will be renamed internally to `weight`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `beta` will be renamed internally to `bias`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `gamma` will be renamed internally to `weight`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `beta` will be renamed internally to `bias`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `gamma` will be renamed internally to `weight`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `beta` will be renamed internally to `bias`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `gamma` will be renamed internally to `weight`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `beta` will be renamed internally to `bias`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `gamma` will be renamed internally to `weight`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `beta` will be renamed internally to `bias`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `gamma` will be renamed internally to `weight`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `beta` will be renamed internally to `bias`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `gamma` will be renamed internally to `weight`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `beta` will be renamed internally to `bias`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `gamma` will be renamed internally to `weight`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `beta` will be renamed internally to `bias`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `gamma` will be renamed internally to `weight`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `beta` will be renamed internally to `bias`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `gamma` will be renamed internally to `weight`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `beta` will be renamed internally to `bias`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `gamma` will be renamed internally to `weight`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `beta` will be renamed internally to `bias`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `gamma` will be renamed internally to `weight`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `beta` will be renamed internally to `bias`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `gamma` will be renamed internally to `weight`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `beta` will be renamed internally to `bias`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `gamma` will be renamed internally to `weight`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `beta` will be renamed internally to `bias`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `gamma` will be renamed internally to `weight`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `beta` will be renamed internally to `bias`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `gamma` will be renamed internally to `weight`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `beta` will be renamed internally to `bias`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `gamma` will be renamed internally to `weight`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `beta` will be renamed internally to `bias`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `gamma` will be renamed internally to `weight`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `beta` will be renamed internally to `bias`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `gamma` will be renamed internally to `weight`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `beta` will be renamed internally to `bias`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `gamma` will be renamed internally to `weight`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `beta` will be renamed internally to `bias`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `gamma` will be renamed internally to `weight`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `beta` will be renamed internally to `bias`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `gamma` will be renamed internally to `weight`. Please use a different name to suppress this warning.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "_IncompatibleKeys(missing_keys=[], unexpected_keys=['bert.embeddings.position_ids'])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load the fine-tuned model\n",
    "model=initialise_bert_model_unfrozen()\n",
    "model.load_state_dict(torch.load(model_path), strict=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to predict labels and compute performance metrics using batching\n",
    "def predictions_and_metrics_basic(model, original_df, sequences, masks, labels):\n",
    "    model = model.to(device)\n",
    "    model.eval()\n",
    "    all_preds = []\n",
    "    batch_size = 32\n",
    "\n",
    "    n_batches = (len(sequences) + batch_size - 1) // batch_size\n",
    "    print(f\"Total batches to process: {n_batches}\")\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for i in range(0, len(sequences), batch_size):\n",
    "            seq_batch = sequences[i:i+batch_size].to(device)\n",
    "            mask_batch = masks[i:i+batch_size].to(device)\n",
    "            \n",
    "            preds = model(seq_batch, mask_batch)\n",
    "            preds = preds.detach().cpu().numpy()\n",
    "            all_preds.append(preds)\n",
    "\n",
    "            \n",
    "            # Progress update every 10 batches\n",
    "            if (i // batch_size + 1) % 10 == 0:\n",
    "                processed_batches = i // batch_size + 1\n",
    "                remaining_batches = n_batches - processed_batches\n",
    "                print(f\"Processed {processed_batches} batches, {remaining_batches} batches remaining\")\n",
    "    \n",
    "    all_preds=np.concatenate(all_preds, axis=0)\n",
    "    predictions = np.argmax(all_preds, axis=1)\n",
    "\n",
    "    text = original_df['text']\n",
    "    text_pd = pd.DataFrame(text)\n",
    "    text_pd = text_pd.iloc[:,0]\n",
    "\n",
    "    labels_numpy = labels.numpy()\n",
    "    labels_pd = pd.DataFrame(labels_numpy)\n",
    "    labels_pd = labels_pd.iloc[:,0]\n",
    "\n",
    "    results_df = pd.DataFrame({'Text': text_pd, 'Predicted Label': predictions, 'Original Label': labels_pd})\n",
    "    results_df = results_df.dropna(subset=['Text'])\n",
    "\n",
    "    original_misinformations = results_df[results_df['Original Label'] == 0]\n",
    "    correct_predictions = original_misinformations[original_misinformations['Predicted Label'] == 0].shape[0]\n",
    "    success_rate = 100*(correct_predictions / original_misinformations.shape[0]) if original_misinformations.shape[0] > 0 else 0\n",
    "\n",
    "    metrics = classification_report(labels, predictions)\n",
    "    \n",
    "    return results_df, success_rate, metrics\n",
    "\n",
    "\n",
    "# Function to predict labels and compute performance metrics using batching\n",
    "# This function also outputs classwise success rates (for different LLMFake categories)\n",
    "def predictions_and_metrics_classwise(model, original_df, sequences, masks, labels):\n",
    "    model = model.to(device)\n",
    "    model.eval()\n",
    "    all_preds = []\n",
    "    batch_size = 32\n",
    "\n",
    "    n_batches = (len(sequences) + batch_size - 1) // batch_size\n",
    "    print(f\"Total batches to process: {n_batches}\")\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for i in range(0, len(sequences), batch_size):\n",
    "            seq_batch = sequences[i:i+batch_size].to(device)\n",
    "            mask_batch = masks[i:i+batch_size].to(device)\n",
    "            \n",
    "            preds = model(seq_batch, mask_batch)\n",
    "            preds = preds.detach().cpu().numpy()\n",
    "            all_preds.append(preds)\n",
    "\n",
    "            # Progress update every 10 batches\n",
    "            if (i // batch_size + 1) % 10 == 0:\n",
    "                processed_batches = i // batch_size + 1\n",
    "                remaining_batches = n_batches - processed_batches\n",
    "                print(f\"Processed {processed_batches} batches, {remaining_batches} batches remaining\")\n",
    "    \n",
    "    all_preds = np.concatenate(all_preds, axis=0)\n",
    "    predictions = np.argmax(all_preds, axis=1)\n",
    "\n",
    "    text = original_df['text']\n",
    "    text_pd = pd.DataFrame(text)\n",
    "    text_pd = text_pd.iloc[:, 0]\n",
    "\n",
    "    labels_numpy = labels.numpy()\n",
    "    labels_pd = pd.DataFrame(labels_numpy)\n",
    "    labels_pd = labels_pd.iloc[:, 0]\n",
    "\n",
    "    categories = original_df['label']\n",
    "    categories_pd = pd.DataFrame(categories)\n",
    "    categories_pd = categories_pd.iloc[:, 0]\n",
    "\n",
    "    results_df = pd.DataFrame({\n",
    "        'Text': text_pd,\n",
    "        'Category': categories_pd,\n",
    "        'Predicted Label': predictions,\n",
    "        'Original Label': labels_pd\n",
    "    })\n",
    "    results_df = results_df.dropna(subset=['Text'])\n",
    "\n",
    "    # Compute overall success rate\n",
    "    original_misinformations = results_df[results_df['Original Label'] == 0]\n",
    "    correct_predictions = original_misinformations[original_misinformations['Predicted Label'] == 0].shape[0]\n",
    "    success_rate = 100 * (correct_predictions / original_misinformations.shape[0]) if original_misinformations.shape[0] > 0 else 0\n",
    "\n",
    "    # Compute class-wise success rates\n",
    "    classwise_success_rates = {}\n",
    "    for category in results_df['Category'].unique():\n",
    "        category_df = results_df[results_df['Category'] == category]\n",
    "        original_misinformations = category_df[category_df['Original Label'] == 0]\n",
    "        correct_predictions = original_misinformations[original_misinformations['Predicted Label'] == 0].shape[0]\n",
    "        classwise_success_rate = 100 * (correct_predictions / original_misinformations.shape[0]) if original_misinformations.shape[0] > 0 else 0\n",
    "        classwise_success_rates[category] = classwise_success_rate\n",
    "\n",
    "    metrics = classification_report(labels, predictions)\n",
    "    \n",
    "    return results_df, success_rate, classwise_success_rates, metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total batches to process: 6\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.84      0.89      0.87        76\n",
      "           1       0.92      0.87      0.89       100\n",
      "\n",
      "    accuracy                           0.88       176\n",
      "   macro avg       0.88      0.88      0.88       176\n",
      "weighted avg       0.88      0.88      0.88       176\n",
      "\n",
      "Success rate: 89.47%\n",
      "/Applications/AI/msc_project/predictions/my_politifact_test_predictions_human_bert.csv already exists. The DataFrame will not be saved.\n"
     ]
    }
   ],
   "source": [
    "# Human trained BERT on human test set\n",
    "# Obtain performance metrics\n",
    "results_df, success_rate, metrics = predictions_and_metrics_basic(model=model, original_df=test_df, sequences=test_seq, masks=test_mask, labels=test_y)\n",
    "print(metrics)\n",
    "print(f\"Success rate: {success_rate:.2f}%\")\n",
    "\n",
    "# Save predictions to file if the file does not already exist\n",
    "results_table_path = '/Applications/AI/msc_project/predictions/my_politifact_test_predictions_human_bert.csv'\n",
    "if os.path.exists(results_table_path):\n",
    "    print(f\"{results_table_path} already exists. The DataFrame will not be saved.\")\n",
    "else:\n",
    "    # Save the results_df to the results_table_path\n",
    "    results_df.to_csv(results_table_path, index=False)\n",
    "    print(f\"Results DataFrame saved to {results_table_path}.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/jacobshort/anaconda3/envs/uni_39/lib/python3.9/site-packages/transformers/tokenization_utils_base.py:1601: FutureWarning: `clean_up_tokenization_spaces` was not set. It will be set to `True` by default. This behavior will be depracted in transformers v4.45, and will be then set to `False` by default. For more details check this issue: https://github.com/huggingface/transformers/issues/31884\n",
      "  warnings.warn(\n",
      "Token indices sequence length is longer than the specified maximum sequence length for this model (545 > 512). Running this sequence through the model will result in indexing errors\n",
      "/Users/jacobshort/anaconda3/envs/uni_39/lib/python3.9/site-packages/transformers/tokenization_utils_base.py:2870: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total batches to process: 14\n",
      "Processed 10 batches, 4 batches remaining\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.66      0.80       417\n",
      "           1       0.00      0.00      0.00         0\n",
      "\n",
      "    accuracy                           0.66       417\n",
      "   macro avg       0.50      0.33      0.40       417\n",
      "weighted avg       1.00      0.66      0.80       417\n",
      "\n",
      "Success rate: 66.19%\n",
      "{'llm_totally_arbitrary_generation': 100.0, 'llm_incomplete': 34.48275862068966, 'llm_false_context': 40.0, 'llm_open_generation': 90.74074074074075, 'llm_unsubstantiated_content': 37.93103448275862, 'llm_outdated': 34.48275862068966, 'llm_health_generation': 100.0, 'llm_rewritten': 92.5925925925926, 'llm_total_fabrication': 44.827586206896555, 'llm_politics_generation': 100.0, 'llm_paraphrase': 87.03703703703704, 'llm_hallucination': 45.0, 'llm_ambiguity': 17.24137931034483}\n",
      "/Applications/AI/msc_project/predictions/my_llm_fake_politifact_test_predictions_human_bert.csv already exists. The DataFrame will not be saved.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/jacobshort/anaconda3/envs/uni_39/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1469: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/jacobshort/anaconda3/envs/uni_39/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1469: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/jacobshort/anaconda3/envs/uni_39/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1469: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "# Human trained BERT on LLMFake test set\n",
    "# Load & pre-process test data\n",
    "ood_df = pd.read_csv(\"/Applications/AI/msc_project/data/my_llm_fake_politifact_test.csv\")\n",
    "ood_untruncated_seq, ood_seq, ood_mask, ood_y = pre_process_data(ood_df, tokenizer, max_len)\n",
    "\n",
    "# Obtain performance metrics\n",
    "results_df, success_rate, classwise_success_rates, metrics = predictions_and_metrics_classwise(model=model, original_df=ood_df, sequences=ood_seq, masks=ood_mask, labels=ood_y)\n",
    "print(metrics)\n",
    "print(f\"Success rate: {success_rate:.2f}%\")\n",
    "print(classwise_success_rates)\n",
    "\n",
    "results_table_path = '/Applications/AI/msc_project/predictions/my_llm_fake_politifact_test_predictions_human_bert.csv'\n",
    "if os.path.exists(results_table_path):\n",
    "    print(f\"{results_table_path} already exists. The DataFrame will not be saved.\")\n",
    "else:\n",
    "    # Save the results_df to the results_table_path\n",
    "    results_df.to_csv(results_table_path, index=False)\n",
    "    print(f\"Results DataFrame saved to {results_table_path}.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# BERT Fine-Tuning On PolitiFact (Human & LLM)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Loading & Pre-Processing\n",
    "- Tokenisation\n",
    "- Analyse tokenised sequence length\n",
    "- Data formatting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/jacobshort/anaconda3/envs/uni_39/lib/python3.9/site-packages/transformers/tokenization_utils_base.py:2870: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAA2QAAAIjCAYAAABswtioAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjguMCwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy81sbWrAAAACXBIWXMAAA9hAAAPYQGoP6dpAABgwElEQVR4nO3dfXyP9f////tr52e2mZONnC2EOY+wKMUYloROSIyU0iiRSsl5hgqRqG9ykqR0onKWOYliOcu5QkXrHZuimZPMbM/fH/12fLxsxGyvY83term8Lnk9j+dxHM/jtcfr1e47juP5chhjjAAAAAAALudm9wAAAAAA4HpFIAMAAAAAmxDIAAAAAMAmBDIAAAAAsAmBDAAAAABsQiADAAAAAJsQyAAAAADAJgQyAAAAALAJgQwAAAAAbEIgA4qASpUqqWfPnnYPo8h75ZVXdOONN8rd3V316tUr0H19/fXXcjgc+vjjjwt0P/h3hfH9dejQITkcDr366qu27Hf27Nku3W/Pnj1VqVIll+7TbpUqVdJdd91l9zAAuACBDChkZs+eLYfDoS1btuS6/I477lCtWrWueT9Lly7ViBEjrnk714sVK1bo2WefVdOmTTVr1iyNHTs2R5/sEHUlj/+is2fPatKkSWrcuLGCgoLk4+Ojm266Sf369dP+/fvtHp4kacOGDRoxYoRSU1PtHkoO2WHmSh6HDh2ye7j/SVfy+ThixAg5HA79+eefl+xz4Xt53rx5ufZp2rSpHA5Hjv1VqlTpkj/Xs2fPXv1BFZCL69HT01MlS5bUrbfeqhdeeEFJSUl53vbhw4c1YsQIbd++Pf8GDBRhHnYPAMC127dvn9zcru7vK0uXLtW0adMIZVdo9erVcnNz08yZM+Xl5ZVrnxo1aui9995zahsyZIgCAgL04osvumKYBebPP/9UmzZttHXrVt1111168MEHFRAQoH379mnBggV6++23de7cObuHqQ0bNmjkyJHq2bOngoOD82WbeXl/5aZUqVI56uO1117T//73P02aNClH38KoYsWK+vvvv+Xp6Wn3UFzCx8dH8+fP10MPPeTUfujQIW3YsEE+Pj65rlevXj0NGjQoR/ulPjvs1LVrV7Vr105ZWVn666+/tHnzZk2ePFmvv/66Zs6cqS5dulz1Ng8fPqyRI0eqUqVKBX41AVAUEMiAIsDb29vuIVy106dPy9/f3+5hXLGjR4/K19f3sr9QhYaG5vjFbdy4cSpZsmSO9v+anj17atu2bfr444/VuXNnp2WjR4/+zwfOy8mv95e/v3+OOliwYIH++uuv/0x9OByOS4aQoqhdu3b64osv9Oeff6pkyZJW+/z58xUaGqqqVavqr7/+yrHeDTfc8J/5md588805xvrrr7+qdevWio2NVY0aNVS3bl2bRgdcH7hkESgCLr7HJSMjQyNHjlTVqlXl4+OjEiVKqFmzZkpISJD0zy/X06ZNk6RcL6M7ffq0Bg0apPLly8vb21vVqlXTq6++KmOM037//vtvPfnkkypZsqSKFSumu+++W7///rscDofTmbfsS4T27t2rBx98UMWLF1ezZs0kSTt37lTPnj114403ysfHR2FhYXr44Yd17Ngxp31lb2P//v166KGHFBQUpFKlSumll16SMUa//fabOnTooMDAQIWFhem11167otfu/PnzGj16tCpXrixvb29VqlRJL7zwgtLT060+DodDs2bN0unTp63X6lruofnll1903333KSQkRH5+fmrSpImWLFnyr+ulp6frrrvuUlBQkDZs2CBJysrK0uTJk1WzZk35+PgoNDRUjz32WI5fErPvR/n222/VqFEj+fj46MYbb9TcuXP/db8bN27UkiVL1Lt37xxhTPonsFx8L9Pq1at12223yd/fX8HBwerQoYN++OEHpz6Xui8o+2d9IYfDoX79+mnRokWqVauWvL29VbNmTS1fvtxpvcGDB0uSwsPDc1z+l5CQoGbNmik4OFgBAQGqVq2aXnjhhX89/ovfX9mXFa9fv14DBw5UqVKl5O/vr44dO+qPP/741+39m6NHj6p3794KDQ2Vj4+P6tatqzlz5vzresYY9enTR15eXvr000+t9nnz5qlBgwby9fVVSEiIunTpot9++81p3exL/fbu3as777xTfn5+uuGGGzRhwgSnfrndQ5acnKxevXqpXLly8vb2VpkyZdShQ4ccl10uW7bMqolixYopJiZGe/bsyXEc2T9jHx8f1apVS5999tkVvGoFo0OHDvL29tbChQud2ufPn6/7779f7u7uV73NWbNmqUWLFipdurS8vb0VERGh6dOnX9G6c+bMkYeHh1Xn0j/vzzZt2igoKEh+fn5q3ry51q9ff9XjulDFihU1e/ZsnTt3zqkGjh8/rmeeeUa1a9dWQECAAgMD1bZtW+3YscPq8/XXX+uWW26RJPXq1SvHZ+Y333yj++67TxUqVJC3t7fKly+vp59+Wn///fc1jRn4L+MMGVBInThxItd7HDIyMv513REjRig+Pl6PPPKIGjVqpLS0NG3ZskXff/+9WrVqpccee0yHDx9WQkJCjkuojDG6++67tWbNGvXu3Vv16tXTV199pcGDB+v33393urSqZ8+e+uijj9S9e3c1adJEa9euVUxMzCXHdd9996lq1aoaO3asFe4SEhL0yy+/qFevXgoLC9OePXv09ttva8+ePfruu+9y/GL+wAMPqEaNGho3bpyWLFmiMWPGKCQkRG+99ZZatGih8ePH6/3339czzzyjW265RbfffvtlX6tHHnlEc+bM0b333qtBgwZp48aNio+P1w8//GD9Ivjee+/p7bff1qZNm/TOO+9Ikm699dZ//TnkJiUlRbfeeqvOnDmjJ598UiVKlNCcOXN099136+OPP1bHjh1zXe/vv/9Whw4dtGXLFq1cudL6heexxx7T7Nmz1atXLz355JM6ePCg3njjDW3btk3r1693urTsp59+0r333qvevXsrNjZW7777rnr27KkGDRqoZs2alxzzF198IUnq3r37FR3jypUr1bZtW914440aMWKE/v77b02dOlVNmzbV999/n+fJGb799lt9+umneuKJJ1SsWDFNmTJFnTt3VlJSkkqUKKFOnTpp//79+uCDDzRp0iTrjEapUqW0Z88e3XXXXapTp45GjRolb29v/fTTT9f0i2v//v1VvHhxDR8+XIcOHdLkyZPVr18/ffjhh3ne5t9//6077rhDP/30k/r166fw8HAtXLhQPXv2VGpqqp566qlc18vMzNTDDz+sDz/8UJ999pn1Pnz55Zf10ksv6f7779cjjzyiP/74Q1OnTtXtt9+ubdu2OV3W+ddff6lNmzbq1KmT7r//fn388cd67rnnVLt2bbVt2/aSY+7cubP27Nmj/v37q1KlSjp69KgSEhKUlJRk/azfe+89xcbGKjo6WuPHj9eZM2c0ffp0NWvWTNu2bbP6rVixQp07d1ZERITi4+N17NgxK+zZwc/PTx06dNAHH3ygvn37SpJ27NihPXv26J133tHOnTtzXS8jIyPH57efn5/8/Pw0ffp01axZU3fffbc8PDz05Zdf6oknnlBWVpbi4uIuOZa3335bjz/+uF544QWNGTNG0j9/+Gjbtq0aNGig4cOHy83NzQp833zzjRo1apTnY4+MjFTlypWtP+RJ//wxadGiRbrvvvsUHh6ulJQUvfXWW2revLn27t2rsmXLqkaNGho1apSGDRumPn366LbbbpP0f5+ZCxcu1JkzZ9S3b1+VKFFCmzZt0tSpU/W///0vR/AFrhsGQKEya9YsI+myj5o1azqtU7FiRRMbG2s9r1u3romJibnsfuLi4kxuHwGLFi0yksyYMWOc2u+9917jcDjMTz/9ZIwxZuvWrUaSGTBggFO/nj17Gklm+PDhVtvw4cONJNO1a9cc+ztz5kyOtg8++MBIMuvWrcuxjT59+lht58+fN+XKlTMOh8OMGzfOav/rr7+Mr6+v02uSm+3btxtJ5pFHHnFqf+aZZ4wks3r1aqstNjbW+Pv7X3Z7ualZs6Zp3ry59XzAgAFGkvnmm2+stpMnT5rw8HBTqVIlk5mZaYwxZs2aNUaSWbhwoTl58qRp3ry5KVmypNm2bZu13jfffGMkmffff99pn8uXL8/RXrFixRyv6dGjR423t7cZNGjQZY+hY8eORpL566+/ruiY69WrZ0qXLm2OHTtmte3YscO4ubmZHj16WG2xsbGmYsWKOdbP/llfSJLx8vKy6i97m5LM1KlTrbZXXnnFSDIHDx50Wn/SpElGkvnjjz+u6BgudPH7K/s9GhUVZbKysqz2p59+2ri7u5vU1NQr3nZMTIzTazB58mQjycybN89qO3funImMjDQBAQEmLS3NGGPMwYMHjSTzyiuvmIyMDPPAAw8YX19f89VXX1nrHTp0yLi7u5uXX37ZaZ+7du0yHh4eTu3Nmzc3kszcuXOttvT0dBMWFmY6d+5stWXvd9asWcaYf95r2eO4lJMnT5rg4GDz6KOPOrUnJyeboKAgp/Z69eqZMmXKOL2GK1asMJJyrZWLNW/ePMfn48Wy6+tytXDh+2/x4sXG4XCYpKQkY4wxgwcPNjfeeOMl95f9Xrv4kf2ZmNtnXnR0tLXNC7eT/Tn++uuvG4fDYUaPHm0tz8rKMlWrVjXR0dFOdXjmzBkTHh5uWrVqddnX4cIaupQOHToYSebEiRPGGGPOnj1rfUZduB1vb28zatQoq23z5s1OdXKh3I4/Pj7eOBwO8+uvv152zEBRxSWLQCE1bdo0JSQk5HjUqVPnX9cNDg7Wnj17dODAgave79KlS+Xu7q4nn3zSqX3QoEEyxmjZsmWSZF0q9sQTTzj169+//yW3/fjjj+do8/X1tf599uxZ/fnnn2rSpIkk6fvvv8/R/5FHHrH+7e7uroYNG8oYo969e1vtwcHBqlatmn755ZdLjkX651glaeDAgU7t2TfjX8llhFdr6dKlatSokXXJpiQFBASoT58+OnTokPbu3evU/8SJE2rdurV+/PFHff311043yC9cuFBBQUFq1aqV/vzzT+vRoEEDBQQEaM2aNU7bioiIsP5aLf1z5uhKXqe0tDRJUrFixf71+I4cOaLt27erZ8+eCgkJsdrr1KmjVq1aWa95XkRFRaly5cpO2wwMDPzX8UuyzgR9/vnnysrKyvMYLtSnTx+nM7i33XabMjMz9euvv+Z5m0uXLlVYWJi6du1qtXl6eurJJ5/UqVOntHbtWqf+586d03333afFixdr6dKlat26tbXs008/VVZWlu6//36n+ggLC1PVqlVz1EdAQIDTvUReXl5q1KjRZV/f7Psqv/7661zvpZL+OQuempqqrl27Oo3D3d1djRs3tsaRXTuxsbEKCgqy1m/VqpUiIiKu4NUrGK1bt1ZISIgWLFggY4wWLFjg9PPJTePGjXN8dvfo0UOS82de9pUQzZs31y+//KITJ07k2NaECRP01FNPafz48Ro6dKjVvn37dh04cEAPPvigjh07Zr2up0+fVsuWLbVu3bprrvWAgABJ0smTJyX9c3ly9gQ3mZmZOnbsmHX5b26f17m58PhPnz6tP//8U7feequMMdq2bds1jRf4r+KSRaCQatSokRo2bJijvXjx4pedrlmSRo0apQ4dOuimm25SrVq11KZNG3Xv3v2Kwtyvv/6qsmXL5vjlu0aNGtby7P+6ubkpPDzcqV+VKlUuue2L+0r/3JMwcuRILViwQEePHnValtsvJxUqVHB6nj39+oU33Ge3X3wf2sWyj+HiMYeFhSk4OPiafrG+3D4bN26co/3C1/fCabQHDBigs2fPatu2bTkuKzxw4IBOnDih0qVL57qvi1/Pi1876Z96utQv0tkCAwMl/fNL2b/NXJj9mlWrVi3Hsho1auirr77K84QueR2/9M+lru+8844eeeQRPf/882rZsqU6deqke++9N88zKF48nuLFi0vSFY3nUn799VdVrVo1x5gufv9li4+P16lTp7Rs2TLdcccdTssOHDggY4yqVq2a674unimxXLlyOS4RLl68+CUvy5P++QV9/PjxGjRokEJDQ9WkSRPddddd6tGjh8LCwqxxSFKLFi1y3UZ2fWUfW27jvZpf+PObp6en7rvvPs2fP1+NGjXSb7/9pgcffPCy65QsWVJRUVG5Llu/fr2GDx+uxMREnTlzxmnZiRMnnMLo2rVrtWTJEj333HNO941J//e6xsbGXnIcJ06csOoyL06dOiXp//4Yk5WVpddff11vvvmmDh48qMzMTKtviRIlrmibSUlJGjZsmL744osc75XcPvOB6wGBDCiCbr/9dv3888/6/PPPtWLFCr3zzjuaNGmSZsyY4XSGydUu/Mtotvvvv18bNmzQ4MGDVa9ePQUEBCgrK0tt2rTJ9a+7ud1Ef6kb681Fk5BcSmH+XrAOHTpowYIFGjdunObOnev0i3pWVpZKly6t999/P9d1L546Pa+vU/Xq1SVJu3btcjrDdq0u9bpf+Eveha7l5+zr66t169ZpzZo1WrJkiZYvX64PP/xQLVq00IoVK/I0OcO11l1+iI6O1vLlyzVhwgTdcccdTjMgZmVlyeFwaNmyZbmONfvsR7a8Hs+AAQPUvn17LVq0SF999ZVeeuklxcfHa/Xq1apfv771Pn7vvfeskHYhD4/C/6vIgw8+qBkzZmjEiBGqW7duns/Y/fzzz2rZsqWqV6+uiRMnqnz58vLy8tLSpUs1adKkHJ95NWvWVGpqqt577z099thjTn/Uyu77yiuvXHJq+Yt/xldr9+7dKl26tBWax44dq5deekkPP/ywRo8erZCQELm5uWnAgAFXdDYuMzNTrVq10vHjx/Xcc8+pevXq8vf31++//66ePXvm29lr4L+m8H8KAsiTkJAQ9erVS7169dKpU6d0++23a8SIEVYgu9QvwxUrVtTKlSt18uRJp7NkP/74o7U8+79ZWVk6ePCg01+0f/rppyse419//aVVq1Zp5MiRGjZsmNWel0st8yL7GA4cOGCdgZD+mXgjNTXVOtb83ue+fftytF/8+ma755571Lp1a/Xs2VPFihVzmo2tcuXKWrlypZo2bZpr2M0v7du3V3x8vObNm/evgSx7/Jc6xpIlS1pnx4oXL57rFzhfy5nJy4VrNzc3tWzZUi1bttTEiRM1duxYvfjii1qzZs0lz2a4WsWKFbVz505lZWU5he9L1UeTJk30+OOP66677tJ9992nzz77zAo4lStXljFG4eHhuummmwp03JUrV9agQYM0aNAgHThwQPXq1dNrr72mefPmWZeZli5d+rKvc/ax5fb+z62eXKlZs2aqUKGCvv76a40fPz7P2/nyyy+Vnp6uL774wukM68WXj2YrWbKkPv74YzVr1kwtW7bUt99+q7Jly0qS9boGBgYWSP0mJibq559/drqM9eOPP9add96pmTNnOvVNTU11ukrhUu/DXbt2af/+/ZozZ451Cackp4lDgOsR95ABRdDFl+oFBASoSpUqTlO5Z/9SfPEvxO3atVNmZqbeeOMNp/ZJkybJ4XBYs61FR0dLkt58802nflOnTr3icWb/Rf7iv8BPnjz5irdxLdq1a5fr/iZOnChJl50x8lr2uWnTJiUmJlptp0+f1ttvv61KlSrl+pf3Hj16aMqUKZoxY4aee+45q/3+++9XZmamRo8enWOd8+fP5xp28iIyMlJt2rTRO++8o0WLFuVYfu7cOT3zzDOSpDJlyqhevXqaM2eO0/53796tFStWWK+59M8vlCdOnHC6JO7IkSPXNM35per6+PHjOfpmn1W48H1ht3bt2ik5Odlppsbz589r6tSpCggIUPPmzXOsExUVpQULFmj58uXq3r27dZahU6dOcnd318iRI3O8x4wx/3pJ75U4c+aMzp4969RWuXJlFStWzHpdo6OjFRgYqLFjx+Y6S2z2VwVcWDsXXrqWkJCQ495KV3M4HJoyZYqGDx9+xbON5ia3z7wTJ05o1qxZl1ynXLlyWrlypf7++2+1atXK+rk1aNBAlStX1quvvmpdWniha/kKhl9//VU9e/aUl5eX06WS7u7uOWpp4cKF+v33353aLvU+zO34jTF6/fXX8zxWoCjgDBlQBEVEROiOO+5QgwYNFBISoi1btujjjz9Wv379rD4NGjSQJD355JOKjo6Wu7u7unTpovbt2+vOO+/Uiy++qEOHDqlu3bpasWKFPv/8cw0YMMD6q2yDBg3UuXNnTZ48WceOHbOmvd+/f7+kK7sMMDAwULfffrsmTJigjIwM3XDDDVqxYoUOHjxYAK9KTnXr1lVsbKzefvttpaamqnnz5tq0aZPmzJmje+65R3feeWe+7/P555/XBx98oLZt2+rJJ59USEiI5syZo4MHD+qTTz655P1M/fr1U1paml588UUFBQXphRdeUPPmzfXYY48pPj5e27dvV+vWreXp6akDBw5o4cKFev3113Xvvffmy7jnzp2r1q1bq1OnTmrfvr1atmwpf39/HThwQAsWLNCRI0es7yJ75ZVX1LZtW0VGRqp3797WtPdBQUFO30/XpUsXPffcc+rYsaOefPJJayr0m266Kc/3C2XX9YsvvqguXbrI09NT7du316hRo7Ru3TrFxMSoYsWKOnr0qN58802VK1fOaYIVu/Xp00dvvfWWevbsqa1bt6pSpUr6+OOPtX79ek2ePPmSE6vcc889mjVrlnr06KHAwEC99dZbqly5ssaMGaMhQ4bo0KFDuueee1SsWDEdPHhQn332mfr06WMF6bzav3+/WrZsqfvvv18RERHy8PDQZ599ppSUFHXp0kXSP+/z6dOnq3v37rr55pvVpUsXlSpVSklJSVqyZImaNm1q/QEoPj5eMTExatasmR5++GEdP35cU6dOVc2aNXMNHbn5448/rGnhLxQeHq5u3bpZzydOnCg/Pz+nPm5ubpf8broOHTqoQ4cOVzSGS2ndurW8vLzUvn17PfbYYzp16pT+3//7fypdurSOHDlyyfWqVKmiFStW6I477lB0dLRWr16twMBAvfPOO2rbtq1q1qypXr166YYbbtDvv/+uNWvWKDAwUF9++eW/jun777/XvHnzlJWVpdTUVG3evFmffPKJHA6H3nvvPad7j++66y6NGjVKvXr10q233qpdu3bp/fff14033ui0zcqVKys4OFgzZsxQsWLF5O/vr8aNG6t69eqqXLmynnnmGf3+++8KDAzUJ598ck33XQJFgqundQRwedlTam/evDnX5ZeaZvnCabnHjBljGjVqZIKDg42vr6+pXr26efnll825c+esPufPnzf9+/c3pUqVMg6Hw2ma8ZMnT5qnn37alC1b1nh6epqqVauaV155xWlqZWOMOX36tImLizMhISEmICDA3HPPPWbfvn1GktM09JebZvp///uf6dixowkODjZBQUHmvvvuM4cPH77k1PkXb+NS09FfyfTXxhiTkZFhRo4cacLDw42np6cpX768GTJkiDl79uwV7effXDztvTHG/Pzzz+bee+81wcHBxsfHxzRq1MgsXrzYqc+F025f6NlnnzWSzBtvvGG1vf3226ZBgwbG19fXFCtWzNSuXds8++yz5vDhw1afC6fQvlDz5s1zjO9Szpw5Y1599VVzyy23mICAAOPl5WWqVq1q+vfv7zQdvTHGrFy50jRt2tT4+vqawMBA0759e7N3794c21yxYoWpVauW8fLyMtWqVTPz5s275LT3cXFxOda/uPaNMWb06NHmhhtuMG5ubtYU+KtWrTIdOnQwZcuWNV5eXqZs2bKma9euZv/+/f963Jea9v7i92j2z2zNmjX/us1sF097b4wxKSkpplevXqZkyZLGy8vL1K5dO8f04ZeasvzNN980kswzzzxjtX3yySemWbNmxt/f3/j7+5vq1aubuLg4s2/fPqvPpd4vF381wcXT3v/5558mLi7OVK9e3fj7+5ugoCDTuHFj89FHH+XY1po1a0x0dLQJCgoyPj4+pnLlyqZnz55my5YtTv0++eQTU6NGDePt7W0iIiLMp59+esmvSLhY9vT9uT1atmxpjPm/z5LcHu7u7tZYc3v/5ba/3D6PL/e1I1988YWpU6eO8fHxMZUqVTLjx4837777bo6va8htOxs3bjTFihUzt99+uzV9/LZt20ynTp1MiRIljLe3t6lYsaK5//77zapVqy479uyfZfbDw8PDhISEmMaNG5shQ4bkOgX92bNnzaBBg0yZMmWMr6+vadq0qUlMTMz1c+Tzzz83ERERxsPDw6lm9u7da6KiokxAQIApWbKkefTRR62vsMhtmnzgeuAwxoV3HwMo8rZv36769etr3rx5Tn+NBgAAQE7cQwYgz/7+++8cbZMnT5abm5tuv/12G0YEAADw38I9ZADybMKECdq6davuvPNOeXh4aNmyZVq2bJn69Omj8uXL2z08AACAQo9LFgHkWUJCgkaOHKm9e/fq1KlTqlChgrp3764XX3zxP/HdQgAAAHYjkAEAAACATbiHDAAAAABsQiADAAAAAJtwk4ekrKwsHT58WMWKFbuiL7MFAAAAUDQZY3Ty5EmVLVtWbm4Ff/6KQCbp8OHDzAgHAAAAwPLbb7+pXLlyBb4fApmkYsWKSZIOHjyokJAQm0eDoiwjI0MrVqxQ69at5enpafdwUIRRa3AVag2uQq3BVY4fP67w8HArIxQ0AplkXaZYrFgxBQYG2jwaFGUZGRny8/NTYGAg/zNBgaLW4CrUGlyFWoOrZGRkSJLLbmViUg8AAAAAsAmBDAAAAABsQiADAAAAAJsQyAAAAADAJgQyAAAAALAJgQwAAAAAbEIgAwAAAACbEMgAAAAAwCYEMgAAAACwCYEMAAAAAGxCIAMAAAAAmxDIAAAAAMAmBDIAAAAAsAmBDAAAAABsQiADAAAAAJvYGsgyMzP10ksvKTw8XL6+vqpcubJGjx4tY4zVxxijYcOGqUyZMvL19VVUVJQOHDjgtJ3jx4+rW7duCgwMVHBwsHr37q1Tp065+nAAAAAA4KrYGsjGjx+v6dOn64033tAPP/yg8ePHa8KECZo6darVZ8KECZoyZYpmzJihjRs3yt/fX9HR0Tp79qzVp1u3btqzZ48SEhK0ePFirVu3Tn369LHjkAAAAADginnYufMNGzaoQ4cOiomJkSRVqlRJH3zwgTZt2iTpn7NjkydP1tChQ9WhQwdJ0ty5cxUaGqpFixapS5cu+uGHH7R8+XJt3rxZDRs2lCRNnTpV7dq106uvvqqyZcvac3AAAAAA8C9sDWS33nqr3n77be3fv1833XSTduzYoW+//VYTJ06UJB08eFDJycmKioqy1gkKClLjxo2VmJioLl26KDExUcHBwVYYk6SoqCi5ublp48aN6tixY479pqenKz093XqelpYmScrIyFBGRkZBHS5g1Rd1hoJGrcFVqDW4CrUGV3F1jdkayJ5//nmlpaWpevXqcnd3V2Zmpl5++WV169ZNkpScnCxJCg0NdVovNDTUWpacnKzSpUs7Lffw8FBISIjV52Lx8fEaOXJkjvY1a9bIz8/vmo8L+DcJCQl2DwHXCWoNrkKtwVWoNRS0M2fOuHR/tgayjz76SO+//77mz5+vmjVravv27RowYIDKli2r2NjYAtvvkCFDNHDgQOt5WlqaypcvrzHb3HTe0/2at797RPQ1bwNFU0ZGhhISEtSqVSt5enraPRwUYdQaXIVag6tQa3CVY8eOuXR/tgaywYMH6/nnn1eXLl0kSbVr19avv/6q+Ph4xcbGKiwsTJKUkpKiMmXKWOulpKSoXr16kqSwsDAdPXrUabvnz5/X8ePHrfUv5u3tLW9v7xzt6VkOnc90XPNx8SGBf+Pp6UmdwCWoNbgKtQZXodZQ0FxdX7bOsnjmzBm5uTkPwd3dXVlZWZKk8PBwhYWFadWqVdbytLQ0bdy4UZGRkZKkyMhIpaamauvWrVaf1atXKysrS40bN3bBUQAAAABA3th6hqx9+/Z6+eWXVaFCBdWsWVPbtm3TxIkT9fDDD0uSHA6HBgwYoDFjxqhq1aoKDw/XSy+9pLJly+qee+6RJNWoUUNt2rTRo48+qhkzZigjI0P9+vVTly5dmGERAAAAQKFmayCbOnWqXnrpJT3xxBM6evSoypYtq8cee0zDhg2z+jz77LM6ffq0+vTpo9TUVDVr1kzLly+Xj4+P1ef9999Xv3791LJlS7m5ualz586aMmWKHYcEAAAAAFfM1kBWrFgxTZ48WZMnT75kH4fDoVGjRmnUqFGX7BMSEqL58+cXwAgBAAAAoODYeg8ZAAAAAFzPCGQAAAAAYBMCGQAAAADYhEAGAAAAADYhkAEAAACATQhkAAAAAGATAhkAAAAA2IRABgAAAAA2IZABAAAAgE0IZAAAAABgEwIZAAAAANiEQAYAAAAANiGQAQAAAIBNCGQAAAAAYBMCGQAAAADYhEAGAAAAADYhkAEAAACATQhkAAAAAGATAhkAAAAA2IRABgAAAAA2IZABAAAAgE0IZAAAAABgEwIZAAAAANiEQAYAAAAANiGQAQAAAIBNCGQAAAAAYBMCGQAAAADYhEAGAAAAADYhkAEAAACATQhkAAAAAGATAhkAAAAA2IRABgAAAAA2IZABAAAAgE0IZAAAAABgEwIZAAAAANiEQAYAAAAANiGQAQAAAIBNCGQAAAAAYBMCGQAAAADYhEAGAAAAADYhkAEAAACATQhkAAAAAGATAhkAAAAA2IRABgAAAAA2sTWQVapUSQ6HI8cjLi5OknT27FnFxcWpRIkSCggIUOfOnZWSkuK0jaSkJMXExMjPz0+lS5fW4MGDdf78eTsOBwAAAACuiq2BbPPmzTpy5Ij1SEhIkCTdd999kqSnn35aX375pRYuXKi1a9fq8OHD6tSpk7V+ZmamYmJidO7cOW3YsEFz5szR7NmzNWzYMFuOBwAAAACuhq2BrFSpUgoLC7MeixcvVuXKldW8eXOdOHFCM2fO1MSJE9WiRQs1aNBAs2bN0oYNG/Tdd99JklasWKG9e/dq3rx5qlevntq2bavRo0dr2rRpOnfunJ2HBgAAAAD/ysPuAWQ7d+6c5s2bp4EDB8rhcGjr1q3KyMhQVFSU1ad69eqqUKGCEhMT1aRJEyUmJqp27doKDQ21+kRHR6tv377as2eP6tevn+u+0tPTlZ6ebj1PS0uTJHm7Gbm7m2s+loyMjGveBoqm7NqgRlDQqDW4CrUGV6HW4CqurrFCE8gWLVqk1NRU9ezZU5KUnJwsLy8vBQcHO/ULDQ1VcnKy1efCMJa9PHvZpcTHx2vkyJE52ofWz5KfX+Y1HMU/li5des3bQNGWfXkuUNCoNbgKtQZXodZQ0M6cOePS/RWaQDZz5ky1bdtWZcuWLfB9DRkyRAMHDrSep6WlqXz58hqzzU3nPd2vefu7R0Rf8zZQNGVkZCghIUGtWrWSp6en3cNBEUatwVWoNbgKtQZXOXbsmEv3VygC2a+//qqVK1fq008/tdrCwsJ07tw5paamOp0lS0lJUVhYmNVn06ZNTtvKnoUxu09uvL295e3tnaM9Pcuh85mOazkUSeJDAv/K09OTOoFLUGtwFWoNrkKtoaC5ur4KxfeQzZo1S6VLl1ZMTIzV1qBBA3l6emrVqlVW2759+5SUlKTIyEhJUmRkpHbt2qWjR49afRISEhQYGKiIiAjXHQAAAAAA5IHtZ8iysrI0a9YsxcbGysPj/4YTFBSk3r17a+DAgQoJCVFgYKD69++vyMhINWnSRJLUunVrRUREqHv37powYYKSk5M1dOhQxcXF5XoGDAAAAAAKE9sD2cqVK5WUlKSHH344x7JJkybJzc1NnTt3Vnp6uqKjo/Xmm29ay93d3bV48WL17dtXkZGR8vf3V2xsrEaNGuXKQwAAAACAPLE9kLVu3VrG5D7VvI+Pj6ZNm6Zp06Zdcv2KFSsyqyEAAACA/6RCcQ8ZAAAAAFyPCGQAAAAAYBMCGQAAAADYhEAGAAAAADYhkAEAAACATQhkAAAAAGATAhkAAAAA2IRABgAAAAA2IZABAAAAgE0IZAAAAABgEwIZAAAAANiEQAYAAAAANiGQAQAAAIBNCGQAAAAAYBMCGQAAAADYhEAGAAAAADYhkAEAAACATQhkAAAAAGATAhkAAAAA2IRABgAAAAA2IZABAAAAgE0IZAAAAABgEwIZAAAAANiEQAYAAAAANiGQAQAAAIBNCGQAAAAAYBMCGQAAAADYhEAGAAAAADYhkAEAAACATQhkAAAAAGATAhkAAAAA2IRABgAAAAA2IZABAAAAgE0IZAAAAABgEwIZAAAAANiEQAYAAAAANiGQAQAAAIBNCGQAAAAAYBMCGQAAAADYhEAGAAAAADYhkAEAAACATQhkAAAAAGATAhkAAAAA2IRABgAAAAA2sT2Q/f7773rooYdUokQJ+fr6qnbt2tqyZYu13BijYcOGqUyZMvL19VVUVJQOHDjgtI3jx4+rW7duCgwMVHBwsHr37q1Tp065+lAAAAAA4KrYGsj++usvNW3aVJ6enlq2bJn27t2r1157TcWLF7f6TJgwQVOmTNGMGTO0ceNG+fv7Kzo6WmfPnrX6dOvWTXv27FFCQoIWL16sdevWqU+fPnYcEgAAAABcMQ87dz5+/HiVL19es2bNstrCw8OtfxtjNHnyZA0dOlQdOnSQJM2dO1ehoaFatGiRunTpoh9++EHLly/X5s2b1bBhQ0nS1KlT1a5dO7366qsqW7asaw8KAAAAAK6QrYHsiy++UHR0tO677z6tXbtWN9xwg5544gk9+uijkqSDBw8qOTlZUVFR1jpBQUFq3LixEhMT1aVLFyUmJio4ONgKY5IUFRUlNzc3bdy4UR07dsyx3/T0dKWnp1vP09LSJEnebkbu7uaajysjI+Oat4GiKbs2qBEUNGoNrkKtwVWoNbiKq2vM1kD2yy+/aPr06Ro4cKBeeOEFbd68WU8++aS8vLwUGxur5ORkSVJoaKjTeqGhoday5ORklS5d2mm5h4eHQkJCrD4Xi4+P18iRI3O0D62fJT+/zGs+rqVLl17zNlC0JSQk2D0EXCeoNbgKtQZXodZQ0M6cOePS/dkayLKystSwYUONHTtWklS/fn3t3r1bM2bMUGxsbIHtd8iQIRo4cKD1PC0tTeXLl9eYbW467+l+zdvfPSL6mreBoikjI0MJCQlq1aqVPD097R4OijBqDa5CrcFVqDW4yrFjx1y6P1sDWZkyZRQREeHUVqNGDX3yySeSpLCwMElSSkqKypQpY/VJSUlRvXr1rD5Hjx512sb58+d1/Phxa/2LeXt7y9vbO0d7epZD5zMdeT6ebHxI4N94enpSJ3AJag2uQq3BVag1FDRX15etsyw2bdpU+/btc2rbv3+/KlasKOmfCT7CwsK0atUqa3laWpo2btyoyMhISVJkZKRSU1O1detWq8/q1auVlZWlxo0bu+AoAAAAACBvbD1D9vTTT+vWW2/V2LFjdf/992vTpk16++239fbbb0uSHA6HBgwYoDFjxqhq1aoKDw/XSy+9pLJly+qee+6R9M8ZtTZt2ujRRx/VjBkzlJGRoX79+qlLly7MsAgAAACgULM1kN1yyy367LPPNGTIEI0aNUrh4eGaPHmyunXrZvV59tlndfr0afXp00epqalq1qyZli9fLh8fH6vP+++/r379+qlly5Zyc3NT586dNWXKFDsOCQAAAACumK2BTJLuuusu3XXXXZdc7nA4NGrUKI0aNeqSfUJCQjR//vyCGB4AAAAAFBhb7yEDAAAAgOsZgQwAAAAAbEIgAwAAAACbEMgAAAAAwCYEMgAAAACwCYEMAAAAAGxCIAMAAAAAmxDIAAAAAMAmBDIAAAAAsAmBDAAAAABsQiADAAAAAJsQyAAAAADAJgQyAAAAALAJgQwAAAAAbEIgAwAAAACbEMgAAAAAwCYEMgAAAACwCYEMAAAAAGxCIAMAAAAAmxDIAAAAAMAmBDIAAAAAsAmBDAAAAABsQiADAAAAAJsQyAAAAADAJgQyAAAAALAJgQwAAAAAbEIgAwAAAACbEMgAAAAAwCYEMgAAAACwCYEMAAAAAGxCIAMAAAAAmxDIAAAAAMAmBDIAAAAAsImH3QMoiio9vyTftnVoXEy+bQsAAABA4cIZMgAAAACwCYEMAAAAAGxCIAMAAAAAmxDIAAAAAMAmBDIAAAAAsAmBDAAAAABsQiADAAAAAJsQyAAAAADAJgQyAAAAALAJgQwAAAAAbGJrIBsxYoQcDofTo3r16tbys2fPKi4uTiVKlFBAQIA6d+6slJQUp20kJSUpJiZGfn5+Kl26tAYPHqzz58+7+lAAAAAA4Kp52D2AmjVrauXKldZzD4//G9LTTz+tJUuWaOHChQoKClK/fv3UqVMnrV+/XpKUmZmpmJgYhYWFacOGDTpy5Ih69OghT09PjR071uXHAgAAAABXw/ZA5uHhobCwsBztJ06c0MyZMzV//ny1aNFCkjRr1izVqFFD3333nZo0aaIVK1Zo7969WrlypUJDQ1WvXj2NHj1azz33nEaMGCEvLy9XHw4AAAAAXDHbA9mBAwdUtmxZ+fj4KDIyUvHx8apQoYK2bt2qjIwMRUVFWX2rV6+uChUqKDExUU2aNFFiYqJq166t0NBQq090dLT69u2rPXv2qH79+rnuMz09Xenp6dbztLQ0SZK3m5G7uymgI82bjIwMu4eAfJT98+TnioJGrcFVqDW4CrUGV3F1jdkayBo3bqzZs2erWrVqOnLkiEaOHKnbbrtNu3fvVnJysry8vBQcHOy0TmhoqJKTkyVJycnJTmEse3n2skuJj4/XyJEjc7QPrZ8lP7/Mazyq/LV06VK7h4ACkJCQYPcQcJ2g1uAq1BpchVpDQTtz5oxL92drIGvbtq317zp16qhx48aqWLGiPvroI/n6+hbYfocMGaKBAwdaz9PS0lS+fHmN2eam857uBbbfvNg9ItruISAfZWRkKCEhQa1atZKnp6fdw0ERRq3BVag1uAq1Blc5duyYS/dn+yWLFwoODtZNN92kn376Sa1atdK5c+eUmprqdJYsJSXFuucsLCxMmzZtctpG9iyMud2Xls3b21ve3t452tOzHDqf6ciHI8k/fOAUTZ6envxs4RLUGlyFWoOrUGsoaK6ur0L1PWSnTp3Szz//rDJlyqhBgwby9PTUqlWrrOX79u1TUlKSIiMjJUmRkZHatWuXjh49avVJSEhQYGCgIiIiXD5+AAAAALgatp4he+aZZ9S+fXtVrFhRhw8f1vDhw+Xu7q6uXbsqKChIvXv31sCBAxUSEqLAwED1799fkZGRatKkiSSpdevWioiIUPfu3TVhwgQlJydr6NChiouLy/UMGAAAAAAUJrYGsv/973/q2rWrjh07plKlSqlZs2b67rvvVKpUKUnSpEmT5Obmps6dOys9PV3R0dF68803rfXd3d21ePFi9e3bV5GRkfL391dsbKxGjRpl1yEBAAAAwBWzNZAtWLDgsst9fHw0bdo0TZs27ZJ9KlasyEyEAAAAAP6TCtU9ZAAAAABwPSGQAQAAAIBNCGQAAAAAYBMCGQAAAADYJE+B7JdffsnvcQAAAADAdSdPgaxKlSq68847NW/ePJ09eza/xwQAAAAA14U8BbLvv/9ederU0cCBAxUWFqbHHntMmzZtyu+xAQAAAECRlqdAVq9ePb3++us6fPiw3n33XR05ckTNmjVTrVq1NHHiRP3xxx/5PU4AAAAAKHKuaVIPDw8PderUSQsXLtT48eP1008/6ZlnnlH58uXVo0cPHTlyJL/GCQAAAABFzjUFsi1btuiJJ55QmTJlNHHiRD3zzDP6+eeflZCQoMOHD6tDhw75NU4AAAAAKHI88rLSxIkTNWvWLO3bt0/t2rXT3Llz1a5dO7m5/ZPvwsPDNXv2bFWqVCk/xwoAAAAARUqeAtn06dP18MMPq2fPnipTpkyufUqXLq2ZM2de0+AAAAAAoCjLUyA7cODAv/bx8vJSbGxsXjYPAAAAANeFPN1DNmvWLC1cuDBH+8KFCzVnzpxrHhQAAAAAXA/yFMji4+NVsmTJHO2lS5fW2LFjr3lQAAAAAHA9yFMgS0pKUnh4eI72ihUrKikp6ZoHBQAAAADXgzwFstKlS2vnzp052nfs2KESJUpc86AAAAAA4HqQp0DWtWtXPfnkk1qzZo0yMzOVmZmp1atX66mnnlKXLl3ye4wAAAAAUCTlaZbF0aNH69ChQ2rZsqU8PP7ZRFZWlnr06ME9ZAAAAABwhfIUyLy8vPThhx9q9OjR2rFjh3x9fVW7dm1VrFgxv8cHAAAAAEVWngJZtptuukk33XRTfo0FAAAAAK4reQpkmZmZmj17tlatWqWjR48qKyvLafnq1avzZXAAAAAAUJTlKZA99dRTmj17tmJiYlSrVi05HI78HhcAAAAAFHl5CmQLFizQRx99pHbt2uX3eAAAAADgupGnae+9vLxUpUqV/B4LAAAAAFxX8hTIBg0apNdff13GmPweDwAAAABcN/J0yeK3336rNWvWaNmyZapZs6Y8PT2dln/66af5MjgAAAAAKMryFMiCg4PVsWPH/B4LAAAAAFxX8hTIZs2ald/jAAAAAIDrTp7uIZOk8+fPa+XKlXrrrbd08uRJSdLhw4d16tSpfBscAAAAABRleTpD9uuvv6pNmzZKSkpSenq6WrVqpWLFimn8+PFKT0/XjBkz8nucAAAAAFDk5OkM2VNPPaWGDRvqr7/+kq+vr9XesWNHrVq1Kt8GBwAAAABFWZ7OkH3zzTfasGGDvLy8nNorVaqk33//PV8GBgAAAABFXZ7OkGVlZSkzMzNH+//+9z8VK1bsmgcFAAAAANeDPAWy1q1ba/LkydZzh8OhU6dOafjw4WrXrl1+jQ0AAAAAirQ8XbL42muvKTo6WhERETp79qwefPBBHThwQCVLltQHH3yQ32MEAAAAgCIpT4GsXLly2rFjhxYsWKCdO3fq1KlT6t27t7p16+Y0yQcAAAAA4NLyFMgkycPDQw899FB+jgUAAAAArit5CmRz58697PIePXrkaTAAAAAAcD3JUyB76qmnnJ5nZGTozJkz8vLykp+fH4EMAAAAAK5AnmZZ/Ouvv5wep06d0r59+9SsWTMm9QAAAACAK5SnQJabqlWraty4cTnOngEAAAAAcpdvgUz6Z6KPw4cP5+cmAQAAAKDIytM9ZF988YXTc2OMjhw5ojfeeENNmzbNl4EBAAAAQFGXpzNk99xzj9OjU6dOGjFihOrUqaN33303TwMZN26cHA6HBgwYYLWdPXtWcXFxKlGihAICAtS5c2elpKQ4rZeUlKSYmBj5+fmpdOnSGjx4sM6fP5+nMQAAAACAK+XpDFlWVla+DmLz5s166623VKdOHaf2p59+WkuWLNHChQsVFBSkfv36qVOnTlq/fr0kKTMzUzExMQoLC9OGDRt05MgR9ejRQ56enho7dmy+jhEAAAAA8lu+3kOWF6dOnVK3bt30//7f/1Px4sWt9hMnTmjmzJmaOHGiWrRooQYNGmjWrFnasGGDvvvuO0nSihUrtHfvXs2bN0/16tVT27ZtNXr0aE2bNk3nzp2z65AAAAAA4Irk6QzZwIEDr7jvxIkTL7s8Li5OMTExioqK0pgxY6z2rVu3KiMjQ1FRUVZb9erVVaFCBSUmJqpJkyZKTExU7dq1FRoaavWJjo5W3759tWfPHtWvXz/Xfaanpys9Pd16npaWJknydjNydzdXfGyukJGRYfcQkI+yf578XFHQqDW4CrUGV6HW4CqurrE8BbJt27Zp27ZtysjIULVq1SRJ+/fvl7u7u26++Warn8PhuOx2FixYoO+//16bN2/OsSw5OVleXl4KDg52ag8NDVVycrLV58Iwlr08e9mlxMfHa+TIkTnah9bPkp9f5mXH7GpLly61ewgoAAkJCXYPAdcJag2uQq3BVag1FLQzZ864dH95CmTt27dXsWLFNGfOHOsyw7/++ku9evXSbbfdpkGDBv3rNn777Tc99dRTSkhIkI+PT16GkWdDhgxxOsuXlpam8uXLa8w2N533dHfpWP7N7hHRdg8B+SgjI0MJCQlq1aqVPD097R4OijBqDa5CrcFVqDW4yrFjx1y6vzwFstdee00rVqxwuuerePHiGjNmjFq3bn1FgWzr1q06evSo0xm1zMxMrVu3Tm+88Ya++uornTt3TqmpqU5nyVJSUhQWFiZJCgsL06ZNm5y2mz0LY3af3Hh7e8vb2ztHe3qWQ+czL39Wz9X4wCmaPD09+dnCJag1uAq1Bleh1lDQXF1feZrUIy0tTX/88UeO9j/++EMnT568om20bNlSu3bt0vbt261Hw4YN1a1bN+vfnp6eWrVqlbXOvn37lJSUpMjISElSZGSkdu3apaNHj1p9EhISFBgYqIiIiLwcGgAAAAC4TJ7OkHXs2FG9evXSa6+9pkaNGkmSNm7cqMGDB6tTp05XtI1ixYqpVq1aTm3+/v4qUaKE1d67d28NHDhQISEhCgwMVP/+/RUZGakmTZpIklq3bq2IiAh1795dEyZMUHJysoYOHaq4uLhcz4ABAAAAQGGSp0A2Y8YMPfPMM3rwwQetWUg8PDzUu3dvvfLKK/k2uEmTJsnNzU2dO3dWenq6oqOj9eabb1rL3d3dtXjxYvXt21eRkZHy9/dXbGysRo0alW9jAAAAAICCkqdA5ufnpzfffFOvvPKKfv75Z0lS5cqV5e/vf02D+frrr52e+/j4aNq0aZo2bdol16lYsSIzEQIAAAD4T7qmL4Y+cuSIjhw5oqpVq8rf31/GFK7v8AIAAACAwixPgezYsWNq2bKlbrrpJrVr105HjhyR9M89X1cywyIAAAAAII+B7Omnn5anp6eSkpLk5+dntT/wwANavnx5vg0OAAAAAIqyPN1DtmLFCn311VcqV66cU3vVqlX166+/5svAAAAAAKCoy9MZstOnTzudGct2/PhxppsHAAAAgCuUp0B22223ae7cudZzh8OhrKwsTZgwQXfeeWe+DQ4AAAAAirI8XbI4YcIEtWzZUlu2bNG5c+f07LPPas+ePTp+/LjWr1+f32MEAAAAgCIpT2fIatWqpf3796tZs2bq0KGDTp8+rU6dOmnbtm2qXLlyfo8RAAAAAIqkqz5DlpGRoTZt2mjGjBl68cUXC2JMAAAAAHBduOozZJ6entq5c2dBjAUAAAAArit5umTxoYce0syZM/N7LAAAAABwXcnTpB7nz5/Xu+++q5UrV6pBgwby9/d3Wj5x4sR8GRwAAAAAFGVXFch++eUXVapUSbt379bNN98sSdq/f79TH4fDkX+jAwAAAIAi7KoCWdWqVXXkyBGtWbNGkvTAAw9oypQpCg0NLZDBAQAAAEBRdlX3kBljnJ4vW7ZMp0+fztcBAQAAAMD1Ik+TemS7OKABAAAAAK7cVQUyh8OR4x4x7hkDAAAAgLy5qnvIjDHq2bOnvL29JUlnz57V448/nmOWxU8//TT/RggAAAAARdRVBbLY2Fin5w899FC+DgYAAAAAridXFchmzZpVUOMAAAAAgOvONU3qAQAAAADIOwIZAAAAANiEQAYAAAAANiGQAQAAAIBNCGQAAAAAYBMCGQAAAADYhEAGAAAAADYhkAEAAACATQhkAAAAAGATAhkAAAAA2IRABgAAAAA2IZABAAAAgE0IZAAAAABgEwIZAAAAANiEQAYAAAAANiGQAQAAAIBNCGQAAAAAYBMCGQAAAADYhEAGAAAAADYhkAEAAACATQhkAAAAAGATAhkAAAAA2IRABgAAAAA2IZABAAAAgE1sDWTTp09XnTp1FBgYqMDAQEVGRmrZsmXW8rNnzyouLk4lSpRQQECAOnfurJSUFKdtJCUlKSYmRn5+fipdurQGDx6s8+fPu/pQAAAAAOCq2RrIypUrp3Hjxmnr1q3asmWLWrRooQ4dOmjPnj2SpKefflpffvmlFi5cqLVr1+rw4cPq1KmTtX5mZqZiYmJ07tw5bdiwQXPmzNHs2bM1bNgwuw4JAAAAAK6Yh507b9++vdPzl19+WdOnT9d3332ncuXKaebMmZo/f75atGghSZo1a5Zq1Kih7777Tk2aNNGKFSu0d+9erVy5UqGhoapXr55Gjx6t5557TiNGjJCXl5cdhwUAAAAAV8TWQHahzMxMLVy4UKdPn1ZkZKS2bt2qjIwMRUVFWX2qV6+uChUqKDExUU2aNFFiYqJq166t0NBQq090dLT69u2rPXv2qH79+rnuKz09Xenp6dbztLQ0SZK3m5G7uymgI8ybjIwMu4eAfJT98+TnioJGrcFVqDW4CrUGV3F1jdkeyHbt2qXIyEidPXtWAQEB+uyzzxQREaHt27fLy8tLwcHBTv1DQ0OVnJwsSUpOTnYKY9nLs5ddSnx8vEaOHJmjfWj9LPn5ZV7jEeWvpUuX2j0EFICEhAS7h4DrBLUGV6HW4CrUGgramTNnXLo/2wNZtWrVtH37dp04cUIff/yxYmNjtXbt2gLd55AhQzRw4EDreVpamsqXL68x29x03tO9QPd9tXaPiLZ7CMhHGRkZSkhIUKtWreTp6Wn3cFCEUWtwFWoNrkKtwVWOHTvm0v3ZHsi8vLxUpUoVSVKDBg20efNmvf7663rggQd07tw5paamOp0lS0lJUVhYmCQpLCxMmzZtctpe9iyM2X1y4+3tLW9v7xzt6VkOnc90XOsh5Ss+cIomT09PfrZwCWoNrkKtwVWoNRQ0V9dXofsesqysLKWnp6tBgwby9PTUqlWrrGX79u1TUlKSIiMjJUmRkZHatWuXjh49avVJSEhQYGCgIiIiXD52AAAAALgatp4hGzJkiNq2basKFSro5MmTmj9/vr7++mt99dVXCgoKUu/evTVw4ECFhIQoMDBQ/fv3V2RkpJo0aSJJat26tSIiItS9e3dNmDBBycnJGjp0qOLi4nI9AwYAAAAAhYmtgezo0aPq0aOHjhw5oqCgINWpU0dfffWVWrVqJUmaNGmS3Nzc1LlzZ6Wnpys6Olpvvvmmtb67u7sWL16svn37KjIyUv7+/oqNjdWoUaPsOiQAAAAAuGK2BrKZM2dedrmPj4+mTZumadOmXbJPxYoVmYkQAAAAwH9SobuHDAAAAACuFwQyAAAAALAJgQwAAAAAbGL795Dh8io9vyRft3doXEy+bg8AAABA3nGGDAAAAABsQiADAAAAAJsQyAAAAADAJgQyAAAAALAJgQwAAAAAbEIgAwAAAACbEMgAAAAAwCYEMgAAAACwCYEMAAAAAGxCIAMAAAAAmxDIAAAAAMAmBDIAAAAAsAmBDAAAAABsQiADAAAAAJsQyAAAAADAJgQyAAAAALAJgQwAAAAAbEIgAwAAAACbEMgAAAAAwCYEMgAAAACwCYEMAAAAAGxCIAMAAAAAmxDIAAAAAMAmBDIAAAAAsAmBDAAAAABsQiADAAAAAJsQyAAAAADAJgQyAAAAALAJgQwAAAAAbEIgAwAAAACbEMgAAAAAwCYEMgAAAACwCYEMAAAAAGxCIAMAAAAAmxDIAAAAAMAmBDIAAAAAsAmBDAAAAABsQiADAAAAAJsQyAAAAADAJgQyAAAAALCJh507j4+P16effqoff/xRvr6+uvXWWzV+/HhVq1bN6nP27FkNGjRICxYsUHp6uqKjo/Xmm28qNDTU6pOUlKS+fftqzZo1CggIUGxsrOLj4+XhYevhFXmVnl+Sr9s7NC4mX7cHAAAAFHa2niFbu3at4uLi9N133ykhIUEZGRlq3bq1Tp8+bfV5+umn9eWXX2rhwoVau3atDh8+rE6dOlnLMzMzFRMTo3PnzmnDhg2aM2eOZs+erWHDhtlxSAAAAABwxWw9hbR8+XKn57Nnz1bp0qW1detW3X777Tpx4oRmzpyp+fPnq0WLFpKkWbNmqUaNGvruu+/UpEkTrVixQnv37tXKlSsVGhqqevXqafTo0Xruuec0YsQIeXl52XFoAAAAAPCvCtU1fSdOnJAkhYSESJK2bt2qjIwMRUVFWX2qV6+uChUqKDExUU2aNFFiYqJq167tdAljdHS0+vbtqz179qh+/fo59pOenq709HTreVpamiTJ283I3d0UyLEVFhkZGfm2Le98fq3yc2yFVfYxXg/HCntRa3AVag2uQq3BVVxdY4UmkGVlZWnAgAFq2rSpatWqJUlKTk6Wl5eXgoODnfqGhoYqOTnZ6nNhGMtenr0sN/Hx8Ro5cmSO9qH1s+Tnl3mth1KoLV26NN+2NaFRvm1KUv6OrbBLSEiwewi4TlBrcBVqDa5CraGgnTlzxqX7KzSBLC4uTrt379a3335b4PsaMmSIBg4caD1PS0tT+fLlNWabm857uhf4/u20e0R0vm2r1oiv8m1bUv6OrbDKyMhQQkKCWrVqJU9PT7uHgyKMWoOrUGtwFWoNrnLs2DGX7q9QBLJ+/fpp8eLFWrduncqVK2e1h4WF6dy5c0pNTXU6S5aSkqKwsDCrz6ZNm5y2l5KSYi3Ljbe3t7y9vXO0p2c5dD7Tca2HU6jl5wdYej6/VtfTh6unp+d1dbywD7UGV6HW4CrUGgqaq+vL1lkWjTHq16+fPvvsM61evVrh4eFOyxs0aCBPT0+tWrXKatu3b5+SkpIUGRkpSYqMjNSuXbt09OhRq09CQoICAwMVERHhmgMBAAAAgDyw9QxZXFyc5s+fr88//1zFihWz7vkKCgqSr6+vgoKC1Lt3bw0cOFAhISEKDAxU//79FRkZqSZNmkiSWrdurYiICHXv3l0TJkxQcnKyhg4dqri4uFzPggEAAABAYWFrIJs+fbok6Y477nBqnzVrlnr27ClJmjRpktzc3NS5c2enL4bO5u7ursWLF6tv376KjIyUv7+/YmNjNWrUKFcdBgAAAADkia2BzJh/nzbdx8dH06ZN07Rp0y7Zp2LFitfVDH0AAAAAigZb7yEDAAAAgOsZgQwAAAAAbEIgAwAAAACbEMgAAAAAwCYEMgAAAACwCYEMAAAAAGxCIAMAAAAAmxDIAAAAAMAmBDIAAAAAsAmBDAAAAABsQiADAAAAAJsQyAAAAADAJgQyAAAAALAJgQwAAAAAbOJh9wDgWpWeX2L3EAAAAAD8/zhDBgAAAAA2IZABAAAAgE0IZAAAAABgEwIZAAAAANiEQAYAAAAANiGQAQAAAIBNCGQAAAAAYBMCGQAAAADYhEAGAAAAADYhkAEAAACATQhkAAAAAGATAhkAAAAA2IRABgAAAAA2IZABAAAAgE0IZAAAAABgEwIZAAAAANiEQAYAAAAANiGQAQAAAIBNCGQAAAAAYBMCGQAAAADYhEAGAAAAADYhkAEAAACATQhkAAAAAGATAhkAAAAA2IRABgAAAAA2IZABAAAAgE0IZAAAAABgEwIZAAAAANiEQAYAAAAANrE1kK1bt07t27dX2bJl5XA4tGjRIqflxhgNGzZMZcqUka+vr6KionTgwAGnPsePH1e3bt0UGBio4OBg9e7dW6dOnXLhUQAAAABA3tgayE6fPq26detq2rRpuS6fMGGCpkyZohkzZmjjxo3y9/dXdHS0zp49a/Xp1q2b9uzZo4SEBC1evFjr1q1Tnz59XHUIAAAAAJBnHnbuvG3btmrbtm2uy4wxmjx5soYOHaoOHTpIkubOnavQ0FAtWrRIXbp00Q8//KDly5dr8+bNatiwoSRp6tSpateunV599VWVLVvWZccCAAAAAFfL1kB2OQcPHlRycrKioqKstqCgIDVu3FiJiYnq0qWLEhMTFRwcbIUxSYqKipKbm5s2btyojh075rrt9PR0paenW8/T0tIkSd5uRu7upoCOCP8mIyPD7iEUuOxjvB6OFfai1uAq1BpchVqDq7i6xgptIEtOTpYkhYaGOrWHhoZay5KTk1W6dGmn5R4eHgoJCbH65CY+Pl4jR47M0T60fpb8/DKvdejIo6VLl9o9BJdJSEiwewi4TlBrcBVqDa5CraGgnTlzxqX7K7SBrCANGTJEAwcOtJ6npaWpfPnyGrPNTec93W0c2fVt94hou4dQ4DIyMpSQkKBWrVrJ09PT7uGgCKPW4CrUGlyFWoOrHDt2zKX7K7SBLCwsTJKUkpKiMmXKWO0pKSmqV6+e1efo0aNO650/f17Hjx+31s+Nt7e3vL29c7SnZzl0PtORD6NHXlxPH66enp7X1fHCPtQaXIVag6tQayhorq6vQvs9ZOHh4QoLC9OqVaustrS0NG3cuFGRkZGSpMjISKWmpmrr1q1Wn9WrVysrK0uNGzd2+ZgBAAAA4GrYeobs1KlT+umnn6znBw8e1Pbt2xUSEqIKFSpowIABGjNmjKpWrarw8HC99NJLKlu2rO655x5JUo0aNdSmTRs9+uijmjFjhjIyMtSvXz916dKFGRYBAAAAFHq2BrItW7bozjvvtJ5n39cVGxur2bNn69lnn9Xp06fVp08fpaamqlmzZlq+fLl8fHysdd5//33169dPLVu2lJubmzp37qwpU6a4/FgAAAAA4GrZGsjuuOMOGXPpaeYdDodGjRqlUaNGXbJPSEiI5s+fXxDDAwAAAIACVWjvIQMAAACAoo5ABgAAAAA2IZABAAAAgE0IZAAAAABgEwIZAAAAANiEQAYAAAAANiGQAQAAAIBNCGQAAAAAYBNbvxgauFCl55fk27YOjYvJt20BAAAABYUzZAAAAABgEwIZAAAAANiEQAYAAAAANiGQAQAAAIBNCGQAAAAAYBMCGQAAAADYhEAGAAAAADYhkAEAAACATQhkAAAAAGATAhkAAAAA2IRABgAAAAA2IZABAAAAgE0IZAAAAABgEwIZAAAAANiEQAYAAAAANiGQAQAAAIBNCGQAAAAAYBMCGQAAAADYhEAGAAAAADYhkAEAAACATQhkAAAAAGATAhkAAAAA2IRABgAAAAA2IZABAAAAgE0IZAAAAABgEwIZAAAAANiEQAYAAAAANiGQAQAAAIBNCGQAAAAAYBMCGQAAAADYhEAGAAAAADYhkAEAAACATTzsHgCAwqHS80vydXuHxsXk6/YAAACKIs6QAQAAAIBNOEOGIik/z/ZwpgcAAAAFpcicIZs2bZoqVaokHx8fNW7cWJs2bbJ7SAAAAABwWUUikH344YcaOHCghg8fru+//15169ZVdHS0jh49avfQAAAAAOCSisQlixMnTtSjjz6qXr16SZJmzJihJUuW6N1339Xzzz9v8+iAgpPfE3EAAADAtf7zgezcuXPaunWrhgwZYrW5ubkpKipKiYmJua6Tnp6u9PR06/mJEyckSR4Zpwt2sPhPqvLMR/m2LW83o6H1s1TvxU+VnuW45u0V5jdwfr5uG4e0zLdtXS8yMjJ05syZfKs1fga4lOxaO3bsmDw9Pe0eDoowag2ucvz4cUmSMcYl+yvMv89dkT///FOZmZkKDQ11ag8NDdWPP/6Y6zrx8fEaOXJkjvZ9Ux4ukDECF3rQ7gH8B5V8ze4RgJ8BAOB6c+zYMQUFBRX4fv7zgSwvhgwZooEDB1rPU1NTVbFiRSUlJbnkRcf1Ky0tTeXLl9dvv/2mwMBAu4eDIoxag6tQa3AVag2ucuLECVWoUEEhISEu2d9/PpCVLFlS7u7uSklJcWpPSUlRWFhYrut4e3vL29s7R3tQUBBvcLhEYGAgtQaXoNbgKtQaXIVag6u4ublm/sP//CyLXl5eatCggVatWmW1ZWVladWqVYqMjLRxZAAAAABwef/5M2SSNHDgQMXGxqphw4Zq1KiRJk+erNOnT1uzLgIAAABAYVQkAtkDDzygP/74Q8OGDVNycrLq1aun5cuX55jo41K8vb01fPjwXC9jBPITtQZXodbgKtQaXIVag6u4utYcxlXzOQIAAAAAnPzn7yEDAAAAgP8qAhkAAAAA2IRABgAAAAA2IZABAAAAgE2u+0A2bdo0VapUST4+PmrcuLE2bdpk95BQyK1bt07t27dX2bJl5XA4tGjRIqflxhgNGzZMZcqUka+vr6KionTgwAGnPsePH1e3bt0UGBio4OBg9e7dW6dOnXLqs3PnTt12223y8fFR+fLlNWHChII+NBQi8fHxuuWWW1SsWDGVLl1a99xzj/bt2+fU5+zZs4qLi1OJEiUUEBCgzp07KyUlxalPUlKSYmJi5Ofnp9KlS2vw4ME6f/68U5+vv/5aN998s7y9vVWlShXNnj27oA8Phcj06dNVp04d68t2IyMjtWzZMms5dYaCMm7cODkcDg0YMMBqo96QH0aMGCGHw+H0qF69urW80NWZuY4tWLDAeHl5mXfffdfs2bPHPProoyY4ONikpKTYPTQUYkuXLjUvvvii+fTTT40k89lnnzktHzdunAkKCjKLFi0yO3bsMHfffbcJDw83f//9t9WnTZs2pm7duua7774z33zzjalSpYrp2rWrtfzEiRMmNDTUdOvWzezevdt88MEHxtfX17z11luuOkzYLDo62syaNcvs3r3bbN++3bRr185UqFDBnDp1yurz+OOPm/Lly5tVq1aZLVu2mCZNmphbb73VWn7+/HlTq1YtExUVZbZt22aWLl1qSpYsaYYMGWL1+eWXX4yfn58ZOHCg2bt3r5k6dapxd3c3y5cvd+nxwj5ffPGFWbJkidm/f7/Zt2+feeGFF4ynp6fZvXu3MYY6Q8HYtGmTqVSpkqlTp4556qmnrHbqDflh+PDhpmbNmubIkSPW448//rCWF7Y6u64DWaNGjUxcXJz1PDMz05QtW9bEx8fbOCr8l1wcyLKyskxYWJh55ZVXrLbU1FTj7e1tPvjgA2OMMXv37jWSzObNm60+y5YtMw6Hw/z+++/GGGPefPNNU7x4cZOenm71ee6550y1atUK+IhQWB09etRIMmvXrjXG/FNXnp6eZuHChVafH374wUgyiYmJxph//njg5uZmkpOTrT7Tp083gYGBVm09++yzpmbNmk77euCBB0x0dHRBHxIKseLFi5t33nmHOkOBOHnypKlatapJSEgwzZs3twIZ9Yb8Mnz4cFO3bt1clxXGOrtuL1k8d+6ctm7dqqioKKvNzc1NUVFRSkxMtHFk+C87ePCgkpOTneoqKChIjRs3tuoqMTFRwcHBatiwodUnKipKbm5u2rhxo9Xn9ttvl5eXl9UnOjpa+/bt019//eWio0FhcuLECUlSSEiIJGnr1q3KyMhwqrXq1aurQoUKTrVWu3ZthYaGWn2io6OVlpamPXv2WH0u3EZ2Hz4Hr0+ZmZlasGCBTp8+rcjISOoMBSIuLk4xMTE5aoJ6Q346cOCAypYtqxtvvFHdunVTUlKSpMJZZ9dtIPvzzz+VmZnp9EJLUmhoqJKTk20aFf7rsmvncnWVnJys0qVLOy338PBQSEiIU5/ctnHhPnD9yMrK0oABA9S0aVPVqlVL0j914OXlpeDgYKe+F9fav9XRpfqkpaXp77//LojDQSG0a9cuBQQEyNvbW48//rg+++wzRUREUGfIdwsWLND333+v+Pj4HMuoN+SXxo0ba/bs2Vq+fLmmT5+ugwcP6rbbbtPJkycLZZ15XFVvAIDLxcXFaffu3fr222/tHgqKqGrVqmn79u06ceKEPv74Y8XGxmrt2rV2DwtFzG+//aannnpKCQkJ8vHxsXs4KMLatm1r/btOnTpq3LixKlasqI8++ki+vr42jix31+0ZspIlS8rd3T3HjCopKSkKCwuzaVT4r8uuncvVVVhYmI4ePeq0/Pz58zp+/LhTn9y2ceE+cH3o16+fFi9erDVr1qhcuXJWe1hYmM6dO6fU1FSn/hfX2r/V0aX6BAYGFsr/aaFgeHl5qUqVKmrQoIHi4+NVt25dvf7669QZ8tXWrVt19OhR3XzzzfLw8JCHh4fWrl2rKVOmyMPDQ6GhodQbCkRwcLBuuukm/fTTT4Xyc+26DWReXl5q0KCBVq1aZbVlZWVp1apVioyMtHFk+C8LDw9XWFiYU12lpaVp48aNVl1FRkYqNTVVW7dutfqsXr1aWVlZaty4sdVn3bp1ysjIsPokJCSoWrVqKl68uIuOBnYyxqhfv3767LPPtHr1aoWHhzstb9CggTw9PZ1qbd++fUpKSnKqtV27djn9ASAhIUGBgYGKiIiw+ly4jew+fA5e37KyspSenk6dIV+1bNlSu3bt0vbt261Hw4YN1a1bN+vf1BsKwqlTp/Tzzz+rTJkyhfNz7aqnASlCFixYYLy9vc3s2bPN3r17TZ8+fUxwcLDTjCrAxU6ePGm2bdtmtm3bZiSZiRMnmm3btplff/3VGPPPtPfBwcHm888/Nzt37jQdOnTIddr7+vXrm40bN5pvv/3WVK1a1Wna+9TUVBMaGmq6d+9udu/ebRYsWGD8/PyY9v460rdvXxMUFGS+/vprp2l7z5w5Y/V5/PHHTYUKFczq1avNli1bTGRkpImMjLSWZ0/b27p1a7N9+3azfPlyU6pUqVyn7R08eLD54YcfzLRp05ge+jrz/PPPm7Vr15qDBw+anTt3mueff944HA6zYsUKYwx1hoJ14SyLxlBvyB+DBg0yX3/9tTl48KBZv369iYqKMiVLljRHjx41xhS+OruuA5kxxkydOtVUqFDBeHl5mUaNGpnvvvvO7iGhkFuzZo2RlOMRGxtrjPln6vuXXnrJhIaGGm9vb9OyZUuzb98+p20cO3bMdO3a1QQEBJjAwEDTq1cvc/LkSac+O3bsMM2aNTPe3t7mhhtuMOPGjXPVIaIQyK3GJJlZs2ZZff7++2/zxBNPmOLFixs/Pz/TsWNHc+TIEaftHDp0yLRt29b4+vqakiVLmkGDBpmMjAynPmvWrDH16tUzXl5e5sYbb3TaB4q+hx9+2FSsWNF4eXmZUqVKmZYtW1phzBjqDAXr4kBGvSE/PPDAA6ZMmTLGy8vL3HDDDeaBBx4wP/30k7W8sNWZwxhjrv68GgAAAADgWl2395ABAAAAgN0IZAAAAABgEwIZAAAAANiEQAYAAAAANiGQAQAAAIBNCGQAAAAAYBMCGQAAAADYhEAGAAAAADYhkAEACrVDhw7J4XBo+/btdg8FAIB8RyADABQ4h8Nx2ceIESPsHmKufvrpJ/Xq1UvlypWTt7e3wsPD1bVrV23ZssWl4yCUAkDR5WH3AAAARd+RI0esf3/44YcaNmyY9u3bZ7UFBATYMazL2rJli1q2bKlatWrprbfeUvXq1XXy5El9/vnnGjRokNauXWv3EAEARQBnyAAABS4sLMx6BAUFyeFwWM9Lly6tiRMnWmeh6tWrp+XLl19yW5mZmXr44YdVvXp1JSUlSZI+//xz3XzzzfLx8dGNN96okSNH6vz589Y6DodD77zzjjp27Cg/Pz9VrVpVX3zxxSX3YYxRz549VbVqVX3zzTeKiYlR5cqVVa9ePQ0fPlyff/651XfXrl1q0aKFfH19VaJECfXp00enTp2ylt9xxx0aMGCA0/bvuece9ezZ03peqVIljR07Vg8//LCKFSumChUq6O2337aWh4eHS5Lq168vh8OhO+6447KvNwDgv4NABgCw1euvv67XXntNr776qnbu3Kno6GjdfffdOnDgQI6+6enpuu+++7R9+3Z98803qlChgr755hv16NFDTz31lPbu3au33npLs2fP1ssvv+y07siRI3X//fdr586dateunbp166bjx4/nOqbt27drz549GjRokNzccv6vMjg4WJJ0+vRpRUdHq3jx4tq8ebMWLlyolStXql+/flf9Orz22mtq2LChtm3bpieeeEJ9+/a1ziJu2rRJkrRy5UodOXJEn3766VVvHwBQOBHIAAC2evXVV/Xcc8+pS5cuqlatmsaPH6969epp8uTJTv1OnTqlmJgY/fHHH1qzZo1KlSol6Z+g9fzzzys2NlY33nijWrVqpdGjR+utt95yWr9nz57q2rWrqlSporFjx+rUqVNW0LlYdhisXr36Zcc+f/58nT17VnPnzlWtWrXUokULvfHGG3rvvfeUkpJyVa9Du3bt9MQTT6hKlSp67rnnVLJkSa1Zs0aSrGMtUaKEwsLCFBISclXbBgAUXtxDBgCwTVpamg4fPqymTZs6tTdt2lQ7duxwauvatavKlSun1atXy9fX12rfsWOH1q9f73RGLDMzU2fPntWZM2fk5+cnSapTp4613N/fX4GBgTp69Giu4zLGXNH4f/jhB9WtW1f+/v5OY8/KytK+ffsUGhp6Rdu5eHzZl3ReanwAgKKDM2QAgP+Edu3aaefOnUpMTHRqP3XqlEaOHKnt27dbj127dunAgQPy8fGx+nl6ejqt53A4lJWVleu+brrpJknSjz/+eM3jdnNzyxHwMjIycvS7mvEBAIoOAhkAwDaBgYEqW7as1q9f79S+fv16RUREOLX17dtX48aN09133+00w+HNN9+sffv2qUqVKjkeud3/dSXq1auniIgIvfbaa7mGotTUVElSjRo1tGPHDp0+fdpp7G5ubqpWrZqkfy43vHCWyczMTO3evfuqxuPl5WWtCwAoWghkAABbDR48WOPHj9eHH36offv26fnnn9f27dv11FNP5ejbv39/jRkzRnfddZe+/fZbSdKwYcM0d+5cjRw5Unv27NEPP/ygBQsWaOjQoXkek8Ph0KxZs7R//37ddtttWrp0qX755Rft3LlTL7/8sjp06CBJ6tatm3x8fBQbG6vdu3drzZo16t+/v7p3725drtiiRQstWbJES5Ys0Y8//qi+fftage5KlS5dWr6+vlq+fLlSUlJ04sSJPB8bAKBwIZABAGz15JNPauDAgRo0aJBq166t5cuX64svvlDVqlVz7T9gwACNHDlS7dq104YNGxQdHa3FixdrxYoVuuWWW9SkSRNNmjRJFStWvKZxNWrUSFu2bFGVKlX06KOPqkaNGrr77ru1Z88ea8IRPz8/ffXVVzp+/LhuueUW3XvvvWrZsqXeeOMNazsPP/ywYmNj1aNHDzVv3lw33nij7rzzzqsai4eHh6ZMmaK33npLZcuWtQIhAOC/z2Gu9M5lAAAAAEC+4gwZAAAAANiEQAYAAAAANiGQAQAAAIBNCGQAAAAAYBMCGQAAAADYhEAGAAAAADYhkAEAAACATQhkAAAAAGATAhkAAAAA2IRABgAAAAA2IZABAAAAgE3+P9nNEBM+bxYwAAAAAElFTkSuQmCC",
      "text/plain": [
       "<Figure size 1000x600 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Load data\n",
    "train_human_df = pd.read_csv(\"/Applications/AI/msc_project/data/my_politifact_train.csv\")\n",
    "val_human_df = pd.read_csv(\"/Applications/AI/msc_project/data/my_politifact_validation.csv\")\n",
    "test_human_df = pd.read_csv(\"/Applications/AI/msc_project/data/my_politifact_test.csv\")\n",
    "train_llm_df = pd.read_csv(\"/Applications/AI/msc_project/data/my_llm_fake_politifact_train.csv\")\n",
    "val_llm_df = pd.read_csv(\"/Applications/AI/msc_project/data/my_llm_fake_politifact_validation.csv\")\n",
    "test_llm_df = pd.read_csv(\"/Applications/AI/msc_project/data/my_llm_fake_politifact_test.csv\")\n",
    "\n",
    "# Combine Human & LLMFake datasets\n",
    "filtered_train_llm_df = train_llm_df[['text', 'is_true']]\n",
    "combined_train_df = pd.concat([train_human_df, filtered_train_llm_df], ignore_index=True)\n",
    "filtered_val_llm_df = val_llm_df[['text', 'is_true']]\n",
    "combined_val_df = pd.concat([val_human_df, filtered_val_llm_df], ignore_index=True)\n",
    "filtered_test_llm_df = test_llm_df[['text', 'is_true']]\n",
    "combined_test_df = pd.concat([test_human_df, filtered_test_llm_df], ignore_index=True)\n",
    "\n",
    "# Pre-process data\n",
    "train_untruncated_seq, train_seq, train_mask, train_y = pre_process_data(combined_train_df, tokenizer, max_len)\n",
    "val_untruncated_seq, val_seq, val_mask, val_y = pre_process_data(combined_val_df, tokenizer, max_len)\n",
    "test_untruncated_seq, test_seq, test_mask, test_y = pre_process_data(combined_test_df, tokenizer, max_len)\n",
    "\n",
    "\n",
    "# Plot the histogram of token counts of tokenised text for LLMFake Data\n",
    "train_llm_untruncated_seq, train_llm_seq, train_llm_mask, train_llm_y = pre_process_data(filtered_train_llm_df, tokenizer, max_len)\n",
    "val_llm_untruncated_seq, val_llm_seq, val_llm_mask, val_llm_y = pre_process_data(filtered_val_llm_df, tokenizer, max_len)\n",
    "test_llm_untruncated_seq, test_llm_seq, test_llm_mask, test_llm_y = pre_process_data(filtered_test_llm_df, tokenizer, max_len)\n",
    "all_llm_tokenised_seq = train_llm_untruncated_seq + val_llm_untruncated_seq + test_llm_untruncated_seq\n",
    "llm_token_counts = [len(seq) for seq in all_llm_tokenised_seq]\n",
    "plt.figure(figsize=(10, 6))\n",
    "pd.Series(llm_token_counts).hist(bins=200, range=(0, 25000))\n",
    "plt.xlabel('Token Count')\n",
    "plt.ylabel('Frequency')\n",
    "plt.title('Histogram of Token Counts in Tokenised LLMFake Data')\n",
    "plt.xlim(0, 5000)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Hyperparameter Selection Using Validation Set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nos.remove(model_path)\\n'"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Define model path\n",
    "model_path = \"/Applications/AI/msc_project/model_weights/bert_weights_politifact_human_and_llm_validation.pt\"\n",
    "\n",
    "# RUN THIS CODE TO RERUN HYPERPARAMETER TUNING\n",
    "'''\n",
    "os.remove(model_path)\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model weights already saved at /Applications/AI/msc_project/model_weights/bert_weights_politifact_human_and_llm_validation.pt. Skipping hyperparameter selection.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/jacobshort/anaconda3/envs/uni_39/lib/python3.9/site-packages/sklearn/preprocessing/_label.py:114: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'lr': None, 'batch_size': None, 'epochs': None, 'model_init': None}"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Define hyperparameter search grid\n",
    "learning_rates = [1e-5, 5e-5]\n",
    "batch_sizes = [16]\n",
    "epochs_options = [2, 4]\n",
    "model_inits = [\"unfrozen\", \"frozen\"]\n",
    "\n",
    "# Run hyperparameter selection (this code will not run if model weights already exist as we have already performed this step)\n",
    "hyper_param_selection(learning_rates=learning_rates, batch_sizes=batch_sizes, epochs_options=epochs_options, model_inits=model_inits, train_seq=train_seq, train_mask=train_mask, train_y=train_y, val_seq=val_seq, val_mask=val_mask, val_y=val_y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "DO BELOW (UPDATE TO MODERN)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fine Tune Using Chosen Hyperparameters On Train Union Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nos.remove(model_path)\\n'"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Define model path\n",
    "model_path = \"/Applications/AI/msc_project/model_weights/bert_weights_politifact_human_llm_finetuned.pt\"\n",
    "\n",
    "# RUN THIS CODE TO RERUN FINE-TUNING\n",
    "'''\n",
    "os.remove(model_path)\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model weights already saved at /Applications/AI/msc_project/model_weights/bert_weights_politifact_human_llm_finetuned.pt. Skipping training.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/jacobshort/anaconda3/envs/uni_39/lib/python3.9/site-packages/sklearn/preprocessing/_label.py:114: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    }
   ],
   "source": [
    "# Define best hyperparameters as chosen by previous hyperparameter selection grid search\n",
    "best_lr = 1e-5\n",
    "best_batch_size = 16\n",
    "best_epochs = 2\n",
    "best_model_init = \"unfrozen\"\n",
    "\n",
    "# Combine training and validation data for fine-tuning\n",
    "combined_training_sequence = torch.cat((train_seq, val_seq), 0)\n",
    "combined_training_mask = torch.cat((train_mask, val_mask), 0)\n",
    "combined_training_y = torch.cat((train_y, val_y), 0)\n",
    "\n",
    "# Fine-tune the model\n",
    "fine_tune(training_sequence=combined_training_sequence, training_mask=combined_training_mask, training_y=combined_training_y, epochs=best_epochs, batch_size=best_batch_size, lr=best_lr, model_init=best_model_init, model_path=model_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Predict Labels On Test Set & LLM Set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "A parameter name that contains `beta` will be renamed internally to `bias`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `gamma` will be renamed internally to `weight`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `beta` will be renamed internally to `bias`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `gamma` will be renamed internally to `weight`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `beta` will be renamed internally to `bias`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `gamma` will be renamed internally to `weight`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `beta` will be renamed internally to `bias`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `gamma` will be renamed internally to `weight`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `beta` will be renamed internally to `bias`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `gamma` will be renamed internally to `weight`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `beta` will be renamed internally to `bias`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `gamma` will be renamed internally to `weight`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `beta` will be renamed internally to `bias`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `gamma` will be renamed internally to `weight`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `beta` will be renamed internally to `bias`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `gamma` will be renamed internally to `weight`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `beta` will be renamed internally to `bias`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `gamma` will be renamed internally to `weight`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `beta` will be renamed internally to `bias`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `gamma` will be renamed internally to `weight`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `beta` will be renamed internally to `bias`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `gamma` will be renamed internally to `weight`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `beta` will be renamed internally to `bias`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `gamma` will be renamed internally to `weight`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `beta` will be renamed internally to `bias`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `gamma` will be renamed internally to `weight`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `beta` will be renamed internally to `bias`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `gamma` will be renamed internally to `weight`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `beta` will be renamed internally to `bias`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `gamma` will be renamed internally to `weight`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `beta` will be renamed internally to `bias`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `gamma` will be renamed internally to `weight`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `beta` will be renamed internally to `bias`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `gamma` will be renamed internally to `weight`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `beta` will be renamed internally to `bias`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `gamma` will be renamed internally to `weight`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `beta` will be renamed internally to `bias`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `gamma` will be renamed internally to `weight`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `beta` will be renamed internally to `bias`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `gamma` will be renamed internally to `weight`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `beta` will be renamed internally to `bias`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `gamma` will be renamed internally to `weight`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `beta` will be renamed internally to `bias`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `gamma` will be renamed internally to `weight`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `beta` will be renamed internally to `bias`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `gamma` will be renamed internally to `weight`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `beta` will be renamed internally to `bias`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `gamma` will be renamed internally to `weight`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `beta` will be renamed internally to `bias`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `gamma` will be renamed internally to `weight`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `beta` will be renamed internally to `bias`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `gamma` will be renamed internally to `weight`. Please use a different name to suppress this warning.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "_IncompatibleKeys(missing_keys=[], unexpected_keys=['bert.embeddings.position_ids'])"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load the fine-tuned model\n",
    "model=initialise_bert_model_unfrozen()\n",
    "model.load_state_dict(torch.load(model_path), strict=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total batches to process: 19\n",
      "Processed 10 batches, 9 batches remaining\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      0.94      0.96       493\n",
      "           1       0.74      0.89      0.81       100\n",
      "\n",
      "    accuracy                           0.93       593\n",
      "   macro avg       0.86      0.91      0.88       593\n",
      "weighted avg       0.94      0.93      0.93       593\n",
      "\n",
      "Success rate: 82.89%\n",
      "/Applications/AI/msc_project/predictions/my_politifact_test_predictions_human_and_llm_bert.csv already exists. The DataFrame will not be saved.\n"
     ]
    }
   ],
   "source": [
    "# Human and LLMFake trained BERT on human test set\n",
    "# Obtain performance metrics\n",
    "results_df, success_rate, metrics = predictions_and_metrics_basic(model=model, original_df=test_df, sequences=test_seq, masks=test_mask, labels=test_y)\n",
    "print(metrics)\n",
    "print(f\"Success rate: {success_rate:.2f}%\")\n",
    "\n",
    "results_table_path = '/Applications/AI/msc_project/predictions/my_politifact_test_predictions_human_and_llm_bert.csv'\n",
    "if os.path.exists(results_table_path):\n",
    "    print(f\"{results_table_path} already exists. The DataFrame will not be saved.\")\n",
    "else:\n",
    "    # Save the results_df to the results_table_path\n",
    "    results_df.to_csv(results_table_path, index=False)\n",
    "    print(f\"Results DataFrame saved to {results_table_path}.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/jacobshort/anaconda3/envs/uni_39/lib/python3.9/site-packages/transformers/tokenization_utils_base.py:1601: FutureWarning: `clean_up_tokenization_spaces` was not set. It will be set to `True` by default. This behavior will be depracted in transformers v4.45, and will be then set to `False` by default. For more details check this issue: https://github.com/huggingface/transformers/issues/31884\n",
      "  warnings.warn(\n",
      "Token indices sequence length is longer than the specified maximum sequence length for this model (545 > 512). Running this sequence through the model will result in indexing errors\n",
      "/Users/jacobshort/anaconda3/envs/uni_39/lib/python3.9/site-packages/transformers/tokenization_utils_base.py:2870: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total batches to process: 14\n",
      "Processed 10 batches, 4 batches remaining\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.95      0.98       417\n",
      "           1       0.00      0.00      0.00         0\n",
      "\n",
      "    accuracy                           0.95       417\n",
      "   macro avg       0.50      0.48      0.49       417\n",
      "weighted avg       1.00      0.95      0.98       417\n",
      "\n",
      "Success rate: 95.44%\n",
      "{'llm_totally_arbitrary_generation': 100.0, 'llm_incomplete': 89.65517241379311, 'llm_false_context': 96.66666666666667, 'llm_open_generation': 98.14814814814815, 'llm_unsubstantiated_content': 93.10344827586206, 'llm_outdated': 96.55172413793103, 'llm_health_generation': 100.0, 'llm_rewritten': 98.14814814814815, 'llm_total_fabrication': 89.65517241379311, 'llm_politics_generation': 100.0, 'llm_paraphrase': 98.14814814814815, 'llm_hallucination': 100.0, 'llm_ambiguity': 79.3103448275862}\n",
      "/Applications/AI/msc_project/predictions/my_llm_fake_politifact_test_predictions_human_and_llm_bert.csv already exists. The DataFrame will not be saved.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/jacobshort/anaconda3/envs/uni_39/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1469: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/jacobshort/anaconda3/envs/uni_39/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1469: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/jacobshort/anaconda3/envs/uni_39/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1469: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "# Human and LLMFake trained BERT on LLMFake test set\n",
    "# Load & pre-process test data\n",
    "ood_df = pd.read_csv(\"/Applications/AI/msc_project/data/my_llm_fake_politifact_test.csv\")\n",
    "ood_untruncated_seq, ood_seq, ood_mask, ood_y = pre_process_data(ood_df, tokenizer, max_len)\n",
    "\n",
    "# Obtain performance metrics\n",
    "results_df, success_rate, classwise_success_rates, metrics = predictions_and_metrics_classwise(model=model, original_df=ood_df, sequences=ood_seq, masks=ood_mask, labels=ood_y)\n",
    "print(metrics)\n",
    "print(f\"Success rate: {success_rate:.2f}%\")\n",
    "print(classwise_success_rates)\n",
    "\n",
    "results_table_path = '/Applications/AI/msc_project/predictions/my_llm_fake_politifact_test_predictions_human_and_llm_bert.csv'\n",
    "if os.path.exists(results_table_path):\n",
    "    print(f\"{results_table_path} already exists. The DataFrame will not be saved.\")\n",
    "else:\n",
    "    # Save the results_df to the results_table_path\n",
    "    results_df.to_csv(results_table_path, index=False)\n",
    "    print(f\"Results DataFrame saved to {results_table_path}.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-----------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Resampling (Human BERT)\n",
    "- We train and evaluate BERT on 5 different train and test sets to obtain 5 sets of performance metrics for statistical hypothesis testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to fine-tune multiple models\n",
    "def resample_training_models(model_paths, train_processed_seq_list, train_processed_mask_list, train_processed_y_list, model_init, epochs, batch_size, lr):\n",
    "\n",
    "    for i in range(len(model_paths)):\n",
    "\n",
    "        model_path = model_paths[i]\n",
    "        if os.path.exists(model_path):\n",
    "            print(f\"Model weights already saved at {model_path}. Skipping training.\")\n",
    "            continue\n",
    "\n",
    "        fine_tune(training_sequence=train_processed_seq_list, training_mask=train_processed_mask_list, training_y=train_processed_y_list, epochs=epochs, batch_size=batch_size, lr=lr, model_init=model_init, model_path=model_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to pre-process multiple datasets\n",
    "def pre_process_multi_datasplits(data_list,tokenizer,max_len):\n",
    "    processed_seq_list=[]\n",
    "    processed_mask_list=[]\n",
    "    processed_y_list=[]\n",
    "    for i in range(len(data_list)):\n",
    "        dataset = pd.read_csv(data_list[i])\n",
    "        _, dataset_seq, dataset_mask, dataset_y = pre_process_data(dataset, tokenizer, max_len)\n",
    "        processed_seq_list.append(dataset_seq)\n",
    "        processed_mask_list.append(dataset_mask)\n",
    "        processed_y_list.append(dataset_y)\n",
    "\n",
    "    return processed_seq_list, processed_mask_list, processed_y_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to obtain performance metrics from multiple models on multiple datasets\n",
    "def obtain_resampled_metrics_lists(models_list, original_df_list, sequences_list, masks_list, labels_list):\n",
    "\n",
    "    success_rate_list=[]\n",
    "    macro_f1_list=[]\n",
    "    for i in range(len(models_list)):\n",
    "        _, success_rate, metrics = predictions_and_metrics_basic(models_list[i],original_df_list[i],sequences_list[i],masks_list[i],labels_list[i])\n",
    "        macro_f1_score = float(re.search(r'^\\s*macro avg\\s+[\\d\\.]+\\s+[\\d\\.]+\\s+([\\d\\.]+)', metrics, re.MULTILINE).group(1))\n",
    "\n",
    "        success_rate_list.append(success_rate)\n",
    "        macro_f1_list.append(macro_f1_score)\n",
    "\n",
    "    return success_rate_list,macro_f1_list\n",
    "\n",
    "# Function to obtain performance metrics from multiple models on multiple datasets\n",
    "# This function also outputs classwise success rates (for different LLMFake categories)\n",
    "def obtain_resampled_metrics_lists_classwise(models_list, original_df_list, sequences_list, masks_list, labels_list):\n",
    "    success_rate_list = []\n",
    "    macro_f1_list = []\n",
    "    all_classwise_success_rates = {}\n",
    "\n",
    "    for i in range(len(models_list)):\n",
    "        _, success_rate, classwise_success_rates, metrics = predictions_and_metrics_classwise(\n",
    "            models_list[i], original_df_list[i], sequences_list[i], masks_list[i], labels_list[i]\n",
    "        )\n",
    "        macro_f1_score = float(re.search(r'^\\s*macro avg\\s+[\\d\\.]+\\s+[\\d\\.]+\\s+([\\d\\.]+)', metrics, re.MULTILINE).group(1))\n",
    "\n",
    "        success_rate_list.append(success_rate)\n",
    "        macro_f1_list.append(macro_f1_score)\n",
    "        \n",
    "        for category, rate in classwise_success_rates.items():\n",
    "            if category not in all_classwise_success_rates:\n",
    "                all_classwise_success_rates[category] = []\n",
    "            all_classwise_success_rates[category].append(rate)\n",
    "\n",
    "    return success_rate_list, macro_f1_list, all_classwise_success_rates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/jacobshort/anaconda3/envs/uni_39/lib/python3.9/site-packages/transformers/tokenization_utils_base.py:2870: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
      "  warnings.warn(\n",
      "/Users/jacobshort/anaconda3/envs/uni_39/lib/python3.9/site-packages/transformers/tokenization_utils_base.py:2870: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
      "  warnings.warn(\n",
      "/Users/jacobshort/anaconda3/envs/uni_39/lib/python3.9/site-packages/transformers/tokenization_utils_base.py:2870: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
      "  warnings.warn(\n",
      "/Users/jacobshort/anaconda3/envs/uni_39/lib/python3.9/site-packages/transformers/tokenization_utils_base.py:2870: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
      "  warnings.warn(\n",
      "/Users/jacobshort/anaconda3/envs/uni_39/lib/python3.9/site-packages/transformers/tokenization_utils_base.py:2870: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
      "  warnings.warn(\n",
      "A parameter name that contains `beta` will be renamed internally to `bias`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `gamma` will be renamed internally to `weight`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `beta` will be renamed internally to `bias`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `gamma` will be renamed internally to `weight`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `beta` will be renamed internally to `bias`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `gamma` will be renamed internally to `weight`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `beta` will be renamed internally to `bias`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `gamma` will be renamed internally to `weight`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `beta` will be renamed internally to `bias`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `gamma` will be renamed internally to `weight`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `beta` will be renamed internally to `bias`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `gamma` will be renamed internally to `weight`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `beta` will be renamed internally to `bias`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `gamma` will be renamed internally to `weight`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `beta` will be renamed internally to `bias`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `gamma` will be renamed internally to `weight`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `beta` will be renamed internally to `bias`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `gamma` will be renamed internally to `weight`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `beta` will be renamed internally to `bias`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `gamma` will be renamed internally to `weight`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `beta` will be renamed internally to `bias`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `gamma` will be renamed internally to `weight`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `beta` will be renamed internally to `bias`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `gamma` will be renamed internally to `weight`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `beta` will be renamed internally to `bias`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `gamma` will be renamed internally to `weight`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `beta` will be renamed internally to `bias`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `gamma` will be renamed internally to `weight`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `beta` will be renamed internally to `bias`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `gamma` will be renamed internally to `weight`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `beta` will be renamed internally to `bias`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `gamma` will be renamed internally to `weight`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `beta` will be renamed internally to `bias`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `gamma` will be renamed internally to `weight`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `beta` will be renamed internally to `bias`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `gamma` will be renamed internally to `weight`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `beta` will be renamed internally to `bias`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `gamma` will be renamed internally to `weight`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `beta` will be renamed internally to `bias`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `gamma` will be renamed internally to `weight`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `beta` will be renamed internally to `bias`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `gamma` will be renamed internally to `weight`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `beta` will be renamed internally to `bias`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `gamma` will be renamed internally to `weight`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `beta` will be renamed internally to `bias`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `gamma` will be renamed internally to `weight`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `beta` will be renamed internally to `bias`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `gamma` will be renamed internally to `weight`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `beta` will be renamed internally to `bias`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `gamma` will be renamed internally to `weight`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `beta` will be renamed internally to `bias`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `gamma` will be renamed internally to `weight`. Please use a different name to suppress this warning.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model weights already saved at /Applications/AI/msc_project/model_weights/bert_weights_politifact_human_cv1.pt. Skipping training.\n",
      "Model weights already saved at /Applications/AI/msc_project/model_weights/bert_weights_politifact_human_cv2.pt. Skipping training.\n",
      "Model weights already saved at /Applications/AI/msc_project/model_weights/bert_weights_politifact_human_cv3.pt. Skipping training.\n",
      "Model weights already saved at /Applications/AI/msc_project/model_weights/bert_weights_politifact_human_cv4.pt. Skipping training.\n",
      "Model weights already saved at /Applications/AI/msc_project/model_weights/bert_weights_politifact_human_cv5.pt. Skipping training.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "A parameter name that contains `beta` will be renamed internally to `bias`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `gamma` will be renamed internally to `weight`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `beta` will be renamed internally to `bias`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `gamma` will be renamed internally to `weight`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `beta` will be renamed internally to `bias`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `gamma` will be renamed internally to `weight`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `beta` will be renamed internally to `bias`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `gamma` will be renamed internally to `weight`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `beta` will be renamed internally to `bias`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `gamma` will be renamed internally to `weight`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `beta` will be renamed internally to `bias`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `gamma` will be renamed internally to `weight`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `beta` will be renamed internally to `bias`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `gamma` will be renamed internally to `weight`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `beta` will be renamed internally to `bias`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `gamma` will be renamed internally to `weight`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `beta` will be renamed internally to `bias`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `gamma` will be renamed internally to `weight`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `beta` will be renamed internally to `bias`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `gamma` will be renamed internally to `weight`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `beta` will be renamed internally to `bias`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `gamma` will be renamed internally to `weight`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `beta` will be renamed internally to `bias`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `gamma` will be renamed internally to `weight`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `beta` will be renamed internally to `bias`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `gamma` will be renamed internally to `weight`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `beta` will be renamed internally to `bias`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `gamma` will be renamed internally to `weight`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `beta` will be renamed internally to `bias`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `gamma` will be renamed internally to `weight`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `beta` will be renamed internally to `bias`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `gamma` will be renamed internally to `weight`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `beta` will be renamed internally to `bias`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `gamma` will be renamed internally to `weight`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `beta` will be renamed internally to `bias`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `gamma` will be renamed internally to `weight`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `beta` will be renamed internally to `bias`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `gamma` will be renamed internally to `weight`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `beta` will be renamed internally to `bias`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `gamma` will be renamed internally to `weight`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `beta` will be renamed internally to `bias`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `gamma` will be renamed internally to `weight`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `beta` will be renamed internally to `bias`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `gamma` will be renamed internally to `weight`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `beta` will be renamed internally to `bias`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `gamma` will be renamed internally to `weight`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `beta` will be renamed internally to `bias`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `gamma` will be renamed internally to `weight`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `beta` will be renamed internally to `bias`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `gamma` will be renamed internally to `weight`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `beta` will be renamed internally to `bias`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `gamma` will be renamed internally to `weight`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `beta` will be renamed internally to `bias`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `gamma` will be renamed internally to `weight`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `beta` will be renamed internally to `bias`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `gamma` will be renamed internally to `weight`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `beta` will be renamed internally to `bias`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `gamma` will be renamed internally to `weight`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `beta` will be renamed internally to `bias`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `gamma` will be renamed internally to `weight`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `beta` will be renamed internally to `bias`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `gamma` will be renamed internally to `weight`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `beta` will be renamed internally to `bias`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `gamma` will be renamed internally to `weight`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `beta` will be renamed internally to `bias`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `gamma` will be renamed internally to `weight`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `beta` will be renamed internally to `bias`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `gamma` will be renamed internally to `weight`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `beta` will be renamed internally to `bias`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `gamma` will be renamed internally to `weight`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `beta` will be renamed internally to `bias`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `gamma` will be renamed internally to `weight`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `beta` will be renamed internally to `bias`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `gamma` will be renamed internally to `weight`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `beta` will be renamed internally to `bias`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `gamma` will be renamed internally to `weight`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `beta` will be renamed internally to `bias`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `gamma` will be renamed internally to `weight`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `beta` will be renamed internally to `bias`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `gamma` will be renamed internally to `weight`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `beta` will be renamed internally to `bias`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `gamma` will be renamed internally to `weight`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `beta` will be renamed internally to `bias`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `gamma` will be renamed internally to `weight`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `beta` will be renamed internally to `bias`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `gamma` will be renamed internally to `weight`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `beta` will be renamed internally to `bias`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `gamma` will be renamed internally to `weight`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `beta` will be renamed internally to `bias`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `gamma` will be renamed internally to `weight`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `beta` will be renamed internally to `bias`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `gamma` will be renamed internally to `weight`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `beta` will be renamed internally to `bias`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `gamma` will be renamed internally to `weight`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `beta` will be renamed internally to `bias`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `gamma` will be renamed internally to `weight`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `beta` will be renamed internally to `bias`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `gamma` will be renamed internally to `weight`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `beta` will be renamed internally to `bias`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `gamma` will be renamed internally to `weight`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `beta` will be renamed internally to `bias`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `gamma` will be renamed internally to `weight`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `beta` will be renamed internally to `bias`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `gamma` will be renamed internally to `weight`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `beta` will be renamed internally to `bias`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `gamma` will be renamed internally to `weight`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `beta` will be renamed internally to `bias`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `gamma` will be renamed internally to `weight`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `beta` will be renamed internally to `bias`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `gamma` will be renamed internally to `weight`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `beta` will be renamed internally to `bias`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `gamma` will be renamed internally to `weight`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `beta` will be renamed internally to `bias`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `gamma` will be renamed internally to `weight`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `beta` will be renamed internally to `bias`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `gamma` will be renamed internally to `weight`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `beta` will be renamed internally to `bias`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `gamma` will be renamed internally to `weight`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `beta` will be renamed internally to `bias`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `gamma` will be renamed internally to `weight`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `beta` will be renamed internally to `bias`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `gamma` will be renamed internally to `weight`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `beta` will be renamed internally to `bias`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `gamma` will be renamed internally to `weight`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `beta` will be renamed internally to `bias`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `gamma` will be renamed internally to `weight`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `beta` will be renamed internally to `bias`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `gamma` will be renamed internally to `weight`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `beta` will be renamed internally to `bias`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `gamma` will be renamed internally to `weight`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `beta` will be renamed internally to `bias`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `gamma` will be renamed internally to `weight`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `beta` will be renamed internally to `bias`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `gamma` will be renamed internally to `weight`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `beta` will be renamed internally to `bias`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `gamma` will be renamed internally to `weight`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `beta` will be renamed internally to `bias`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `gamma` will be renamed internally to `weight`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `beta` will be renamed internally to `bias`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `gamma` will be renamed internally to `weight`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `beta` will be renamed internally to `bias`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `gamma` will be renamed internally to `weight`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `beta` will be renamed internally to `bias`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `gamma` will be renamed internally to `weight`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `beta` will be renamed internally to `bias`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `gamma` will be renamed internally to `weight`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `beta` will be renamed internally to `bias`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `gamma` will be renamed internally to `weight`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `beta` will be renamed internally to `bias`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `gamma` will be renamed internally to `weight`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `beta` will be renamed internally to `bias`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `gamma` will be renamed internally to `weight`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `beta` will be renamed internally to `bias`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `gamma` will be renamed internally to `weight`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `beta` will be renamed internally to `bias`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `gamma` will be renamed internally to `weight`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `beta` will be renamed internally to `bias`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `gamma` will be renamed internally to `weight`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `beta` will be renamed internally to `bias`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `gamma` will be renamed internally to `weight`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `beta` will be renamed internally to `bias`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `gamma` will be renamed internally to `weight`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `beta` will be renamed internally to `bias`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `gamma` will be renamed internally to `weight`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `beta` will be renamed internally to `bias`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `gamma` will be renamed internally to `weight`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `beta` will be renamed internally to `bias`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `gamma` will be renamed internally to `weight`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `beta` will be renamed internally to `bias`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `gamma` will be renamed internally to `weight`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `beta` will be renamed internally to `bias`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `gamma` will be renamed internally to `weight`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `beta` will be renamed internally to `bias`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `gamma` will be renamed internally to `weight`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `beta` will be renamed internally to `bias`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `gamma` will be renamed internally to `weight`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `beta` will be renamed internally to `bias`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `gamma` will be renamed internally to `weight`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `beta` will be renamed internally to `bias`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `gamma` will be renamed internally to `weight`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `beta` will be renamed internally to `bias`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `gamma` will be renamed internally to `weight`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `beta` will be renamed internally to `bias`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `gamma` will be renamed internally to `weight`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `beta` will be renamed internally to `bias`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `gamma` will be renamed internally to `weight`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `beta` will be renamed internally to `bias`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `gamma` will be renamed internally to `weight`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `beta` will be renamed internally to `bias`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `gamma` will be renamed internally to `weight`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `beta` will be renamed internally to `bias`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `gamma` will be renamed internally to `weight`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `beta` will be renamed internally to `bias`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `gamma` will be renamed internally to `weight`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `beta` will be renamed internally to `bias`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `gamma` will be renamed internally to `weight`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `beta` will be renamed internally to `bias`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `gamma` will be renamed internally to `weight`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `beta` will be renamed internally to `bias`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `gamma` will be renamed internally to `weight`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `beta` will be renamed internally to `bias`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `gamma` will be renamed internally to `weight`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `beta` will be renamed internally to `bias`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `gamma` will be renamed internally to `weight`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `beta` will be renamed internally to `bias`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `gamma` will be renamed internally to `weight`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `beta` will be renamed internally to `bias`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `gamma` will be renamed internally to `weight`. Please use a different name to suppress this warning.\n"
     ]
    }
   ],
   "source": [
    "# Define model weight file paths\n",
    "model_path_1 = \"/Applications/AI/msc_project/model_weights/bert_weights_politifact_human_cv1.pt\"\n",
    "model_path_2 = \"/Applications/AI/msc_project/model_weights/bert_weights_politifact_human_cv2.pt\"\n",
    "model_path_3 = \"/Applications/AI/msc_project/model_weights/bert_weights_politifact_human_cv3.pt\"\n",
    "model_path_4 = \"/Applications/AI/msc_project/model_weights/bert_weights_politifact_human_cv4.pt\"\n",
    "model_path_5 = \"/Applications/AI/msc_project/model_weights/bert_weights_politifact_human_cv5.pt\"\n",
    "model_paths = [model_path_1, model_path_2, model_path_3, model_path_4, model_path_5]\n",
    "\n",
    "# RUN THIS CODE TO RERUN RESAMPLED FINE-TUNING EVALUATION\n",
    "'''\n",
    "os.remove(model_path_1)\n",
    "os.remove(model_path_2)\n",
    "os.remove(model_path_3)\n",
    "os.remove(model_path_4)\n",
    "os.remove(model_path_5)\n",
    "'''\n",
    "\n",
    "# Load & pre-process training data\n",
    "train_path_1 = \"/Applications/AI/msc_project/data/my_human_politifact_train_split_1.csv\"\n",
    "train_path_2 = \"/Applications/AI/msc_project/data/my_human_politifact_train_split_2.csv\"\n",
    "train_path_3 = \"/Applications/AI/msc_project/data/my_human_politifact_train_split_3.csv\"\n",
    "train_path_4 = \"/Applications/AI/msc_project/data/my_human_politifact_train_split_4.csv\"\n",
    "train_path_5 = \"/Applications/AI/msc_project/data/my_human_politifact_train_split_5.csv\"\n",
    "train_splits = [train_path_1, train_path_2, train_path_3, train_path_4, train_path_5]\n",
    "train_processed_seq_list, train_processed_mask_list, train_processed_y_list = pre_process_multi_datasplits(data_list=train_splits, tokenizer=tokenizer, max_len=max_len)\n",
    "\n",
    "# Define best hyperparameters as chosen by previous hyperparameter selection grid search on initial exploration\n",
    "best_lr = 5e-5\n",
    "best_batch_size = 16\n",
    "best_epochs = 2\n",
    "best_model_init = \"unfrozen\"\n",
    "\n",
    "# Fine-tune models\n",
    "resample_training_models(model_paths=model_paths, train_processed_seq_list=train_processed_seq_list, train_processed_mask_list=train_processed_mask_list, train_processed_y_list=train_processed_y_list, model_init=best_model_init, epochs=best_epochs, batch_size=best_batch_size, lr=best_lr)\n",
    "\n",
    "# Initialize and load these models\n",
    "model_1 = initialise_bert_model_unfrozen()\n",
    "model_1.load_state_dict(torch.load(model_path_1), strict=False)\n",
    "model_2 = initialise_bert_model_unfrozen()\n",
    "model_2.load_state_dict(torch.load(model_path_2), strict=False)\n",
    "model_3 = initialise_bert_model_unfrozen()\n",
    "model_3.load_state_dict(torch.load(model_path_3), strict=False)\n",
    "model_4 = initialise_bert_model_unfrozen()\n",
    "model_4.load_state_dict(torch.load(model_path_4), strict=False)\n",
    "model_5 = initialise_bert_model_unfrozen()\n",
    "model_5.load_state_dict(torch.load(model_path_5), strict=False)\n",
    "models_list = [model_1, model_2, model_3, model_4, model_5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/jacobshort/anaconda3/envs/uni_39/lib/python3.9/site-packages/transformers/tokenization_utils_base.py:2870: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
      "  warnings.warn(\n",
      "/Users/jacobshort/anaconda3/envs/uni_39/lib/python3.9/site-packages/transformers/tokenization_utils_base.py:2870: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
      "  warnings.warn(\n",
      "/Users/jacobshort/anaconda3/envs/uni_39/lib/python3.9/site-packages/transformers/tokenization_utils_base.py:2870: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
      "  warnings.warn(\n",
      "/Users/jacobshort/anaconda3/envs/uni_39/lib/python3.9/site-packages/transformers/tokenization_utils_base.py:2870: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
      "  warnings.warn(\n",
      "/Users/jacobshort/anaconda3/envs/uni_39/lib/python3.9/site-packages/transformers/tokenization_utils_base.py:2870: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total batches to process: 6\n",
      "Total batches to process: 6\n",
      "Total batches to process: 6\n",
      "Total batches to process: 6\n",
      "Total batches to process: 6\n",
      "[91.8918918918919, 88.75, 80.0, 94.20289855072464, 72.97297297297297]\n",
      "[0.88, 0.9, 0.88, 0.83, 0.87]\n"
     ]
    }
   ],
   "source": [
    "# [RESAMPLING] Human trained BERT on human test set\n",
    "test_path_1 = \"/Applications/AI/msc_project/data/my_human_politifact_test_split_1.csv\"\n",
    "test_path_2 = \"/Applications/AI/msc_project/data/my_human_politifact_test_split_2.csv\"\n",
    "test_path_3 = \"/Applications/AI/msc_project/data/my_human_politifact_test_split_3.csv\"\n",
    "test_path_4 = \"/Applications/AI/msc_project/data/my_human_politifact_test_split_4.csv\"\n",
    "test_path_5 = \"/Applications/AI/msc_project/data/my_human_politifact_test_split_5.csv\"\n",
    "test_splits = [test_path_1, test_path_2, test_path_3, test_path_4, test_path_5]\n",
    "test_processed_seq_list, test_processed_mask_list, test_processed_y_list = pre_process_multi_datasplits(data_list=test_splits, tokenizer=tokenizer, max_len=max_len)\n",
    "\n",
    "original_df_1 = pd.read_csv(test_path_1)\n",
    "original_df_2 = pd.read_csv(test_path_2)\n",
    "original_df_3 = pd.read_csv(test_path_3)\n",
    "original_df_4 = pd.read_csv(test_path_4)\n",
    "original_df_5 = pd.read_csv(test_path_5)\n",
    "original_df_list = [original_df_1, original_df_2, original_df_3, original_df_4, original_df_5]\n",
    "\n",
    "success_rate_list, macro_f1_list = obtain_resampled_metrics_lists(models_list, original_df_list=original_df_list, sequences_list=test_processed_seq_list, masks_list=test_processed_mask_list, labels_list=test_processed_y_list)\n",
    "print(success_rate_list)\n",
    "print(macro_f1_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/jacobshort/anaconda3/envs/uni_39/lib/python3.9/site-packages/transformers/tokenization_utils_base.py:2870: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
      "  warnings.warn(\n",
      "/Users/jacobshort/anaconda3/envs/uni_39/lib/python3.9/site-packages/transformers/tokenization_utils_base.py:2870: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
      "  warnings.warn(\n",
      "/Users/jacobshort/anaconda3/envs/uni_39/lib/python3.9/site-packages/transformers/tokenization_utils_base.py:2870: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
      "  warnings.warn(\n",
      "/Users/jacobshort/anaconda3/envs/uni_39/lib/python3.9/site-packages/transformers/tokenization_utils_base.py:2870: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
      "  warnings.warn(\n",
      "/Users/jacobshort/anaconda3/envs/uni_39/lib/python3.9/site-packages/transformers/tokenization_utils_base.py:2870: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total batches to process: 13\n",
      "Processed 10 batches, 3 batches remaining\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/jacobshort/anaconda3/envs/uni_39/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1469: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/jacobshort/anaconda3/envs/uni_39/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1469: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/jacobshort/anaconda3/envs/uni_39/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1469: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total batches to process: 13\n",
      "Processed 10 batches, 3 batches remaining\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/jacobshort/anaconda3/envs/uni_39/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1469: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/jacobshort/anaconda3/envs/uni_39/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1469: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/jacobshort/anaconda3/envs/uni_39/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1469: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total batches to process: 13\n",
      "Processed 10 batches, 3 batches remaining\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/jacobshort/anaconda3/envs/uni_39/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1469: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/jacobshort/anaconda3/envs/uni_39/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1469: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/jacobshort/anaconda3/envs/uni_39/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1469: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total batches to process: 13\n",
      "Processed 10 batches, 3 batches remaining\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/jacobshort/anaconda3/envs/uni_39/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1469: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/jacobshort/anaconda3/envs/uni_39/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1469: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/jacobshort/anaconda3/envs/uni_39/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1469: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total batches to process: 13\n",
      "Processed 10 batches, 3 batches remaining\n",
      "[72.59615384615384, 64.42307692307693, 50.0, 78.36538461538461, 55.52884615384615]\n",
      "{'llm_false_context': [34.48275862068966, 31.03448275862069, 24.137931034482758, 68.96551724137932, 31.03448275862069], 'llm_unsubstantiated_content': [44.827586206896555, 37.93103448275862, 27.586206896551722, 62.06896551724138, 41.37931034482759], 'llm_total_fabrication': [62.06896551724138, 44.827586206896555, 27.586206896551722, 68.96551724137932, 48.275862068965516], 'llm_incomplete': [41.37931034482759, 31.03448275862069, 20.689655172413794, 37.93103448275862, 17.24137931034483], 'llm_ambiguity': [34.48275862068966, 34.48275862068966, 13.793103448275861, 41.37931034482759, 41.37931034482759], 'llm_totally_arbitrary_generation': [100.0, 90.0, 95.0, 100.0, 95.0], 'llm_open_generation': [94.44444444444444, 90.74074074074075, 79.62962962962963, 100.0, 62.96296296296296], 'llm_paraphrase': [96.29629629629629, 90.74074074074075, 66.66666666666666, 100.0, 94.44444444444444], 'llm_outdated': [48.275862068965516, 17.24137931034483, 24.137931034482758, 27.586206896551722, 13.793103448275861], 'llm_rewritten': [94.44444444444444, 87.03703703703704, 68.51851851851852, 96.29629629629629, 75.92592592592592], 'llm_hallucination': [55.00000000000001, 40.0, 0.0, 85.0, 0.0], 'llm_health_generation': [100.0, 100.0, 65.0, 100.0, 50.0], 'llm_politics_generation': [100.0, 100.0, 100.0, 100.0, 100.0]}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/jacobshort/anaconda3/envs/uni_39/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1469: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/jacobshort/anaconda3/envs/uni_39/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1469: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/jacobshort/anaconda3/envs/uni_39/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1469: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "# [RESAMPLED] Human trained BERT on LLMFake test set\n",
    "# Note: macro F1 here doesn't make sense\n",
    "test_path_1 = \"/Applications/AI/msc_project/data/my_llm_fake_politifact_test_split_1.csv\"\n",
    "test_path_2 = \"/Applications/AI/msc_project/data/my_llm_fake_politifact_test_split_2.csv\"\n",
    "test_path_3 = \"/Applications/AI/msc_project/data/my_llm_fake_politifact_test_split_3.csv\"\n",
    "test_path_4 = \"/Applications/AI/msc_project/data/my_llm_fake_politifact_test_split_4.csv\"\n",
    "test_path_5 = \"/Applications/AI/msc_project/data/my_llm_fake_politifact_test_split_5.csv\"\n",
    "test_splits = [test_path_1, test_path_2, test_path_3, test_path_4, test_path_5]\n",
    "test_processed_seq_list, test_processed_mask_list, test_processed_y_list = pre_process_multi_datasplits(data_list=test_splits, tokenizer=tokenizer, max_len=max_len)\n",
    "\n",
    "original_df_1 = pd.read_csv(test_path_1)\n",
    "original_df_2 = pd.read_csv(test_path_2)\n",
    "original_df_3 = pd.read_csv(test_path_3)\n",
    "original_df_4 = pd.read_csv(test_path_4)\n",
    "original_df_5 = pd.read_csv(test_path_5)\n",
    "original_df_list = [original_df_1, original_df_2, original_df_3, original_df_4, original_df_5]\n",
    "\n",
    "success_rate_list, _, classwise_success_rates = obtain_resampled_metrics_lists_classwise(models_list, original_df_list=original_df_list, sequences_list=test_processed_seq_list, masks_list=test_processed_mask_list, labels_list=test_processed_y_list)\n",
    "print(success_rate_list)\n",
    "print(classwise_success_rates)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Resampling (Human & LLMFake BERT)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/jacobshort/anaconda3/envs/uni_39/lib/python3.9/site-packages/transformers/tokenization_utils_base.py:2870: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
      "  warnings.warn(\n",
      "/Users/jacobshort/anaconda3/envs/uni_39/lib/python3.9/site-packages/transformers/tokenization_utils_base.py:2870: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
      "  warnings.warn(\n",
      "/Users/jacobshort/anaconda3/envs/uni_39/lib/python3.9/site-packages/transformers/tokenization_utils_base.py:2870: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
      "  warnings.warn(\n",
      "/Users/jacobshort/anaconda3/envs/uni_39/lib/python3.9/site-packages/transformers/tokenization_utils_base.py:2870: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
      "  warnings.warn(\n",
      "/Users/jacobshort/anaconda3/envs/uni_39/lib/python3.9/site-packages/transformers/tokenization_utils_base.py:2870: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
      "  warnings.warn(\n",
      "/Users/jacobshort/anaconda3/envs/uni_39/lib/python3.9/site-packages/transformers/tokenization_utils_base.py:2870: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
      "  warnings.warn(\n",
      "/Users/jacobshort/anaconda3/envs/uni_39/lib/python3.9/site-packages/transformers/tokenization_utils_base.py:2870: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
      "  warnings.warn(\n",
      "/Users/jacobshort/anaconda3/envs/uni_39/lib/python3.9/site-packages/transformers/tokenization_utils_base.py:2870: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
      "  warnings.warn(\n",
      "/Users/jacobshort/anaconda3/envs/uni_39/lib/python3.9/site-packages/transformers/tokenization_utils_base.py:2870: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
      "  warnings.warn(\n",
      "/Users/jacobshort/anaconda3/envs/uni_39/lib/python3.9/site-packages/transformers/tokenization_utils_base.py:2870: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
      "  warnings.warn(\n",
      "A parameter name that contains `beta` will be renamed internally to `bias`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `gamma` will be renamed internally to `weight`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `beta` will be renamed internally to `bias`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `gamma` will be renamed internally to `weight`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `beta` will be renamed internally to `bias`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `gamma` will be renamed internally to `weight`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `beta` will be renamed internally to `bias`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `gamma` will be renamed internally to `weight`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `beta` will be renamed internally to `bias`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `gamma` will be renamed internally to `weight`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `beta` will be renamed internally to `bias`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `gamma` will be renamed internally to `weight`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `beta` will be renamed internally to `bias`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `gamma` will be renamed internally to `weight`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `beta` will be renamed internally to `bias`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `gamma` will be renamed internally to `weight`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `beta` will be renamed internally to `bias`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `gamma` will be renamed internally to `weight`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `beta` will be renamed internally to `bias`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `gamma` will be renamed internally to `weight`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `beta` will be renamed internally to `bias`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `gamma` will be renamed internally to `weight`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `beta` will be renamed internally to `bias`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `gamma` will be renamed internally to `weight`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `beta` will be renamed internally to `bias`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `gamma` will be renamed internally to `weight`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `beta` will be renamed internally to `bias`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `gamma` will be renamed internally to `weight`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `beta` will be renamed internally to `bias`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `gamma` will be renamed internally to `weight`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `beta` will be renamed internally to `bias`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `gamma` will be renamed internally to `weight`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `beta` will be renamed internally to `bias`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `gamma` will be renamed internally to `weight`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `beta` will be renamed internally to `bias`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `gamma` will be renamed internally to `weight`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `beta` will be renamed internally to `bias`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `gamma` will be renamed internally to `weight`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `beta` will be renamed internally to `bias`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `gamma` will be renamed internally to `weight`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `beta` will be renamed internally to `bias`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `gamma` will be renamed internally to `weight`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `beta` will be renamed internally to `bias`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `gamma` will be renamed internally to `weight`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `beta` will be renamed internally to `bias`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `gamma` will be renamed internally to `weight`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `beta` will be renamed internally to `bias`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `gamma` will be renamed internally to `weight`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `beta` will be renamed internally to `bias`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `gamma` will be renamed internally to `weight`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `beta` will be renamed internally to `bias`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `gamma` will be renamed internally to `weight`. Please use a different name to suppress this warning.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model weights already saved at /Applications/AI/msc_project/model_weights/bert_weights_politifact_human_and_llm_cv1.pt. Skipping training.\n",
      "Model weights already saved at /Applications/AI/msc_project/model_weights/bert_weights_politifact_human_and_llm_cv2.pt. Skipping training.\n",
      "Model weights already saved at /Applications/AI/msc_project/model_weights/bert_weights_politifact_human_and_llm_cv3.pt. Skipping training.\n",
      "Model weights already saved at /Applications/AI/msc_project/model_weights/bert_weights_politifact_human_and_llm_cv4.pt. Skipping training.\n",
      "Model weights already saved at /Applications/AI/msc_project/model_weights/bert_weights_politifact_human_and_llm_cv5.pt. Skipping training.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "A parameter name that contains `beta` will be renamed internally to `bias`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `gamma` will be renamed internally to `weight`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `beta` will be renamed internally to `bias`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `gamma` will be renamed internally to `weight`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `beta` will be renamed internally to `bias`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `gamma` will be renamed internally to `weight`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `beta` will be renamed internally to `bias`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `gamma` will be renamed internally to `weight`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `beta` will be renamed internally to `bias`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `gamma` will be renamed internally to `weight`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `beta` will be renamed internally to `bias`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `gamma` will be renamed internally to `weight`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `beta` will be renamed internally to `bias`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `gamma` will be renamed internally to `weight`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `beta` will be renamed internally to `bias`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `gamma` will be renamed internally to `weight`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `beta` will be renamed internally to `bias`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `gamma` will be renamed internally to `weight`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `beta` will be renamed internally to `bias`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `gamma` will be renamed internally to `weight`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `beta` will be renamed internally to `bias`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `gamma` will be renamed internally to `weight`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `beta` will be renamed internally to `bias`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `gamma` will be renamed internally to `weight`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `beta` will be renamed internally to `bias`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `gamma` will be renamed internally to `weight`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `beta` will be renamed internally to `bias`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `gamma` will be renamed internally to `weight`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `beta` will be renamed internally to `bias`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `gamma` will be renamed internally to `weight`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `beta` will be renamed internally to `bias`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `gamma` will be renamed internally to `weight`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `beta` will be renamed internally to `bias`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `gamma` will be renamed internally to `weight`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `beta` will be renamed internally to `bias`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `gamma` will be renamed internally to `weight`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `beta` will be renamed internally to `bias`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `gamma` will be renamed internally to `weight`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `beta` will be renamed internally to `bias`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `gamma` will be renamed internally to `weight`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `beta` will be renamed internally to `bias`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `gamma` will be renamed internally to `weight`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `beta` will be renamed internally to `bias`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `gamma` will be renamed internally to `weight`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `beta` will be renamed internally to `bias`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `gamma` will be renamed internally to `weight`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `beta` will be renamed internally to `bias`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `gamma` will be renamed internally to `weight`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `beta` will be renamed internally to `bias`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `gamma` will be renamed internally to `weight`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `beta` will be renamed internally to `bias`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `gamma` will be renamed internally to `weight`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `beta` will be renamed internally to `bias`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `gamma` will be renamed internally to `weight`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `beta` will be renamed internally to `bias`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `gamma` will be renamed internally to `weight`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `beta` will be renamed internally to `bias`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `gamma` will be renamed internally to `weight`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `beta` will be renamed internally to `bias`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `gamma` will be renamed internally to `weight`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `beta` will be renamed internally to `bias`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `gamma` will be renamed internally to `weight`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `beta` will be renamed internally to `bias`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `gamma` will be renamed internally to `weight`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `beta` will be renamed internally to `bias`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `gamma` will be renamed internally to `weight`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `beta` will be renamed internally to `bias`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `gamma` will be renamed internally to `weight`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `beta` will be renamed internally to `bias`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `gamma` will be renamed internally to `weight`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `beta` will be renamed internally to `bias`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `gamma` will be renamed internally to `weight`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `beta` will be renamed internally to `bias`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `gamma` will be renamed internally to `weight`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `beta` will be renamed internally to `bias`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `gamma` will be renamed internally to `weight`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `beta` will be renamed internally to `bias`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `gamma` will be renamed internally to `weight`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `beta` will be renamed internally to `bias`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `gamma` will be renamed internally to `weight`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `beta` will be renamed internally to `bias`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `gamma` will be renamed internally to `weight`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `beta` will be renamed internally to `bias`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `gamma` will be renamed internally to `weight`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `beta` will be renamed internally to `bias`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `gamma` will be renamed internally to `weight`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `beta` will be renamed internally to `bias`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `gamma` will be renamed internally to `weight`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `beta` will be renamed internally to `bias`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `gamma` will be renamed internally to `weight`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `beta` will be renamed internally to `bias`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `gamma` will be renamed internally to `weight`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `beta` will be renamed internally to `bias`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `gamma` will be renamed internally to `weight`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `beta` will be renamed internally to `bias`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `gamma` will be renamed internally to `weight`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `beta` will be renamed internally to `bias`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `gamma` will be renamed internally to `weight`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `beta` will be renamed internally to `bias`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `gamma` will be renamed internally to `weight`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `beta` will be renamed internally to `bias`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `gamma` will be renamed internally to `weight`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `beta` will be renamed internally to `bias`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `gamma` will be renamed internally to `weight`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `beta` will be renamed internally to `bias`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `gamma` will be renamed internally to `weight`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `beta` will be renamed internally to `bias`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `gamma` will be renamed internally to `weight`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `beta` will be renamed internally to `bias`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `gamma` will be renamed internally to `weight`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `beta` will be renamed internally to `bias`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `gamma` will be renamed internally to `weight`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `beta` will be renamed internally to `bias`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `gamma` will be renamed internally to `weight`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `beta` will be renamed internally to `bias`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `gamma` will be renamed internally to `weight`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `beta` will be renamed internally to `bias`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `gamma` will be renamed internally to `weight`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `beta` will be renamed internally to `bias`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `gamma` will be renamed internally to `weight`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `beta` will be renamed internally to `bias`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `gamma` will be renamed internally to `weight`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `beta` will be renamed internally to `bias`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `gamma` will be renamed internally to `weight`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `beta` will be renamed internally to `bias`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `gamma` will be renamed internally to `weight`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `beta` will be renamed internally to `bias`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `gamma` will be renamed internally to `weight`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `beta` will be renamed internally to `bias`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `gamma` will be renamed internally to `weight`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `beta` will be renamed internally to `bias`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `gamma` will be renamed internally to `weight`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `beta` will be renamed internally to `bias`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `gamma` will be renamed internally to `weight`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `beta` will be renamed internally to `bias`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `gamma` will be renamed internally to `weight`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `beta` will be renamed internally to `bias`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `gamma` will be renamed internally to `weight`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `beta` will be renamed internally to `bias`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `gamma` will be renamed internally to `weight`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `beta` will be renamed internally to `bias`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `gamma` will be renamed internally to `weight`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `beta` will be renamed internally to `bias`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `gamma` will be renamed internally to `weight`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `beta` will be renamed internally to `bias`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `gamma` will be renamed internally to `weight`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `beta` will be renamed internally to `bias`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `gamma` will be renamed internally to `weight`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `beta` will be renamed internally to `bias`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `gamma` will be renamed internally to `weight`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `beta` will be renamed internally to `bias`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `gamma` will be renamed internally to `weight`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `beta` will be renamed internally to `bias`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `gamma` will be renamed internally to `weight`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `beta` will be renamed internally to `bias`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `gamma` will be renamed internally to `weight`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `beta` will be renamed internally to `bias`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `gamma` will be renamed internally to `weight`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `beta` will be renamed internally to `bias`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `gamma` will be renamed internally to `weight`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `beta` will be renamed internally to `bias`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `gamma` will be renamed internally to `weight`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `beta` will be renamed internally to `bias`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `gamma` will be renamed internally to `weight`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `beta` will be renamed internally to `bias`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `gamma` will be renamed internally to `weight`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `beta` will be renamed internally to `bias`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `gamma` will be renamed internally to `weight`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `beta` will be renamed internally to `bias`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `gamma` will be renamed internally to `weight`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `beta` will be renamed internally to `bias`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `gamma` will be renamed internally to `weight`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `beta` will be renamed internally to `bias`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `gamma` will be renamed internally to `weight`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `beta` will be renamed internally to `bias`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `gamma` will be renamed internally to `weight`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `beta` will be renamed internally to `bias`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `gamma` will be renamed internally to `weight`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `beta` will be renamed internally to `bias`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `gamma` will be renamed internally to `weight`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `beta` will be renamed internally to `bias`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `gamma` will be renamed internally to `weight`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `beta` will be renamed internally to `bias`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `gamma` will be renamed internally to `weight`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `beta` will be renamed internally to `bias`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `gamma` will be renamed internally to `weight`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `beta` will be renamed internally to `bias`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `gamma` will be renamed internally to `weight`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `beta` will be renamed internally to `bias`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `gamma` will be renamed internally to `weight`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `beta` will be renamed internally to `bias`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `gamma` will be renamed internally to `weight`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `beta` will be renamed internally to `bias`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `gamma` will be renamed internally to `weight`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `beta` will be renamed internally to `bias`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `gamma` will be renamed internally to `weight`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `beta` will be renamed internally to `bias`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `gamma` will be renamed internally to `weight`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `beta` will be renamed internally to `bias`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `gamma` will be renamed internally to `weight`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `beta` will be renamed internally to `bias`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `gamma` will be renamed internally to `weight`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `beta` will be renamed internally to `bias`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `gamma` will be renamed internally to `weight`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `beta` will be renamed internally to `bias`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `gamma` will be renamed internally to `weight`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `beta` will be renamed internally to `bias`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `gamma` will be renamed internally to `weight`. Please use a different name to suppress this warning.\n"
     ]
    }
   ],
   "source": [
    "# Define model weight file paths\n",
    "model_path_1 = \"/Applications/AI/msc_project/model_weights/bert_weights_politifact_human_and_llm_cv1.pt\"\n",
    "model_path_2 = \"/Applications/AI/msc_project/model_weights/bert_weights_politifact_human_and_llm_cv2.pt\"\n",
    "model_path_3 = \"/Applications/AI/msc_project/model_weights/bert_weights_politifact_human_and_llm_cv3.pt\"\n",
    "model_path_4 = \"/Applications/AI/msc_project/model_weights/bert_weights_politifact_human_and_llm_cv4.pt\"\n",
    "model_path_5 = \"/Applications/AI/msc_project/model_weights/bert_weights_politifact_human_and_llm_cv5.pt\"\n",
    "model_paths = [model_path_1, model_path_2, model_path_3, model_path_4, model_path_5]\n",
    "\n",
    "# RUN THIS CODE TO RERUN RESAMPLED FINE-TUNING EVALUATION\n",
    "'''\n",
    "os.remove(model_path_1)\n",
    "os.remove(model_path_2)\n",
    "os.remove(model_path_3)\n",
    "os.remove(model_path_4)\n",
    "os.remove(model_path_5)\n",
    "'''\n",
    "\n",
    "# Load & pre-process training data\n",
    "human_train_path_1 = \"/Applications/AI/msc_project/data/my_human_politifact_train_split_1.csv\"\n",
    "human_train_path_2 = \"/Applications/AI/msc_project/data/my_human_politifact_train_split_2.csv\"\n",
    "human_train_path_3 = \"/Applications/AI/msc_project/data/my_human_politifact_train_split_3.csv\"\n",
    "human_train_path_4 = \"/Applications/AI/msc_project/data/my_human_politifact_train_split_4.csv\"\n",
    "human_train_path_5 = \"/Applications/AI/msc_project/data/my_human_politifact_train_split_5.csv\"\n",
    "human_train_splits = [train_path_1, train_path_2, train_path_3, train_path_4, train_path_5]\n",
    "human_train_processed_seq_list, human_train_processed_mask_list, human_train_processed_y_list = pre_process_multi_datasplits(data_list=human_train_splits, tokenizer=tokenizer, max_len=max_len)\n",
    "llm_train_path_1 = \"/Applications/AI/msc_project/data/my_llm_fake_politifact_train_split_1.csv\"\n",
    "llm_train_path_2 = \"/Applications/AI/msc_project/data/my_llm_fake_politifact_train_split_2.csv\"\n",
    "llm_train_path_3 = \"/Applications/AI/msc_project/data/my_llm_fake_politifact_train_split_3.csv\"\n",
    "llm_train_path_4 = \"/Applications/AI/msc_project/data/my_llm_fake_politifact_train_split_4.csv\"\n",
    "llm_train_path_5 = \"/Applications/AI/msc_project/data/my_llm_fake_politifact_train_split_5.csv\"\n",
    "llm_train_splits = [llm_train_path_1, llm_train_path_2, llm_train_path_3, llm_train_path_4, llm_train_path_5]\n",
    "llm_train_processed_seq_list, llm_train_processed_mask_list, llm_train_processed_y_list = pre_process_multi_datasplits(data_list=llm_train_splits, tokenizer=tokenizer, max_len=max_len)\n",
    "combined_training_sequence_list = torch.cat((train_seq, val_seq), 0)\n",
    "combined_training_mask_list = torch.cat((train_mask, val_mask), 0)\n",
    "combined_training_y_list = torch.cat((train_y, val_y), 0)\n",
    "\n",
    "# Define best hyperparameters as chosen by previous hyperparameter selection grid search on initial exploration\n",
    "best_lr = 1e-5\n",
    "best_batch_size = 16\n",
    "best_epochs = 2\n",
    "best_model_init = \"unfrozen\"\n",
    "\n",
    "# Fine-tune models\n",
    "resample_training_models(model_paths=model_paths, train_processed_seq_list=combined_training_sequence_list, train_processed_mask_list=combined_training_mask_list, train_processed_y_list=combined_training_y_list, model_init=best_model_init, epochs=best_epochs, batch_size=best_batch_size, lr=best_lr)\n",
    "\n",
    "# Initialize and load models\n",
    "model_1 = initialise_bert_model_unfrozen()\n",
    "model_1.load_state_dict(torch.load(model_path_1), strict=False)\n",
    "model_2 = initialise_bert_model_unfrozen()\n",
    "model_2.load_state_dict(torch.load(model_path_2), strict=False)\n",
    "model_3 = initialise_bert_model_unfrozen()\n",
    "model_3.load_state_dict(torch.load(model_path_3), strict=False)\n",
    "model_4 = initialise_bert_model_unfrozen()\n",
    "model_4.load_state_dict(torch.load(model_path_4), strict=False)\n",
    "model_5 = initialise_bert_model_unfrozen()\n",
    "model_5.load_state_dict(torch.load(model_path_5), strict=False)\n",
    "models_list = [model_1, model_2, model_3, model_4, model_5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/jacobshort/anaconda3/envs/uni_39/lib/python3.9/site-packages/transformers/tokenization_utils_base.py:2870: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
      "  warnings.warn(\n",
      "/Users/jacobshort/anaconda3/envs/uni_39/lib/python3.9/site-packages/transformers/tokenization_utils_base.py:2870: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
      "  warnings.warn(\n",
      "/Users/jacobshort/anaconda3/envs/uni_39/lib/python3.9/site-packages/transformers/tokenization_utils_base.py:2870: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
      "  warnings.warn(\n",
      "/Users/jacobshort/anaconda3/envs/uni_39/lib/python3.9/site-packages/transformers/tokenization_utils_base.py:2870: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
      "  warnings.warn(\n",
      "/Users/jacobshort/anaconda3/envs/uni_39/lib/python3.9/site-packages/transformers/tokenization_utils_base.py:2870: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total batches to process: 6\n",
      "Total batches to process: 6\n",
      "Total batches to process: 6\n",
      "Total batches to process: 6\n",
      "Total batches to process: 6\n",
      "[90.54054054054053, 71.25, 86.25, 72.46376811594203, 93.24324324324324]\n",
      "[0.93, 0.86, 0.92, 0.87, 0.91]\n"
     ]
    }
   ],
   "source": [
    "# [RESAMPLING] Human & LLMFake trained BERT on human test set\n",
    "test_path_1 = \"/Applications/AI/msc_project/data/my_human_politifact_test_split_1.csv\"\n",
    "test_path_2 = \"/Applications/AI/msc_project/data/my_human_politifact_test_split_2.csv\"\n",
    "test_path_3 = \"/Applications/AI/msc_project/data/my_human_politifact_test_split_3.csv\"\n",
    "test_path_4 = \"/Applications/AI/msc_project/data/my_human_politifact_test_split_4.csv\"\n",
    "test_path_5 = \"/Applications/AI/msc_project/data/my_human_politifact_test_split_5.csv\"\n",
    "test_splits = [test_path_1, test_path_2, test_path_3, test_path_4, test_path_5]\n",
    "test_processed_seq_list, test_processed_mask_list, test_processed_y_list = pre_process_multi_datasplits(data_list=test_splits, tokenizer=tokenizer, max_len=max_len)\n",
    "\n",
    "original_df_1 = pd.read_csv(test_path_1)\n",
    "original_df_2 = pd.read_csv(test_path_2)\n",
    "original_df_3 = pd.read_csv(test_path_3)\n",
    "original_df_4 = pd.read_csv(test_path_4)\n",
    "original_df_5 = pd.read_csv(test_path_5)\n",
    "original_df_list = [original_df_1, original_df_2, original_df_3, original_df_4, original_df_5]\n",
    "\n",
    "success_rate_list, macro_f1_list = obtain_resampled_metrics_lists(models_list, original_df_list=original_df_list, sequences_list=test_processed_seq_list, masks_list=test_processed_mask_list, labels_list=test_processed_y_list)\n",
    "print(success_rate_list)\n",
    "print(macro_f1_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/jacobshort/anaconda3/envs/uni_39/lib/python3.9/site-packages/transformers/tokenization_utils_base.py:2870: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
      "  warnings.warn(\n",
      "/Users/jacobshort/anaconda3/envs/uni_39/lib/python3.9/site-packages/transformers/tokenization_utils_base.py:2870: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
      "  warnings.warn(\n",
      "/Users/jacobshort/anaconda3/envs/uni_39/lib/python3.9/site-packages/transformers/tokenization_utils_base.py:2870: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
      "  warnings.warn(\n",
      "/Users/jacobshort/anaconda3/envs/uni_39/lib/python3.9/site-packages/transformers/tokenization_utils_base.py:2870: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
      "  warnings.warn(\n",
      "/Users/jacobshort/anaconda3/envs/uni_39/lib/python3.9/site-packages/transformers/tokenization_utils_base.py:2870: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total batches to process: 13\n",
      "Processed 10 batches, 3 batches remaining\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/jacobshort/anaconda3/envs/uni_39/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1469: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/jacobshort/anaconda3/envs/uni_39/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1469: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/jacobshort/anaconda3/envs/uni_39/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1469: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total batches to process: 13\n",
      "Processed 10 batches, 3 batches remaining\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/jacobshort/anaconda3/envs/uni_39/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1469: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/jacobshort/anaconda3/envs/uni_39/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1469: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/jacobshort/anaconda3/envs/uni_39/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1469: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total batches to process: 13\n",
      "Processed 10 batches, 3 batches remaining\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/jacobshort/anaconda3/envs/uni_39/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1469: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/jacobshort/anaconda3/envs/uni_39/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1469: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/jacobshort/anaconda3/envs/uni_39/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1469: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total batches to process: 13\n",
      "Processed 10 batches, 3 batches remaining\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/jacobshort/anaconda3/envs/uni_39/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1469: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/jacobshort/anaconda3/envs/uni_39/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1469: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/jacobshort/anaconda3/envs/uni_39/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1469: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total batches to process: 13\n",
      "Processed 10 batches, 3 batches remaining\n",
      "[93.75, 93.02884615384616, 93.75, 93.02884615384616, 96.875]\n",
      "{'llm_false_context': [79.3103448275862, 79.3103448275862, 79.3103448275862, 86.20689655172413, 96.55172413793103], 'llm_unsubstantiated_content': [82.75862068965517, 89.65517241379311, 86.20689655172413, 93.10344827586206, 100.0], 'llm_total_fabrication': [93.10344827586206, 89.65517241379311, 100.0, 86.20689655172413, 96.55172413793103], 'llm_incomplete': [86.20689655172413, 86.20689655172413, 82.75862068965517, 65.51724137931035, 79.3103448275862], 'llm_ambiguity': [82.75862068965517, 79.3103448275862, 79.3103448275862, 82.75862068965517, 96.55172413793103], 'llm_totally_arbitrary_generation': [100.0, 100.0, 100.0, 100.0, 100.0], 'llm_open_generation': [100.0, 98.14814814814815, 100.0, 100.0, 100.0], 'llm_paraphrase': [100.0, 98.14814814814815, 100.0, 100.0, 98.14814814814815], 'llm_outdated': [86.20689655172413, 82.75862068965517, 82.75862068965517, 96.55172413793103, 89.65517241379311], 'llm_rewritten': [100.0, 100.0, 100.0, 100.0, 100.0], 'llm_hallucination': [100.0, 100.0, 100.0, 85.0, 100.0], 'llm_health_generation': [100.0, 100.0, 100.0, 100.0, 100.0], 'llm_politics_generation': [100.0, 100.0, 100.0, 100.0, 100.0]}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/jacobshort/anaconda3/envs/uni_39/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1469: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/jacobshort/anaconda3/envs/uni_39/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1469: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/jacobshort/anaconda3/envs/uni_39/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1469: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "# [RESAMPLED] Human & LLMFake trained BERT on LLMFake test set\n",
    "# Note: macro F1 here doesn't make sense\n",
    "test_path_1 = \"/Applications/AI/msc_project/data/my_llm_fake_politifact_test_split_1.csv\"\n",
    "test_path_2 = \"/Applications/AI/msc_project/data/my_llm_fake_politifact_test_split_2.csv\"\n",
    "test_path_3 = \"/Applications/AI/msc_project/data/my_llm_fake_politifact_test_split_3.csv\"\n",
    "test_path_4 = \"/Applications/AI/msc_project/data/my_llm_fake_politifact_test_split_4.csv\"\n",
    "test_path_5 = \"/Applications/AI/msc_project/data/my_llm_fake_politifact_test_split_5.csv\"\n",
    "test_splits = [test_path_1, test_path_2, test_path_3, test_path_4, test_path_5]\n",
    "test_processed_seq_list, test_processed_mask_list, test_processed_y_list = pre_process_multi_datasplits(data_list=test_splits, tokenizer=tokenizer, max_len=max_len)\n",
    "\n",
    "original_df_1 = pd.read_csv(test_path_1)\n",
    "original_df_2 = pd.read_csv(test_path_2)\n",
    "original_df_3 = pd.read_csv(test_path_3)\n",
    "original_df_4 = pd.read_csv(test_path_4)\n",
    "original_df_5 = pd.read_csv(test_path_5)\n",
    "original_df_list = [original_df_1, original_df_2, original_df_3, original_df_4, original_df_5]\n",
    "\n",
    "success_rate_list, _, classwise_success_rates = obtain_resampled_metrics_lists_classwise(models_list, original_df_list=original_df_list, sequences_list=test_processed_seq_list, masks_list=test_processed_mask_list, labels_list=test_processed_y_list)\n",
    "print(success_rate_list)\n",
    "print(classwise_success_rates)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.18 ('uni_39')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "c2442b4eed952f48f926d303071082d30c5080f089ed43bdeb0e861e3760da25"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
