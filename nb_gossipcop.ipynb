{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Naive Bayes (Trained On Human GossipCop)\n",
    "https://medium.com/@bedigunjit/simple-guide-to-text-classification-nlp-using-svm-and-naive-bayes-with-python-421db3a72d34"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     /Users/jacobshort/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     /Users/jacobshort/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
      "[nltk_data]     /Users/jacobshort/nltk_data...\n",
      "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
      "[nltk_data]       date!\n",
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     /Users/jacobshort/nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n",
      "[nltk_data] Downloading package averaged_perceptron_tagger_eng to\n",
      "[nltk_data]     /Users/jacobshort/nltk_data...\n",
      "[nltk_data]   Package averaged_perceptron_tagger_eng is already up-to-\n",
      "[nltk_data]       date!\n"
     ]
    }
   ],
   "source": [
    "# IMPORTS\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk import pos_tag\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from collections import defaultdict\n",
    "from nltk.corpus import wordnet as wn\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn import naive_bayes\n",
    "from sklearn.metrics import accuracy_score\n",
    "import nltk\n",
    "from sklearn.metrics import classification_report\n",
    "nltk.download('punkt')\n",
    "nltk.download('stopwords')\n",
    "nltk.download('averaged_perceptron_tagger')\n",
    "nltk.download('wordnet')\n",
    "nltk.download('averaged_perceptron_tagger_eng')\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "\n",
    "# SET SEED\n",
    "np.random.seed(500)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "74.92163009404389\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.55      0.75      0.64       957\n",
      "           1       0.91      0.81      0.86      3045\n",
      "\n",
      "    accuracy                           0.80      4002\n",
      "   macro avg       0.73      0.78      0.75      4002\n",
      "weighted avg       0.83      0.80      0.80      4002\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Text</th>\n",
       "      <th>Predicted Label</th>\n",
       "      <th>Original Label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>HollywoodLife is turning Robert Pattinson ’s n...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>In its quest to launch a hit fantasy series of...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>The budding romance between Josh Duhamel and E...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>She may not be at the Super Bowl, but she cert...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Do not be tardy for this dance,  Friday night ...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3997</th>\n",
       "      <td>Ever wonder what Hollywood stars are whisperin...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3998</th>\n",
       "      <td>Julia Louis-Dreyfus just wrapped her second ro...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3999</th>\n",
       "      <td>She’s had enough! Cheryl Cole shut down a repo...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4000</th>\n",
       "      <td>It's Official! The Bachelor's Arie Luyendyk Jr...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4001</th>\n",
       "      <td>Aoki Lee Simmons / Instagram  Being a teen on ...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>4002 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                   Text  Predicted Label  \\\n",
       "0     HollywoodLife is turning Robert Pattinson ’s n...                0   \n",
       "1     In its quest to launch a hit fantasy series of...                1   \n",
       "2     The budding romance between Josh Duhamel and E...                0   \n",
       "3     She may not be at the Super Bowl, but she cert...                1   \n",
       "4     Do not be tardy for this dance,  Friday night ...                1   \n",
       "...                                                 ...              ...   \n",
       "3997  Ever wonder what Hollywood stars are whisperin...                1   \n",
       "3998  Julia Louis-Dreyfus just wrapped her second ro...                1   \n",
       "3999  She’s had enough! Cheryl Cole shut down a repo...                0   \n",
       "4000  It's Official! The Bachelor's Arie Luyendyk Jr...                1   \n",
       "4001  Aoki Lee Simmons / Instagram  Being a teen on ...                1   \n",
       "\n",
       "      Original Label  \n",
       "0                  0  \n",
       "1                  1  \n",
       "2                  1  \n",
       "3                  1  \n",
       "4                  1  \n",
       "...              ...  \n",
       "3997               1  \n",
       "3998               1  \n",
       "3999               1  \n",
       "4000               1  \n",
       "4001               1  \n",
       "\n",
       "[4002 rows x 3 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Load datasets\n",
    "original_only_train_corpus = pd.read_csv(\"/Applications/AI/msc_project/data/my_gossipcop_train.csv\")\n",
    "original_only_validation_corpus = pd.read_csv(\"/Applications/AI/msc_project/data/my_gossipcop_validation.csv\")\n",
    "original_train_corpus = pd.concat([original_only_train_corpus, original_only_validation_corpus], ignore_index=True)\n",
    "\n",
    "# Preprocess function\n",
    "def preprocess(corpus): \n",
    "    tokenised_corpus = corpus.copy()\n",
    "\n",
    "    # Lowercase all text\n",
    "    tokenised_corpus['text'] = [entry.lower() for entry in tokenised_corpus['text']]\n",
    "\n",
    "    # Split each text into words (word tokenisation)\n",
    "    tokenised_corpus['text'] = [word_tokenize(entry) for entry in tokenised_corpus['text']]\n",
    "\n",
    "    # Remove Stop words & Numeric words. Perform Word Stemming/Lemmatization\n",
    "    tag_map = defaultdict(lambda : wn.NOUN)\n",
    "    tag_map['J'] = wn.ADJ\n",
    "    tag_map['V'] = wn.VERB\n",
    "    tag_map['R'] = wn.ADV\n",
    "    for index, entry in enumerate(tokenised_corpus['text']):\n",
    "        Final_words = []\n",
    "        word_Lemmatized = WordNetLemmatizer()\n",
    "        for word, tag in pos_tag(entry):\n",
    "            if word not in stopwords.words('english') and word.isalpha():\n",
    "                word_Final = word_Lemmatized.lemmatize(word, tag_map[tag[0]])\n",
    "                Final_words.append(word_Final)\n",
    "        tokenised_corpus.loc[index, 'text_final'] = ' '.join(Final_words)  # Convert list of words back to a single string\n",
    "\n",
    "    X = tokenised_corpus['text_final']\n",
    "    Y = tokenised_corpus['is_true']\n",
    "        \n",
    "    return X, Y\n",
    "\n",
    "# Preprocess the training data\n",
    "train_X, train_Y = preprocess(original_train_corpus)\n",
    "\n",
    "# Train Naive Bayes Model\n",
    "def train_nb(Train_X, Train_Y):\n",
    "    Naive = naive_bayes.MultinomialNB()\n",
    "    Naive.fit(Train_X, Train_Y)\n",
    "    return Naive\n",
    "\n",
    "# Vectorize text data using CountVectorizer\n",
    "Count_vect = CountVectorizer(max_features=5000)    \n",
    "Count_vect.fit(train_X)\n",
    "train_X_counts = Count_vect.transform(train_X)\n",
    "\n",
    "model = train_nb(train_X_counts, train_Y)\n",
    "\n",
    "# Prediction and metrics function for basic case\n",
    "def predictions_and_metrics_basic(model, original_df, Count_vect):\n",
    "    # Transform the test data\n",
    "    test_X_counts = Count_vect.transform(original_df['text_final'])\n",
    "    \n",
    "    # Use the model to make predictions\n",
    "    predictions_NB = model.predict(test_X_counts)\n",
    "\n",
    "    results_df = pd.DataFrame({\n",
    "        'Text': original_df['text'],\n",
    "        'Predicted Label': predictions_NB,\n",
    "        'Original Label': original_df['is_true']\n",
    "    })\n",
    "\n",
    "    original_misinformations = results_df[results_df['Original Label'] == 0]\n",
    "    correct_predictions = original_misinformations[original_misinformations['Predicted Label'] == 0].shape[0]\n",
    "    success_rate = 100*(correct_predictions / original_misinformations.shape[0]) if original_misinformations.shape[0] > 0 else 0\n",
    "\n",
    "    metrics = classification_report(results_df['Original Label'], results_df['Predicted Label'])\n",
    "\n",
    "    return results_df, success_rate, metrics\n",
    "\n",
    "# Prediction and metrics function for classwise case\n",
    "def predictions_and_metrics_classwise(model, original_df, test_X_counts):\n",
    "    # Use the model to make predictions directly on the provided count matrix\n",
    "    predictions_NB = model.predict(test_X_counts)\n",
    "\n",
    "    results_df = pd.DataFrame({\n",
    "        'Text': original_df['text'],\n",
    "        'Category': original_df['label'],\n",
    "        'Predicted Label': predictions_NB,\n",
    "        'Original Label': original_df['is_true']\n",
    "    })\n",
    "\n",
    "    # Compute overall success rate\n",
    "    original_misinformations = results_df[results_df['Original Label'] == 0]\n",
    "    correct_predictions = original_misinformations[original_misinformations['Predicted Label'] == 0].shape[0]\n",
    "    success_rate = 100 * (correct_predictions / original_misinformations.shape[0]) if original_misinformations.shape[0] > 0 else 0\n",
    "\n",
    "    # Compute class-wise success rates\n",
    "    classwise_success_rates = {}\n",
    "    for category in results_df['Category'].unique():\n",
    "        category_df = results_df[results_df['Category'] == category]\n",
    "        original_misinformations = category_df[category_df['Original Label'] == 0]\n",
    "        correct_predictions = original_misinformations[original_misinformations['Predicted Label'] == 0].shape[0]\n",
    "        classwise_success_rate = 100 * (correct_predictions / original_misinformations.shape[0]) if original_misinformations.shape[0] > 0 else 0\n",
    "        classwise_success_rates[category] = classwise_success_rate\n",
    "\n",
    "    metrics = classification_report(results_df['Original Label'], results_df['Predicted Label'])\n",
    "    \n",
    "    return results_df, success_rate, classwise_success_rates, metrics\n",
    "\n",
    "\n",
    "# HUMAN TEST SET\n",
    "original_human_test_corpus = pd.read_csv(\"/Applications/AI/msc_project/data/my_gossipcop_test.csv\")\n",
    "test_X, test_Y = preprocess(original_human_test_corpus)\n",
    "\n",
    "# Add 'text_final' to original_human_test_corpus\n",
    "original_human_test_corpus['text_final'] = test_X\n",
    "\n",
    "# Generate predictions and metrics\n",
    "results_df, success_rate, metrics = predictions_and_metrics_basic(model, original_human_test_corpus, Count_vect)\n",
    "print(success_rate)\n",
    "print(metrics)\n",
    "display(results_df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "72.66187050359713\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.73      0.84       139\n",
      "           1       0.00      0.00      0.00         0\n",
      "\n",
      "    accuracy                           0.73       139\n",
      "   macro avg       0.50      0.36      0.42       139\n",
      "weighted avg       1.00      0.73      0.84       139\n",
      "\n",
      "{'llm_paraphrase': 73.91304347826086, 'llm_rewritten': 76.59574468085107, 'llm_open_generation': 67.3913043478261}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/jacobshort/anaconda3/envs/uni2_39/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/Users/jacobshort/anaconda3/envs/uni2_39/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/Users/jacobshort/anaconda3/envs/uni2_39/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    }
   ],
   "source": [
    "# LLM TEST SET\n",
    "original_llm_test_corpus = pd.read_csv(\"/Applications/AI/msc_project/data/my_llm_fake_gossipcop_test.csv\")\n",
    "test_X, test_Y = preprocess(original_llm_test_corpus)\n",
    "\n",
    "# Add 'text_final' to original_llm_test_corpus\n",
    "original_llm_test_corpus['text_final'] = test_X\n",
    "\n",
    "# Transform the test data using CountVectorizer\n",
    "test_X_counts = Count_vect.transform(test_X)\n",
    "\n",
    "# Generate predictions and metrics for classwise evaluation\n",
    "results_df, success_rate, classwise_success_rates, metrics = predictions_and_metrics_classwise(model, original_llm_test_corpus, test_X_counts)\n",
    "print(success_rate)\n",
    "print(metrics)\n",
    "print(classwise_success_rates)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "uni_39",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
