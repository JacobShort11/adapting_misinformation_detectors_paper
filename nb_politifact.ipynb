{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Naive Bayes (Trained On Human PolitiFact)\n",
    "https://medium.com/@bedigunjit/simple-guide-to-text-classification-nlp-using-svm-and-naive-bayes-with-python-421db3a72d34"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     /Users/jacobshort/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     /Users/jacobshort/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
      "[nltk_data]     /Users/jacobshort/nltk_data...\n",
      "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
      "[nltk_data]       date!\n",
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     /Users/jacobshort/nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n",
      "[nltk_data] Downloading package averaged_perceptron_tagger_eng to\n",
      "[nltk_data]     /Users/jacobshort/nltk_data...\n",
      "[nltk_data]   Package averaged_perceptron_tagger_eng is already up-to-\n",
      "[nltk_data]       date!\n"
     ]
    }
   ],
   "source": [
    "# IMPORTS\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk import pos_tag\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from collections import defaultdict\n",
    "from nltk.corpus import wordnet as wn\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn import naive_bayes\n",
    "from sklearn.metrics import accuracy_score\n",
    "import nltk\n",
    "from sklearn.metrics import classification_report\n",
    "nltk.download('punkt')\n",
    "nltk.download('stopwords')\n",
    "nltk.download('averaged_perceptron_tagger')\n",
    "nltk.download('wordnet')\n",
    "nltk.download('averaged_perceptron_tagger_eng')\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "\n",
    "# SET SEED\n",
    "np.random.seed(500)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "92.10526315789474\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.71      0.92      0.80        76\n",
      "           1       0.92      0.71      0.80       100\n",
      "\n",
      "    accuracy                           0.80       176\n",
      "   macro avg       0.81      0.82      0.80       176\n",
      "weighted avg       0.83      0.80      0.80       176\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Text</th>\n",
       "      <th>Predicted Label</th>\n",
       "      <th>Original Label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Senate Passes Obama-Hagel Provision Aimed at P...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>The .gov means it's official. Federal governme...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Muslim convert and would-be domestic terrorist...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>'This Week' Transcript: Former Vice President ...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>We'll stop supporting this browser soon. For t...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>171</th>\n",
       "      <td>Fox News host Sandra Smith on Wednesday linked...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>172</th>\n",
       "      <td>Listen to this page  Listen to this page  List...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>173</th>\n",
       "      <td>NRA President Jim Porter Falsely Accused of Sa...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>174</th>\n",
       "      <td>President Trump invited Elizabeth Alvarado, Ro...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>175</th>\n",
       "      <td>Snopes Paid to Push ‘Propaganda’ by Facebook, ...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>176 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                  Text  Predicted Label  \\\n",
       "0    Senate Passes Obama-Hagel Provision Aimed at P...                1   \n",
       "1    The .gov means it's official. Federal governme...                0   \n",
       "2    Muslim convert and would-be domestic terrorist...                0   \n",
       "3    'This Week' Transcript: Former Vice President ...                1   \n",
       "4    We'll stop supporting this browser soon. For t...                1   \n",
       "..                                                 ...              ...   \n",
       "171  Fox News host Sandra Smith on Wednesday linked...                0   \n",
       "172  Listen to this page  Listen to this page  List...                0   \n",
       "173  NRA President Jim Porter Falsely Accused of Sa...                0   \n",
       "174  President Trump invited Elizabeth Alvarado, Ro...                0   \n",
       "175  Snopes Paid to Push ‘Propaganda’ by Facebook, ...                0   \n",
       "\n",
       "     Original Label  \n",
       "0                 1  \n",
       "1                 1  \n",
       "2                 0  \n",
       "3                 1  \n",
       "4                 1  \n",
       "..              ...  \n",
       "171               0  \n",
       "172               1  \n",
       "173               0  \n",
       "174               0  \n",
       "175               0  \n",
       "\n",
       "[176 rows x 3 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Load datasets\n",
    "original_only_train_corpus = pd.read_csv(\"/Applications/AI/msc_project/data/my_politifact_train.csv\")\n",
    "original_only_validation_corpus = pd.read_csv(\"/Applications/AI/msc_project/data/my_politifact_validation.csv\")\n",
    "original_train_corpus = pd.concat([original_only_train_corpus, original_only_validation_corpus], ignore_index=True)\n",
    "\n",
    "# Preprocess function\n",
    "def preprocess(corpus): \n",
    "    tokenised_corpus = corpus.copy()\n",
    "\n",
    "    # Lowercase all text\n",
    "    tokenised_corpus['text'] = [entry.lower() for entry in tokenised_corpus['text']]\n",
    "\n",
    "    # Split each text into words (word tokenisation)\n",
    "    tokenised_corpus['text'] = [word_tokenize(entry) for entry in tokenised_corpus['text']]\n",
    "\n",
    "    # Remove Stop words & Numeric words. Perform Word Stemming/Lemmatization\n",
    "    tag_map = defaultdict(lambda : wn.NOUN)\n",
    "    tag_map['J'] = wn.ADJ\n",
    "    tag_map['V'] = wn.VERB\n",
    "    tag_map['R'] = wn.ADV\n",
    "    for index, entry in enumerate(tokenised_corpus['text']):\n",
    "        Final_words = []\n",
    "        word_Lemmatized = WordNetLemmatizer()\n",
    "        for word, tag in pos_tag(entry):\n",
    "            if word not in stopwords.words('english') and word.isalpha():\n",
    "                word_Final = word_Lemmatized.lemmatize(word, tag_map[tag[0]])\n",
    "                Final_words.append(word_Final)\n",
    "        tokenised_corpus.loc[index, 'text_final'] = ' '.join(Final_words)\n",
    "\n",
    "    X = tokenised_corpus['text_final']\n",
    "    Y = tokenised_corpus['is_true']\n",
    "        \n",
    "    return X, Y\n",
    "\n",
    "# Preprocess the training data\n",
    "train_X, train_Y = preprocess(original_train_corpus)\n",
    "\n",
    "# Train Naive Bayes Model\n",
    "def train_nb(Train_X, Train_Y):\n",
    "    Naive = naive_bayes.MultinomialNB()\n",
    "    Naive.fit(Train_X, Train_Y)\n",
    "    return Naive\n",
    "\n",
    "# Vectorize text data using CountVectorizer\n",
    "Count_vect = CountVectorizer(max_features=5000)    \n",
    "Count_vect.fit(train_X)\n",
    "train_X_counts = Count_vect.transform(train_X)\n",
    "\n",
    "model = train_nb(train_X_counts, train_Y)\n",
    "\n",
    "# Prediction and metrics function for basic case\n",
    "def predictions_and_metrics_basic(model, original_df, Count_vect):\n",
    "    # Transform the test data\n",
    "    test_X_counts = Count_vect.transform(original_df['text_final'])\n",
    "    \n",
    "    # Use the model to make predictions\n",
    "    predictions_NB = model.predict(test_X_counts)\n",
    "\n",
    "    results_df = pd.DataFrame({\n",
    "        'Text': original_df['text'],\n",
    "        'Predicted Label': predictions_NB,\n",
    "        'Original Label': original_df['is_true']\n",
    "    })\n",
    "\n",
    "    original_misinformations = results_df[results_df['Original Label'] == 0]\n",
    "    correct_predictions = original_misinformations[original_misinformations['Predicted Label'] == 0].shape[0]\n",
    "    success_rate = 100*(correct_predictions / original_misinformations.shape[0]) if original_misinformations.shape[0] > 0 else 0\n",
    "\n",
    "    metrics = classification_report(results_df['Original Label'], results_df['Predicted Label'])\n",
    "\n",
    "    return results_df, success_rate, metrics\n",
    "\n",
    "# Prediction and metrics function for classwise case\n",
    "def predictions_and_metrics_classwise(model, original_df, test_X_counts):\n",
    "    # Use the model to make predictions directly on the provided count matrix\n",
    "    predictions_NB = model.predict(test_X_counts)\n",
    "\n",
    "    results_df = pd.DataFrame({\n",
    "        'Text': original_df['text'],\n",
    "        'Category': original_df['label'],\n",
    "        'Predicted Label': predictions_NB,\n",
    "        'Original Label': original_df['is_true']\n",
    "    })\n",
    "\n",
    "    # Compute overall success rate\n",
    "    original_misinformations = results_df[results_df['Original Label'] == 0]\n",
    "    correct_predictions = original_misinformations[original_misinformations['Predicted Label'] == 0].shape[0]\n",
    "    success_rate = 100 * (correct_predictions / original_misinformations.shape[0]) if original_misinformations.shape[0] > 0 else 0\n",
    "\n",
    "    # Compute class-wise success rates\n",
    "    classwise_success_rates = {}\n",
    "    for category in results_df['Category'].unique():\n",
    "        category_df = results_df[results_df['Category'] == category]\n",
    "        original_misinformations = category_df[category_df['Original Label'] == 0]\n",
    "        correct_predictions = original_misinformations[original_misinformations['Predicted Label'] == 0].shape[0]\n",
    "        classwise_success_rate = 100 * (correct_predictions / original_misinformations.shape[0]) if original_misinformations.shape[0] > 0 else 0\n",
    "        classwise_success_rates[category] = classwise_success_rate\n",
    "\n",
    "    metrics = classification_report(results_df['Original Label'], results_df['Predicted Label'])\n",
    "    \n",
    "    return results_df, success_rate, classwise_success_rates, metrics\n",
    "\n",
    "\n",
    "# HUMAN TEST SET\n",
    "original_human_test_corpus = pd.read_csv(\"/Applications/AI/msc_project/data/my_politifact_test.csv\")\n",
    "test_X, test_Y = preprocess(original_human_test_corpus)\n",
    "\n",
    "# Add 'text_final' to original_human_test_corpus\n",
    "original_human_test_corpus['text_final'] = test_X\n",
    "\n",
    "# Generate predictions and metrics\n",
    "results_df, success_rate, metrics = predictions_and_metrics_basic(model, original_human_test_corpus, Count_vect)\n",
    "print(success_rate)\n",
    "print(metrics)\n",
    "display(results_df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "71.70263788968825\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.72      0.84       417\n",
      "           1       0.00      0.00      0.00         0\n",
      "\n",
      "    accuracy                           0.72       417\n",
      "   macro avg       0.50      0.36      0.42       417\n",
      "weighted avg       1.00      0.72      0.84       417\n",
      "\n",
      "{'llm_totally_arbitrary_generation': 85.0, 'llm_incomplete': 41.37931034482759, 'llm_false_context': 53.333333333333336, 'llm_open_generation': 88.88888888888889, 'llm_unsubstantiated_content': 41.37931034482759, 'llm_outdated': 41.37931034482759, 'llm_health_generation': 100.0, 'llm_rewritten': 90.74074074074075, 'llm_total_fabrication': 51.724137931034484, 'llm_politics_generation': 100.0, 'llm_paraphrase': 94.44444444444444, 'llm_hallucination': 70.0, 'llm_ambiguity': 44.827586206896555}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/jacobshort/anaconda3/envs/uni2_39/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/Users/jacobshort/anaconda3/envs/uni2_39/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/Users/jacobshort/anaconda3/envs/uni2_39/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    }
   ],
   "source": [
    "# LLM TEST SET\n",
    "original_llm_test_corpus = pd.read_csv(\"/Applications/AI/msc_project/data/my_llm_fake_politifact_test.csv\")\n",
    "test_X, test_Y = preprocess(original_llm_test_corpus)\n",
    "\n",
    "# Add 'text_final' to original_llm_test_corpus\n",
    "original_llm_test_corpus['text_final'] = test_X\n",
    "\n",
    "# Transform the test data using CountVectorizer\n",
    "test_X_counts = Count_vect.transform(test_X)\n",
    "\n",
    "# Generate predictions and metrics for classwise evaluation\n",
    "results_df, success_rate, classwise_success_rates, metrics = predictions_and_metrics_classwise(model, original_llm_test_corpus, test_X_counts)\n",
    "print(success_rate)\n",
    "print(metrics)\n",
    "print(classwise_success_rates)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "uni_39",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
